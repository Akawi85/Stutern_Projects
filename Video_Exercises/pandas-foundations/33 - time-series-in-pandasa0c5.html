<!DOCTYPE html><html lang="en">
<!-- Mirrored from campus.datacamp.com/courses/pandas-foundations/time-series-in-pandas?ex=14 by HTTrack Website Copier/3.x [XR&CO'2014], Mon, 25 Feb 2019 20:43:28 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head><link rel="icon" type="image/png" href="https://campus.datacamp.com/favicon.ico"><link href="../../static/css/main.2a9f739f.css" rel="stylesheet"><title data-react-helmet="true">Time zones and conversion | Python</title><link data-react-helmet="true" href="data:image/png;base64,bW9kdWxlLmV4cG9ydHMgPSBfX3dlYnBhY2tfcHVibGljX3BhdGhfXyArICIvc3RhdGljL21lZGlhL2FwcGxlLWljb24uNGZhMTNiMGYucG5nIjs=" rel="apple-touch-icon"><link data-react-helmet="true" href="data:image/png;base64,bW9kdWxlLmV4cG9ydHMgPSBfX3dlYnBhY2tfcHVibGljX3BhdGhfXyArICIvc3RhdGljL21lZGlhL2FwcGxlLWljb24uNGZhMTNiMGYucG5nIjs=" rel="apple-touch-icon-precomposed"><meta data-react-helmet="true" charset="utf-8"><meta data-react-helmet="true" http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><meta data-react-helmet="true" name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta data-react-helmet="true" name="fragment" content="!"><meta data-react-helmet="true" name="keywords" content="R, Python, Data analysis, interactive, learning"><meta data-react-helmet="true" name="description" content="Here is an example of Time zones and conversion: Time zone handling with pandas typically assumes that you are handling the Index of the Series."><meta data-react-helmet="true" name="twitter:card" content="summary"><meta data-react-helmet="true" name="twitter:site" content="@DataCamp"><meta data-react-helmet="true" name="twitter:title" content="Time zones and conversion | Python"><meta data-react-helmet="true" name="twitter:description" content="Here is an example of Time zones and conversion: Time zone handling with pandas typically assumes that you are handling the Index of the Series."><meta data-react-helmet="true" name="twitter:creator" content="@DataCamp"><meta data-react-helmet="true" name="twitter:image:src" content="../../public/assets/images/var/twitter_share.png"><meta data-react-helmet="true" name="twitter:domain" content="www.datacamp.com"><meta data-react-helmet="true" property="og:title" content="Time zones and conversion | Python"><meta data-react-helmet="true" property="og:image" content="../../public/assets/images/var/linkedin_share.png"><meta data-react-helmet="true" name="google-signin-clientid" content="892114885437-01a7plbsu1b2vobuhvnckmmanhb58h3a.apps.googleusercontent.com"><meta data-react-helmet="true" name="google-signin-scope" content="email profile"><meta data-react-helmet="true" name="google-signin-cookiepolicy" content="single_host_origin"></head><body><script>window.PRELOADED_STATE = "[&quot;~#iM&quot;,[&quot;preFetchedData&quot;,[&quot;^0&quot;,[&quot;course&quot;,[&quot;^0&quot;,[&quot;status&quot;,&quot;SUCCESS&quot;,&quot;data&quot;,[&quot;^ &quot;,&quot;id&quot;,1639,&quot;title&quot;,&quot;pandas Foundations&quot;,&quot;description&quot;,&quot;Pandas DataFrames are the most widely used in-memory representation of complex data collections within Python.  Whether in finance, scientific fields, or data science, a familiarity with Pandas is essential.  This course teaches you to work with real-world data sets containing both string and numeric data, often structured around time series.  You will learn powerful analysis, selection, and visualization techniques in this course.&quot;,&quot;short_description&quot;,&quot;Learn how to use the industry-standard pandas library to import, build, and manipulate DataFrames. &quot;,&quot;author_field&quot;,null,&quot;author_bio&quot;,null,&quot;author_image&quot;,&quot;placeholder.png&quot;,&quot;nb_of_subscriptions&quot;,85379,&quot;slug&quot;,&quot;pandas-foundations&quot;,&quot;image_url&quot;,&quot;https://assets.datacamp.com/production/course_1639/shields/thumb/shield_image_course_1639_20190204-13-1xw9geb?1549311490&quot;,&quot;image_thumbnail_url&quot;,&quot;https://assets.datacamp.com/production/course_1639/shields/thumb_home/shield_image_course_1639_20190204-13-1xw9geb?1549311490&quot;,&quot;last_updated_on&quot;,&quot;04/02/2019&quot;,&quot;link&quot;,&quot;https://www.datacamp.com/courses/pandas-foundations&quot;,&quot;should_cache&quot;,true,&quot;type&quot;,&quot;datacamp&quot;,&quot;difficulty_level&quot;,2,&quot;state&quot;,&quot;live&quot;,&quot;university&quot;,null,&quot;sharing_links&quot;,[&quot;^ &quot;,&quot;twitter&quot;,&quot;http://bit.ly/1eWTMJh&quot;,&quot;facebook&quot;,&quot;http://bit.ly/1iS42Do&quot;],&quot;programming_language&quot;,&quot;python&quot;,&quot;paid&quot;,true,&quot;time_needed&quot;,&quot;4 hours&quot;,&quot;xp&quot;,5150,&quot;topic_id&quot;,3,&quot;reduced_outline&quot;,null,&quot;runtime_config&quot;,&quot;heavy&quot;,&quot;lti_only&quot;,false,&quot;chapters&quot;,[[&quot;^ &quot;,&quot;id&quot;,4259,&quot;title_meta&quot;,null,&quot;^1&quot;,&quot;Data ingestion &amp; inspection&quot;,&quot;^2&quot;,&quot;In this chapter, you will be introduced to Panda&#39;s DataFrames. You will use Pandas to import and inspect a variety of datasets, ranging from population data obtained from The World Bank to monthly stock data obtained via Yahoo! Finance. You will also practice building DataFrames from scratch, and become familiar with Pandas&#39; intrinsic data visualization capabilities.&quot;,&quot;number&quot;,1,&quot;^8&quot;,&quot;data-ingestion-inspection&quot;,&quot;nb_exercises&quot;,14,&quot;badge_completed_url&quot;,&quot;https://assets.datacamp.com/production/default/badges/missing.png&quot;,&quot;badge_uncompleted_url&quot;,&quot;https://assets.datacamp.com/production/default/badges/missing_unc.png&quot;,&quot;^;&quot;,&quot;04/02/2019&quot;,&quot;slides_link&quot;,&quot;https://s3.amazonaws.com/assets.datacamp.com/production/course_2357/slides/ch1_slides.pdf&quot;,&quot;free_preview&quot;,true,&quot;xp&quot;,1100],[&quot;^ &quot;,&quot;id&quot;,4260,&quot;^M&quot;,null,&quot;^1&quot;,&quot;Exploratory data analysis&quot;,&quot;^2&quot;,&quot;Having learned how to ingest and inspect your data, you will next explore it visually as well as quantitatively. This process, known as exploratory data analysis (EDA), is a crucial component of any data science project. Pandas has powerful methods that help with statistical and visual EDA. In this chapter, you will learn how and when to apply these techniques.&quot;,&quot;^N&quot;,2,&quot;^8&quot;,&quot;exploratory-data-analysis&quot;,&quot;^O&quot;,15,&quot;^P&quot;,&quot;https://assets.datacamp.com/production/default/badges/missing.png&quot;,&quot;^Q&quot;,&quot;https://assets.datacamp.com/production/default/badges/missing_unc.png&quot;,&quot;^;&quot;,&quot;13/11/2018&quot;,&quot;^R&quot;,&quot;https://s3.amazonaws.com/assets.datacamp.com/production/course_2357/slides/ch2_slides.pdf&quot;,&quot;^S&quot;,null,&quot;xp&quot;,1250],[&quot;^ &quot;,&quot;id&quot;,4261,&quot;^M&quot;,null,&quot;^1&quot;,&quot;Time series in pandas&quot;,&quot;^2&quot;,&quot;In this chapter, you will learn how to manipulate and visualize time series data using Pandas. You will become familiar with concepts such as upsampling, downsampling, and interpolation. You will practice using Pandas&#39; method chaining to efficiently filter your data and perform time series analyses. From stock prices to flight timings, time series data are found in a wide variety of domains and being able to effectively work with such data can be an invaluable skill.&quot;,&quot;^N&quot;,3,&quot;^8&quot;,&quot;time-series-in-pandas&quot;,&quot;^O&quot;,17,&quot;^P&quot;,&quot;https://assets.datacamp.com/production/default/badges/missing.png&quot;,&quot;^Q&quot;,&quot;https://assets.datacamp.com/production/default/badges/missing_unc.png&quot;,&quot;^;&quot;,&quot;08/01/2019&quot;,&quot;^R&quot;,&quot;https://s3.amazonaws.com/assets.datacamp.com/production/course_2357/slides/ch3_slides.pdf&quot;,&quot;^S&quot;,null,&quot;xp&quot;,1450],[&quot;^ &quot;,&quot;id&quot;,4284,&quot;^M&quot;,null,&quot;^1&quot;,&quot;Case Study - Sunlight in Austin&quot;,&quot;^2&quot;,&quot;Working with real-world weather and climate data, in this chapter you will bring together and apply all of the skills you have acquired in this course. You will use Pandas to manipulate the data into a form usable for analysis, and then systematically explore it using the techniques you learned in the prior chapters. Enjoy!&quot;,&quot;^N&quot;,4,&quot;^8&quot;,&quot;case-study-sunlight-in-austin&quot;,&quot;^O&quot;,16,&quot;^P&quot;,&quot;https://assets.datacamp.com/production/default/badges/missing.png&quot;,&quot;^Q&quot;,&quot;https://assets.datacamp.com/production/default/badges/missing_unc.png&quot;,&quot;^;&quot;,&quot;04/02/2019&quot;,&quot;^R&quot;,&quot;https://s3.amazonaws.com/assets.datacamp.com/production/course_2357/slides/ch4_slides.pdf&quot;,&quot;^S&quot;,null,&quot;xp&quot;,1350]]]]],&quot;chapter&quot;,[&quot;^0&quot;,[&quot;status&quot;,&quot;SUCCESS&quot;,&quot;data&quot;,[&quot;^ &quot;,&quot;id&quot;,4261,&quot;^M&quot;,null,&quot;^1&quot;,&quot;Time series in pandas&quot;,&quot;^2&quot;,&quot;In this chapter, you will learn how to manipulate and visualize time series data using Pandas. You will become familiar with concepts such as upsampling, downsampling, and interpolation. You will practice using Pandas&#39; method chaining to efficiently filter your data and perform time series analyses. From stock prices to flight timings, time series data are found in a wide variety of domains and being able to effectively work with such data can be an invaluable skill.&quot;,&quot;^N&quot;,3,&quot;^8&quot;,&quot;time-series-in-pandas&quot;,&quot;^O&quot;,17,&quot;^P&quot;,&quot;https://assets.datacamp.com/production/default/badges/missing.png&quot;,&quot;^Q&quot;,&quot;https://assets.datacamp.com/production/default/badges/missing_unc.png&quot;,&quot;^;&quot;,&quot;08/01/2019&quot;,&quot;^R&quot;,&quot;https://s3.amazonaws.com/assets.datacamp.com/production/course_2357/slides/ch3_slides.pdf&quot;,&quot;^S&quot;,null,&quot;xp&quot;,1450]]],&quot;exercises&quot;,[&quot;^0&quot;,[&quot;status&quot;,&quot;SUCCESS&quot;,&quot;data&quot;,[[&quot;^ &quot;,&quot;id&quot;,44351,&quot;^&gt;&quot;,&quot;VideoExercise&quot;,&quot;assignment&quot;,null,&quot;^1&quot;,&quot;Indexing pandas time series&quot;,&quot;sample_code&quot;,&quot;&quot;,&quot;instructions&quot;,null,&quot;^N&quot;,1,&quot;sct&quot;,&quot;&quot;,&quot;pre_exercise_code&quot;,&quot;&quot;,&quot;solution&quot;,&quot;&quot;,&quot;hint&quot;,null,&quot;attachments&quot;,null,&quot;xp&quot;,50,&quot;possible_answers&quot;,[],&quot;feedbacks&quot;,[],&quot;question&quot;,&quot;&quot;,&quot;video_link&quot;,null,&quot;video_hls&quot;,&quot;//videos.datacamp.com/transcoded/1639_pandas-1/v6/hls-ch3_1.master.m3u8&quot;,&quot;aspect_ratio&quot;,56.25,&quot;projector_key&quot;,&quot;course_1639_4c739c46fd495fbaf4f0a50286d6f0a0&quot;,&quot;language&quot;,&quot;python&quot;,&quot;randomNumber&quot;,0.9909757797839178,&quot;externalId&quot;,44351],[&quot;^ &quot;,&quot;id&quot;,46106,&quot;^&gt;&quot;,&quot;MultipleChoiceExercise&quot;,&quot;^T&quot;,&quot;&lt;p&gt;For this exercise, we have read in the same data file using three different approaches:&lt;/p&gt;\\n&lt;ul&gt;\\n&lt;li&gt;&lt;p&gt;&lt;code&gt;df1 = pd.read_csv(filename)&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;\\n&lt;li&gt;&lt;p&gt;&lt;code&gt;df2 = pd.read_csv(filename, parse_dates=[&#39;Date&#39;])&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;\\n&lt;li&gt;&lt;p&gt;&lt;code&gt;df3 = pd.read_csv(filename, index_col=&#39;Date&#39;, parse_dates=True)&lt;/code&gt;&lt;/p&gt;\\n&lt;p&gt;Use the &lt;code&gt;.head()&lt;/code&gt; and &lt;code&gt;.info()&lt;/code&gt; methods in the IPython Shell to inspect the DataFrames. Then, try to index each DataFrame with a datetime string. Which of the resulting DataFrames allows you to easily index and slice data by dates using, for example, &lt;code&gt;df1.loc[&#39;2010-Aug-01&#39;]&lt;/code&gt;?&lt;/p&gt;&lt;/li&gt;\\n&lt;/ul&gt;&quot;,&quot;^1&quot;,&quot;Reading and slicing times&quot;,&quot;^U&quot;,&quot;&quot;,&quot;^V&quot;,null,&quot;^N&quot;,2,&quot;sct&quot;,&quot;msg1 = \\&quot;Incorrect. Try running `df1.loc[&#39;2010-Aug-01&#39;]`. What happens?\\&quot; # df1 \\nmsg2 = \\&quot;Try using `df1.loc[&#39;2010-Aug-01&#39;]` and `df2.loc[&#39;2010-Aug-01&#39;]` in the IPython Shell to inspect the data.\\&quot; # df1 and df2\\nmsg3 = \\&quot;Try running `df2.loc[&#39;2010-Aug-01&#39;]` in the IPython Shell.\\&quot; # df2\\nmsg4 = \\&quot;Try out `df2.loc[&#39;2010-Aug-01&#39;]` and `df3.loc[&#39;2010-Aug-01&#39;]` in the IPython Shell to inspect the data.\\&quot; # df2 and df3\\n\\nEx().has_chosen(correct = 5,\\n                msgs = [msg1, msg2, msg3, msg4, &#39;Correct! This is why it is important to read in your data properly, especially when working with time series data.&#39;])&quot;,&quot;^W&quot;,&quot;import pandas as pd\\n\\nfile_name = \\&quot;/usr/local/share/datasets/weather_data_austin_2010.csv\\&quot;\\n\\ndf1 = pd.read_csv(file_name)\\ndf2 = pd.read_csv(file_name, parse_dates=[&#39;Date&#39;])\\ndf3 = pd.read_csv(file_name, index_col=&#39;Date&#39;, parse_dates=True)\\n\\ndel file_name&quot;,&quot;^X&quot;,&quot;&quot;,&quot;^Y&quot;,&quot;&lt;p&gt;Run the given &lt;code&gt;.loc[&#39;2010-Aug-01&#39;]&lt;/code&gt; method on all three DataFrames and inspect the results!&lt;/p&gt;&quot;,&quot;^Z&quot;,null,&quot;xp&quot;,50,&quot;^[&quot;,[&quot;&lt;code&gt;df1&lt;/code&gt;.&quot;,&quot;&lt;code&gt;df1&lt;/code&gt; and &lt;code&gt;df2&lt;/code&gt;.&quot;,&quot;&lt;code&gt;df2&lt;/code&gt;.&quot;,&quot;&lt;code&gt;df2&lt;/code&gt; and &lt;code&gt;df3&lt;/code&gt;.&quot;,&quot;[&lt;code&gt;df3&lt;/code&gt;.]&quot;],&quot;^10&quot;,[],&quot;^11&quot;,&quot;&quot;,&quot;^16&quot;,&quot;python&quot;,&quot;^17&quot;,0.9144603061430696,&quot;^18&quot;,46106],[&quot;^ &quot;,&quot;id&quot;,44352,&quot;^&gt;&quot;,&quot;NormalExercise&quot;,&quot;^T&quot;,&quot;&lt;p&gt;The pandas Index is a powerful way to handle time series data, so it is valuable to know how to build one yourself. Pandas provides the &lt;code&gt;pd.to_datetime()&lt;/code&gt; function for just this task. For example, if passed the list of strings &lt;code&gt;[&#39;2015-01-01 091234&#39;,&#39;2015-01-01 091234&#39;]&lt;/code&gt; and a &lt;code&gt;format&lt;/code&gt; specification variable, such as &lt;code&gt;format=&#39;%Y-%m-%d %H%M%S&lt;/code&gt;, pandas will parse the string into the proper datetime elements and build the datetime objects. &lt;/p&gt;\\n&lt;p&gt;In this exercise, a list of temperature data and a list of date strings has been pre-loaded for you as &lt;code&gt;temperature_list&lt;/code&gt; and &lt;code&gt;date_list&lt;/code&gt; respectively. \\nYour job is to use the &lt;code&gt;.to_datetime()&lt;/code&gt; method to build a DatetimeIndex out of the list of date strings, and to then use it along with the list of temperature data to build a pandas Series.&lt;/p&gt;&quot;,&quot;^1&quot;,&quot;Creating and using a DatetimeIndex&quot;,&quot;^U&quot;,&quot;# Prepare a format string: time_format\\ntime_format = ____\\n\\n# Convert date_list into a datetime object: my_datetimes\\nmy_datetimes = ____(____, ____=____)  \\n\\n# Construct a pandas Series using temperature_list and my_datetimes: time_series\\ntime_series = ____(temperature_list, ____=my_datetimes)&quot;,&quot;^V&quot;,&quot;&lt;ul&gt;\\n&lt;li&gt;Prepare a format string, &lt;code&gt;time_format&lt;/code&gt;, using &lt;code&gt;&#39;%Y-%m-%d %H:%M&#39;&lt;/code&gt; as the desired format.&lt;/li&gt;\\n&lt;li&gt;Convert &lt;code&gt;date_list&lt;/code&gt; into a &lt;code&gt;datetime&lt;/code&gt; object by using the &lt;code&gt;pd.to_datetime()&lt;/code&gt; function. Specify the format string you defined above and assign the result to &lt;code&gt;my_datetimes&lt;/code&gt;.&lt;/li&gt;\\n&lt;li&gt;Construct a pandas Series called &lt;code&gt;time_series&lt;/code&gt; using &lt;code&gt;pd.Series()&lt;/code&gt; with &lt;code&gt;temperature_list&lt;/code&gt; and &lt;code&gt;my_datetimes&lt;/code&gt;. Set the &lt;code&gt;index&lt;/code&gt; of the Series to be &lt;code&gt;my_datetimes&lt;/code&gt;.&lt;/li&gt;\\n&lt;/ul&gt;&quot;,&quot;^N&quot;,3,&quot;sct&quot;,&quot;Ex().check_correct(\\n\\tcheck_object(&#39;time_format&#39;).has_equal_value(),\\n  \\thas_equal_ast(code = \\&quot;&#39;%Y-%m-%d %H:%M&#39;\\&quot;, incorrect_msg = &#39;Did you use the correct time format as a character string to create `time_format`?&#39;)\\n)\\n\\nEx().check_correct(\\n\\tcheck_object(&#39;my_datetimes&#39;).has_equal_value(),\\n  \\tcheck_function(&#39;pandas.to_datetime&#39;, signature = sig_from_obj(&#39;pandas.to_datetime&#39;)).multi(\\n    \\tcheck_args(0).has_equal_value(),\\n      \\tcheck_args(&#39;format&#39;).has_equal_value()\\n    )\\n)\\n\\nEx().check_correct(\\n\\tcheck_object(&#39;time_series&#39;).has_equal_value(),\\n  \\tcheck_function(&#39;pandas.Series&#39;, signature = sig_from_obj(&#39;pandas.Series&#39;)).multi(\\n    \\tcheck_args(0).has_equal_value(),\\n      \\tcheck_args(&#39;index&#39;).has_equal_value()\\n    )\\n)\\n\\nsuccess_msg(\\&quot;Awesome job! Next to `DataFrames`, `Series` are another important object that `pandas` allows us to create, and they&#39;re very convenient for time series data.\\&quot;)&quot;,&quot;^W&quot;,&quot;import pandas as pd\\n\\n# Read in the data\\nfile_name = \\&quot;/usr/local/share/datasets/weather_data_austin_2010.csv\\&quot;\\ndf = pd.read_csv(file_name)\\n\\n# extract out the temperature and date solumns as lists\\ntemperature_list = list(df.Temperature)\\ndate_list = list(df.Date)\\n\\n# Clean up namespace before student sees it\\ndel df\\ndel file_name&quot;,&quot;^X&quot;,&quot;# Prepare a format string: time_format\\ntime_format=&#39;%Y-%m-%d %H:%M&#39;\\n\\n# Convert date_list into a datetime object: my_datetimes\\nmy_datetimes = pd.to_datetime(date_list, format=time_format)  \\n\\n# Construct a pandas Series using temperature_list and my_datetimes: time_series\\ntime_series = pd.Series(temperature_list, index=my_datetimes)&quot;,&quot;^Y&quot;,&quot;&lt;ul&gt;\\n&lt;li&gt;The desired format string here is &lt;code&gt;&#39;%Y-%m-%d %H:%M&#39;&lt;/code&gt;.&lt;/li&gt;\\n&lt;li&gt;You can create the &lt;code&gt;datetime&lt;/code&gt; object &lt;code&gt;my_datetimes&lt;/code&gt; by passing in &lt;code&gt;date_list&lt;/code&gt; to &lt;code&gt;pd.to_datetime()&lt;/code&gt; and specifying the keyword argument &lt;code&gt;format=time_format&lt;/code&gt;.&lt;/li&gt;\\n&lt;li&gt;When creating the Series with &lt;code&gt;pd.Series()&lt;/code&gt;, be sure to pass in &lt;code&gt;temperature_list&lt;/code&gt; as an argument and to also specify the &lt;code&gt;index&lt;/code&gt; parameter. Here, it should be &lt;code&gt;my_datetimes&lt;/code&gt;.&lt;/li&gt;\\n&lt;/ul&gt;&quot;,&quot;^Z&quot;,null,&quot;xp&quot;,100,&quot;^[&quot;,[],&quot;^10&quot;,[],&quot;^11&quot;,&quot;&quot;,&quot;^16&quot;,&quot;python&quot;,&quot;^17&quot;,0.9899993007503594,&quot;^18&quot;,44352],[&quot;^ &quot;,&quot;id&quot;,44353,&quot;^&gt;&quot;,&quot;NormalExercise&quot;,&quot;^T&quot;,&quot;&lt;p&gt;Pandas time series support \\&quot;partial string\\&quot; indexing. What this means is that even when passed only a portion of the datetime, such as the date but not the time, pandas is remarkably good at doing what one would expect. Pandas datetime indexing also supports a wide variety of commonly used datetime string formats, even when mixed. &lt;/p&gt;\\n&lt;p&gt;In this exercise, a time series that contains hourly weather data has been pre-loaded for you. This data was read using the &lt;code&gt;parse_dates=True&lt;/code&gt; option in &lt;code&gt;read_csv()&lt;/code&gt; with &lt;code&gt;index_col=\\&quot;Dates\\&quot;&lt;/code&gt; so that the Index is indeed a &lt;code&gt;DatetimeIndex&lt;/code&gt;. &lt;/p&gt;\\n&lt;p&gt;All data from the &lt;code&gt;&#39;Temperature&#39;&lt;/code&gt; column has been extracted into the variable &lt;code&gt;ts0&lt;/code&gt;. Your job is to use a variety of natural date strings to extract one or more values from &lt;code&gt;ts0&lt;/code&gt;.&lt;/p&gt;\\n&lt;p&gt;After you are done, you will have three new variables - &lt;code&gt;ts1&lt;/code&gt;, &lt;code&gt;ts2&lt;/code&gt;, and &lt;code&gt;ts3&lt;/code&gt;. You can slice these further to extract only the first and last entries of each. Try doing this after your submission for more practice.&lt;/p&gt;&quot;,&quot;^1&quot;,&quot;Partial string indexing and slicing&quot;,&quot;^U&quot;,&quot;# Extract the hour from 9pm to 10pm on &#39;2010-10-11&#39;: ts1\\nts1 = ts0.loc[&#39;2010-10-11 21:00:00&#39;:&#39;____&#39;]\\n\\n# Extract &#39;2010-07-04&#39; from ts0: ts2\\nts2 = ____\\n\\n# Extract data from &#39;2010-12-15&#39; to &#39;2010-12-31&#39;: ts3\\nts3 = ____\\n&quot;,&quot;^V&quot;,&quot;&lt;ul&gt;\\n&lt;li&gt;Extract data from &lt;code&gt;ts0&lt;/code&gt; for a single hour - the hour from 9pm to 10pm on &lt;code&gt;2010-10-11&lt;/code&gt;. Assign it to &lt;code&gt;ts1&lt;/code&gt;.&lt;/li&gt;\\n&lt;li&gt;Extract data from &lt;code&gt;ts0&lt;/code&gt; for a single day - &lt;code&gt;July 4th, 2010&lt;/code&gt; - and assign it to &lt;code&gt;ts2&lt;/code&gt;.&lt;/li&gt;\\n&lt;li&gt;Extract data from &lt;code&gt;ts0&lt;/code&gt; for the second half of December 2010 - &lt;code&gt;12/15/2010&lt;/code&gt; to &lt;code&gt;12/31/2010&lt;/code&gt;. Assign it to &lt;code&gt;ts3&lt;/code&gt;.&lt;/li&gt;\\n&lt;/ul&gt;&quot;,&quot;^N&quot;,4,&quot;sct&quot;,&quot;Ex().check_correct(\\n\\tcheck_object(&#39;ts1&#39;).has_equal_value(),\\n  \\thas_equal_ast(code = \\&quot;ts0.loc[&#39;2010-10-11 21:00:00&#39;:&#39;2010-10-11 22:00:00&#39;]\\&quot;, incorrect_msg = &#39;Be sure you\\\\&#39;re extracting info only on the hour from 21:00 to 22:00 on 2010-10-11.&#39;)\\n)\\n\\nEx().check_correct(\\n\\tcheck_object(&#39;ts2&#39;).has_equal_value(),\\n  \\thas_equal_ast(code = \\&quot;ts0.loc[&#39;2010-07-04&#39;]\\&quot;, incorrect_msg = &#39;Be sure you\\\\&#39;re extracting info only for the day of 2010-07-04.&#39;)\\n)\\n\\nEx().check_correct(\\n\\tcheck_object(&#39;ts3&#39;).has_equal_value(),\\n  \\thas_equal_ast(code = \\&quot;ts0.loc[&#39;2010-12-15&#39;:&#39;2010-12-31&#39;]\\&quot;, incorrect_msg = &#39;Be sure you\\\\&#39;re extracting info for only the days between 2010-12-15 and 2010-12-31.&#39;)\\n)\\n\\nsuccess_msg(\\&quot;Well done!\\&quot;)&quot;,&quot;^W&quot;,&quot;import pandas as pd\\nfile_name = \\&quot;/usr/local/share/datasets/weather_data_austin_2010.csv\\&quot;\\ndf = pd.read_csv(file_name, index_col=&#39;Date&#39;, parse_dates=True)\\n\\ndel file_name\\n# Extract the Temperature data from the DataFrame: ts0\\nts0 = df[&#39;Temperature&#39;]&quot;,&quot;^X&quot;,&quot;# Extract the hour from 9pm to 10pm on &#39;2010-10-11&#39;: ts1\\nts1 = ts0.loc[&#39;2010-10-11 21:00:00&#39;:&#39;2010-10-11 22:00:00&#39;]\\n\\n# Extract &#39;2010-07-04&#39; from ts0: ts2\\nts2 = ts0.loc[&#39;2010-07-04&#39;]\\n\\n# Extract data from &#39;2010-12-15&#39; to &#39;2010-12-31&#39;: ts3\\nts3 = ts0.loc[&#39;2010-12-15&#39;:&#39;2010-12-31&#39;]&quot;,&quot;^Y&quot;,&quot;&lt;ul&gt;\\n&lt;li&gt;You can use the &lt;code&gt;.loc[]&lt;/code&gt; method to extract the relevant values from &lt;code&gt;ts0&lt;/code&gt;. You will have to pass in the appropriate date string. &lt;/li&gt;\\n&lt;li&gt;To extract the hour from 5pm to 6pm on November 5th 2010, for instance, the string would be &lt;code&gt;&#39;2010-11-05 17:00:00&#39;&lt;/code&gt;. &lt;/li&gt;\\n&lt;li&gt;For just November 5th 2010 it would be &lt;code&gt;&#39;2010-11-05&#39;&lt;/code&gt;. &lt;/li&gt;\\n&lt;li&gt;For the time range from November 5th 2010 to November 12th 2010, the string would be &lt;code&gt;&#39;2010-11-05&#39;:&#39;2010-11-12&#39;&lt;/code&gt;.&lt;/li&gt;\\n&lt;/ul&gt;&quot;,&quot;^Z&quot;,null,&quot;xp&quot;,100,&quot;^[&quot;,[],&quot;^10&quot;,[],&quot;^11&quot;,&quot;&quot;,&quot;^16&quot;,&quot;python&quot;,&quot;^17&quot;,0.8569771315432377,&quot;^18&quot;,44353],[&quot;^ &quot;,&quot;id&quot;,44354,&quot;^&gt;&quot;,&quot;NormalExercise&quot;,&quot;^T&quot;,&quot;&lt;p&gt;Reindexing is useful in preparation for adding or otherwise combining two time series data sets. To reindex the data, we provide a new index and ask pandas to try and match the old data to the new index. If data is unavailable for one of the new index dates or times, you must tell pandas how to fill it in. Otherwise, pandas will fill with &lt;code&gt;NaN&lt;/code&gt; by default. &lt;/p&gt;\\n&lt;p&gt;In this exercise, two time series data sets containing daily data have been pre-loaded for you, each indexed by dates. The first, &lt;code&gt;ts1&lt;/code&gt;, includes weekends, but the second, &lt;code&gt;ts2&lt;/code&gt;, does not. The goal is to combine the two data sets in a sensible way. Your job is to reindex the second data set so that it has weekends as well, and then add it to the first. When you are done, it would be informative to inspect your results.&lt;/p&gt;&quot;,&quot;^1&quot;,&quot;Reindexing the Index&quot;,&quot;^U&quot;,&quot;# Reindex without fill method: ts3\\nts3 = ____\\n\\n# Reindex with fill method, using forward fill: ts4\\nts4 = ____\\n\\n# Combine ts1 + ts2: sum12\\nsum12 = ____\\n\\n# Combine ts1 + ts3: sum13\\nsum13 = ____\\n\\n# Combine ts1 + ts4: sum14\\nsum14 = ____&quot;,&quot;^V&quot;,&quot;&lt;ul&gt;\\n&lt;li&gt;Create a new time series &lt;code&gt;ts3&lt;/code&gt; by reindexing &lt;code&gt;ts2&lt;/code&gt; with the index of &lt;code&gt;ts1&lt;/code&gt;. To do this, call &lt;code&gt;.reindex()&lt;/code&gt; on &lt;code&gt;ts2&lt;/code&gt; and pass in the index of &lt;code&gt;ts1&lt;/code&gt; (&lt;code&gt;ts1.index&lt;/code&gt;).&lt;/li&gt;\\n&lt;li&gt;Create another new time series, &lt;code&gt;ts4&lt;/code&gt;, by calling the same &lt;code&gt;.reindex()&lt;/code&gt; as above, but also specifiying a fill method, using the keyword argument &lt;code&gt;method=\\&quot;ffill\\&quot;&lt;/code&gt; to forward-fill values.&lt;/li&gt;\\n&lt;li&gt;Add &lt;code&gt;ts1 + ts2&lt;/code&gt;. Assign the result to &lt;code&gt;sum12&lt;/code&gt;.&lt;/li&gt;\\n&lt;li&gt;Add &lt;code&gt;ts1 + ts3&lt;/code&gt;. Assign the result to &lt;code&gt;sum13&lt;/code&gt;.&lt;/li&gt;\\n&lt;li&gt;Add &lt;code&gt;ts1 + ts4&lt;/code&gt;, Assign the result to &lt;code&gt;sum14&lt;/code&gt;.&lt;/li&gt;\\n&lt;/ul&gt;&quot;,&quot;^N&quot;,5,&quot;sct&quot;,&quot;Ex().check_correct(\\n\\tcheck_object(\\&quot;ts3\\&quot;).has_equal_value(),\\n\\tcheck_function(\\&quot;ts2.reindex\\&quot;).check_args(0).has_equal_value()\\n)\\n\\nEx().check_correct(\\n\\tcheck_object(\\&quot;ts4\\&quot;).has_equal_value(),\\n\\tcheck_function(\\&quot;ts2.reindex\\&quot;).check_args(0).has_equal_value()\\n)\\n\\nEx().check_correct(\\n\\tcheck_object(\\&quot;sum12\\&quot;).has_equal_value(),\\n  \\tcheck_or(\\n    \\thas_equal_ast(code = &#39;ts1 + ts2&#39;, incorrect_msg = &#39;Did you add together `ts1` and `ts2` to create `sum12`?&#39;),\\n      \\thas_equal_ast(code = &#39;ts2 + ts1&#39;, incorrect_msg = &#39;Did you add together `ts1` and `ts2` to create `sum12`?&#39;)\\n    )\\n)\\n\\nEx().check_correct(\\n\\tcheck_object(\\&quot;sum13\\&quot;).has_equal_value(),\\n  \\tcheck_or(\\n    \\thas_equal_ast(code = &#39;ts1 + ts3&#39;, incorrect_msg = &#39;Did you add together `ts1` and `ts3` to create `sum13`?&#39;),\\n      \\thas_equal_ast(code = &#39;ts3 + ts1&#39;, incorrect_msg = &#39;Did you add together `ts1` and `ts3` to create `sum13`?&#39;)\\n    )\\n)\\n\\nEx().check_correct(\\n\\tcheck_object(\\&quot;sum14\\&quot;).has_equal_value(),\\n  \\tcheck_or(\\n    \\thas_equal_ast(code = &#39;ts1 + ts4&#39;, incorrect_msg = &#39;Did you add together `ts1` and `ts4` to create `sum14`?&#39;),\\n      \\thas_equal_ast(code = &#39;ts4 + ts1&#39;, incorrect_msg = &#39;Did you add together `ts1` and `ts4` to create `sum14`?&#39;)\\n    )\\n)\\n\\nsuccess_msg(\\&quot;Wonderful work! Understanding how indexing and reindexing works is a valuable skill.\\&quot;)&quot;,&quot;^W&quot;,&quot;import pandas as pd\\n\\n# Create Series that includes weekends\\ndates1 = pd.to_datetime([&#39;2016-07-01&#39;,\\n                         &#39;2016-07-02&#39;,&#39;2016-07-03&#39;,\\n                         &#39;2016-07-04&#39;,&#39;2016-07-05&#39;,&#39;2016-07-06&#39;,&#39;2016-07-07&#39;,&#39;2016-07-08&#39;,\\n                         &#39;2016-07-09&#39;,&#39;2016-07-10&#39;,\\n                         &#39;2016-07-11&#39;,&#39;2016-07-12&#39;,&#39;2016-07-13&#39;,&#39;2016-07-14&#39;,&#39;2016-07-15&#39;,\\n                         &#39;2016-07-16&#39;,&#39;2016-07-17&#39;])\\ndata1 = range(len(dates1))\\nts1 = pd.Series(data1, index=dates1)\\n\\n# Create Series that does NOT include weekends\\ndates2 = pd.to_datetime([&#39;2016-07-01&#39;,\\n                         &#39;2016-07-04&#39;,&#39;2016-07-05&#39;,&#39;2016-07-06&#39;,&#39;2016-07-07&#39;,&#39;2016-07-08&#39;,\\n                         &#39;2016-07-11&#39;,&#39;2016-07-12&#39;,&#39;2016-07-13&#39;,&#39;2016-07-14&#39;,&#39;2016-07-15&#39;])\\ndata2 = range(len(dates2))\\nts2 = pd.Series(data2, index=dates2)&quot;,&quot;^X&quot;,&quot;# Reindex without fill method: ts3\\nts3 = ts2.reindex(ts1.index)\\n\\n# Reindex with fill method, using forward fill: ts4\\nts4 = ts2.reindex(ts1.index, method=&#39;ffill&#39;)\\n\\n# Combine ts1 + ts2: sum12\\nsum12 = ts1 + ts2\\n\\n# Combine ts1 + ts3: sum13\\nsum13 = ts1 + ts3\\n\\n# Combine ts1 + ts4: sum14\\nsum14 = ts1 + ts4&quot;,&quot;^Y&quot;,&quot;&lt;ul&gt;\\n&lt;li&gt;&lt;code&gt;ts4 = ts2.reindex(ts1.index, method=&#39;ffill&#39;)&lt;/code&gt;&lt;/li&gt;\\n&lt;/ul&gt;&quot;,&quot;^Z&quot;,null,&quot;xp&quot;,100,&quot;^[&quot;,[],&quot;^10&quot;,[],&quot;^11&quot;,&quot;&quot;,&quot;^16&quot;,&quot;python&quot;,&quot;^17&quot;,0.6686954137114809,&quot;^18&quot;,44354],[&quot;^ &quot;,&quot;id&quot;,44355,&quot;^&gt;&quot;,&quot;VideoExercise&quot;,&quot;^T&quot;,null,&quot;^1&quot;,&quot;Resampling pandas time series&quot;,&quot;^U&quot;,&quot;&quot;,&quot;^V&quot;,null,&quot;^N&quot;,6,&quot;sct&quot;,&quot;&quot;,&quot;^W&quot;,&quot;&quot;,&quot;^X&quot;,&quot;&quot;,&quot;^Y&quot;,null,&quot;^Z&quot;,null,&quot;xp&quot;,50,&quot;^[&quot;,[],&quot;^10&quot;,[],&quot;^11&quot;,&quot;&quot;,&quot;^12&quot;,null,&quot;^13&quot;,&quot;//videos.datacamp.com/transcoded/1639_pandas-1/v3/hls-ch3_2.master.m3u8&quot;,&quot;^14&quot;,56.25,&quot;^15&quot;,&quot;course_1639_2668ea6284be6832ac78db0504762bae&quot;,&quot;^16&quot;,&quot;python&quot;,&quot;^17&quot;,0.7907269019091243,&quot;^18&quot;,44355],[&quot;^ &quot;,&quot;id&quot;,44356,&quot;^&gt;&quot;,&quot;NormalExercise&quot;,&quot;^T&quot;,&quot;&lt;p&gt;Pandas provides methods for resampling time series data. When downsampling or upsampling, the syntax is similar, but the methods called are different. Both use the concept of &#39;method chaining&#39; - &lt;code&gt;df.method1().method2().method3()&lt;/code&gt; - to direct the output from one method call to the input of the next, and so on, as a sequence of operations, one feeding into the next. &lt;/p&gt;\\n&lt;p&gt;For example, if you have hourly data, and just need daily data, pandas will not guess how to throw out the 23 of 24 points. You must specify this in the method. One approach, for instance, could be to take the mean, as in &lt;code&gt;df.resample(&#39;D&#39;).mean()&lt;/code&gt;. &lt;/p&gt;\\n&lt;p&gt;In this exercise, a data set containing hourly temperature data has been pre-loaded for you. Your job is to resample the data using a variety of aggregation methods to answer a few questions.&lt;/p&gt;&quot;,&quot;^1&quot;,&quot;Resampling and frequency&quot;,&quot;^U&quot;,&quot;# Downsample to 6 hour data and aggregate by mean: df1\\ndf1 = ____\\n\\n# Downsample to daily data and count the number of data points: df2\\ndf2 = ____&quot;,&quot;^V&quot;,&quot;&lt;ul&gt;\\n&lt;li&gt;Downsample the &lt;code&gt;&#39;Temperature&#39;&lt;/code&gt; column of &lt;code&gt;df&lt;/code&gt; to 6 hour data using &lt;code&gt;.resample(&#39;6h&#39;)&lt;/code&gt; and &lt;code&gt;.mean()&lt;/code&gt;. Assign the result to &lt;code&gt;df1&lt;/code&gt;.&lt;/li&gt;\\n&lt;li&gt;Downsample the &lt;code&gt;&#39;Temperature&#39;&lt;/code&gt; column of &lt;code&gt;df&lt;/code&gt; to daily data using &lt;code&gt;.resample(&#39;D&#39;)&lt;/code&gt; and then count the number of data points in each day with &lt;code&gt;.count()&lt;/code&gt;. Assign the result &lt;code&gt;df2&lt;/code&gt;.&lt;/li&gt;\\n&lt;/ul&gt;&quot;,&quot;^N&quot;,7,&quot;sct&quot;,&quot;Ex().check_correct(\\n\\tcheck_object(\\&quot;df1\\&quot;).has_equal_value(),\\n    has_equal_ast(\\&quot;Did you correctly downsample `&#39;Temperature&#39;` using `.resample(&#39;6h&#39;)` and `.mean()`?\\&quot;,\\n                           code=\\&quot;df[&#39;Temperature&#39;].resample(&#39;6h&#39;).mean()\\&quot;,\\n                           exact=False))\\n\\n\\nEx().check_correct(\\n  \\tcheck_object(\\&quot;df2\\&quot;).has_equal_value(),\\n    has_equal_ast(\\&quot;Did you correctly downsample `&#39;Temperature&#39;` using `.resample(&#39;D&#39;)` and `.count()`?\\&quot;,\\n                           code=\\&quot;df[&#39;Temperature&#39;].resample(&#39;D&#39;).count()\\&quot;,\\n                           exact=False))\\n\\nsuccess_msg(\\&quot;Excellent job! You&#39;ll get a lot more practice with resampling in the coming exercises!\\&quot;)&quot;,&quot;^W&quot;,&quot;import pandas as pd\\nfile_name = \\&quot;/usr/local/share/datasets/weather_data_austin_2010.csv\\&quot;\\ndf = pd.read_csv(file_name, index_col=&#39;Date&#39;, parse_dates=True)\\n\\ndel file_name&quot;,&quot;^X&quot;,&quot;# Downsample to 6 hour data and aggregate by mean: df1\\ndf1 = df[&#39;Temperature&#39;].resample(&#39;6h&#39;).mean()\\n\\n# Downsample to daily data and count the number of data points: df2\\ndf2 = df[&#39;Temperature&#39;].resample(&#39;D&#39;).count()&quot;,&quot;^Y&quot;,&quot;&lt;ul&gt;\\n&lt;li&gt;You can downsample a column to 6 hour data and aggregate the mean by chaining onto it the methods &lt;code&gt;.resample(&#39;6h&#39;).mean()&lt;/code&gt;. &lt;/li&gt;\\n&lt;li&gt;To downsample a column to daily data and aggregate the count, you can chain onto it the methods &lt;code&gt;.resample(&#39;D&#39;).count()&lt;/code&gt;.&lt;/li&gt;\\n&lt;/ul&gt;&quot;,&quot;^Z&quot;,null,&quot;xp&quot;,100,&quot;^[&quot;,[],&quot;^10&quot;,[],&quot;^11&quot;,&quot;&quot;,&quot;^16&quot;,&quot;python&quot;,&quot;^17&quot;,0.13850964168246005,&quot;^18&quot;,44356],[&quot;^ &quot;,&quot;id&quot;,46425,&quot;^&gt;&quot;,&quot;NormalExercise&quot;,&quot;^T&quot;,&quot;&lt;p&gt;With pandas, you can resample in different ways on different subsets of your data. For example, resampling different months of data with different aggregations. In this exercise, the data set containing hourly temperature data from the last exercise has been pre-loaded. &lt;/p&gt;\\n&lt;p&gt;Your job is to resample the data using a variety of aggregation methods. The DataFrame is available in the workspace as &lt;code&gt;df&lt;/code&gt;. You will be working with the &lt;code&gt;&#39;Temperature&#39;&lt;/code&gt; column.&lt;/p&gt;&quot;,&quot;^1&quot;,&quot;Separating and resampling&quot;,&quot;^U&quot;,&quot;# Extract temperature data for August: august\\naugust = ____\\n\\n# Downsample to obtain only the daily highest temperatures in August: august_highs\\naugust_highs = ____\\n\\n# Extract temperature data for February: february\\nfebruary = ____\\n\\n# Downsample to obtain the daily lowest temperatures in February: february_lows\\nfebruary_lows = ____&quot;,&quot;^V&quot;,&quot;&lt;ul&gt;\\n&lt;li&gt;Use partial string indexing to extract temperature data for August 2010 into &lt;code&gt;august&lt;/code&gt;.&lt;/li&gt;\\n&lt;li&gt;Use the temperature data for August and downsample to find the daily maximum temperatures. Store the result in &lt;code&gt;august_highs&lt;/code&gt;.&lt;/li&gt;\\n&lt;li&gt;Use partial string indexing to extract temperature data for February 2010 into &lt;code&gt;february&lt;/code&gt;.&lt;/li&gt;\\n&lt;li&gt;Use the temperature data for February and downsample to find the daily minimum temperatures. Store the result in &lt;code&gt;february_lows&lt;/code&gt;.&lt;/li&gt;\\n&lt;/ul&gt;&quot;,&quot;^N&quot;,8,&quot;sct&quot;,&quot;Ex().check_object(\\&quot;august\\&quot;).has_equal_value(&#39;Did you select the `Temperature` column for only `2010-August` from `df`?&#39;)\\n\\nEx().check_correct(\\n\\tcheck_object(\\&quot;august_highs\\&quot;).has_equal_value(),\\n  \\thas_equal_ast(code = &#39;august.resample(\\\\&#39;D\\\\&#39;).max()&#39;, incorrect_msg = \\&quot;Did you resample `august` correctly using `.resample(&#39;D&#39;)` and `.max()`?\\&quot;)\\n)\\n\\nEx().check_object(\\&quot;february\\&quot;).has_equal_value(&#39;Did you select the `Temperature` column for only `2010-Feb` from `df`?&#39;)\\n\\nEx().check_correct(\\n\\tcheck_object(\\&quot;february_lows\\&quot;).has_equal_value(),\\n  \\thas_equal_ast(code = &#39;february.resample(\\\\&#39;D\\\\&#39;).min()&#39;, incorrect_msg = \\&quot;Did you resample `february` correctly using `.resample(&#39;D&#39;)` and `.min()`?\\&quot;)\\n)\\n\\nsuccess_msg(\\&quot;Great work!\\&quot;)&quot;,&quot;^W&quot;,&quot;import pandas as pd\\nfile_name = \\&quot;/usr/local/share/datasets/weather_data_austin_2010.csv\\&quot;\\ndf = pd.read_csv(file_name, index_col=&#39;Date&#39;, parse_dates=True)\\n\\ndel file_name&quot;,&quot;^X&quot;,&quot;# Extract temperature data for August: august\\naugust = df[&#39;Temperature&#39;][&#39;2010-August&#39;]\\n\\n# Downsample to obtain only the daily highest temperatures in August: august_highs\\naugust_highs = august.resample(&#39;D&#39;).max()\\n\\n# Extract temperature data for February: february\\nfebruary = df[&#39;Temperature&#39;][&#39;2010-Feb&#39;]\\n\\n# Downsample to obtain the daily lowest temperatures in February: february_lows\\nfebruary_lows = february.resample(&#39;D&#39;).min()&quot;,&quot;^Y&quot;,&quot;&lt;ul&gt;\\n&lt;li&gt;To extract September 2010 from &lt;code&gt;df&lt;/code&gt; using partial string indexing, you can use &lt;code&gt;df[&#39;Temperature&#39;][&#39;2010-September&#39;]&lt;/code&gt;. Do this for August 2010.&lt;/li&gt;\\n&lt;li&gt;You need to downsample to daily data, so the relevant method is &lt;code&gt;.resample(&#39;D&#39;)&lt;/code&gt;. Then, you want the maximum daily temperaturs, so you will also have to chain &lt;code&gt;.max()&lt;/code&gt; onto &lt;code&gt;.resample(&#39;D&#39;)&lt;/code&gt;.&lt;/li&gt;\\n&lt;li&gt;Follow the approach you used to extract the August 2010 data from &lt;code&gt;df[&#39;Temperature&#39;]&lt;/code&gt; to extract the data for February 2010.&lt;/li&gt;\\n&lt;li&gt;As before, you need to downsample to daily data, so you need to use &lt;code&gt;.resample(&#39;D&#39;)&lt;/code&gt; on the February data. Since you now want the minimum daily temperatures, you will have to chain &lt;code&gt;.min()&lt;/code&gt; to &lt;code&gt;.resample(&#39;D&#39;)&lt;/code&gt;.&lt;/li&gt;\\n&lt;/ul&gt;&quot;,&quot;^Z&quot;,null,&quot;xp&quot;,100,&quot;^[&quot;,[],&quot;^10&quot;,[],&quot;^11&quot;,&quot;&quot;,&quot;^16&quot;,&quot;python&quot;,&quot;^17&quot;,0.7088183603186637,&quot;^18&quot;,46425],[&quot;^ &quot;,&quot;id&quot;,44357,&quot;^&gt;&quot;,&quot;NormalExercise&quot;,&quot;^T&quot;,&quot;&lt;p&gt;In this exercise, some hourly weather data is pre-loaded for you. You will continue to practice resampling, this time using rolling means.&lt;/p&gt;\\n&lt;p&gt;Rolling means (or moving averages) are generally used to smooth out short-term fluctuations in time series data and highlight long-term trends. You can read more about them &lt;a href=\\&quot;https://en.wikipedia.org/wiki/Moving_average\\&quot;&gt;here&lt;/a&gt;.  &lt;/p&gt;\\n&lt;p&gt;To use the &lt;code&gt;.rolling()&lt;/code&gt; method, you must always use method chaining, first calling &lt;code&gt;.rolling()&lt;/code&gt; and then chaining an aggregation method after it. For example, with a Series &lt;code&gt;hourly_data&lt;/code&gt;, &lt;code&gt;hourly_data.rolling(window=24).mean()&lt;/code&gt; would compute new values for each hourly point, based on a 24-hour window stretching out &lt;strong&gt;behind&lt;/strong&gt; each point. The frequency of the output data is the same: it is still hourly. Such an operation is useful for smoothing time series data. &lt;/p&gt;\\n&lt;p&gt;Your job is to resample the data using the combination of &lt;code&gt;.rolling()&lt;/code&gt; and &lt;code&gt;.mean()&lt;/code&gt;. You will work with the same DataFrame &lt;code&gt;df&lt;/code&gt; from the previous exercise.&lt;/p&gt;&quot;,&quot;^1&quot;,&quot;Rolling mean and frequency&quot;,&quot;^U&quot;,&quot;# Extract data from 2010-Aug-01 to 2010-Aug-15: unsmoothed\\nunsmoothed = df[&#39;Temperature&#39;][____:____]\\n\\n# Apply a rolling mean with a 24 hour window: smoothed\\nsmoothed = ____\\n\\n# Create a new DataFrame with columns smoothed and unsmoothed: august\\naugust = pd.DataFrame({&#39;smoothed&#39;:____, &#39;unsmoothed&#39;:____})\\n\\n# Plot both smoothed and unsmoothed data using august.plot().\\n____\\nplt.show()&quot;,&quot;^V&quot;,&quot;&lt;ul&gt;\\n&lt;li&gt;Use partial string indexing to extract temperature data from August 1 2010 to August 15 2010. Assign to &lt;code&gt;unsmoothed&lt;/code&gt;.&lt;/li&gt;\\n&lt;li&gt;Use &lt;code&gt;.rolling()&lt;/code&gt; with a 24 hour window to smooth the mean temperature data. Assign the result to &lt;code&gt;smoothed&lt;/code&gt;.&lt;/li&gt;\\n&lt;li&gt;Use a dictionary to create a new DataFrame &lt;code&gt;august&lt;/code&gt; with the time series &lt;code&gt;smoothed&lt;/code&gt; and &lt;code&gt;unsmoothed&lt;/code&gt; as columns.&lt;/li&gt;\\n&lt;li&gt;Plot both the columns of &lt;code&gt;august&lt;/code&gt; as line plots using the &lt;code&gt;.plot()&lt;/code&gt; method.&lt;/li&gt;\\n&lt;/ul&gt;&quot;,&quot;^N&quot;,9,&quot;sct&quot;,&quot;Ex().check_object(\\&quot;unsmoothed\\&quot;).has_equal_value(\\&quot;The contents of `unsmoothed` are incorrect. Did you correctly extract `&#39;2010-Aug-01&#39;:&#39;2010-Aug-15&#39;` from `df[&#39;Temperature&#39;]`?\\&quot;)\\n\\nEx().check_correct(\\n\\tcheck_object(\\&quot;smoothed\\&quot;).has_equal_value(),\\n  \\thas_equal_ast(code = &#39;unsmoothed.rolling(window=24).mean()&#39;, incorrect_msg = \\&quot;Did you apply a rolling mean to `unsmoothed` using `.rolling(window=24)` and `.mean()`?\\&quot;)\\n)\\n\\nEx().check_correct(\\n\\tcheck_object(\\&quot;august\\&quot;).has_equal_value(),\\n    multi(\\n    \\tcheck_function(\\&quot;pandas.DataFrame\\&quot;),\\n        has_equal_ast(code = \\&quot;{&#39;smoothed&#39;:smoothed, &#39;unsmoothed&#39;:unsmoothed}\\&quot;, incorrect_msg = \\&quot;Did you create the columns `&#39;smoothed&#39;` and `&#39;unsmoothed&#39;` using `smoothed` and `unsmoothed` in a dictionary?\\&quot;)\\n    )\\n)\\n\\nEx().check_function(\\&quot;august.plot\\&quot;)\\nEx().check_function(\\&quot;matplotlib.pyplot.show\\&quot;)\\n\\nsuccess_msg(\\&quot;Well done!\\&quot;)&quot;,&quot;^W&quot;,&quot;import pandas as pd\\nfile_name = \\&quot;/usr/local/share/datasets/weather_data_austin_2010.csv\\&quot;\\ndf = pd.read_csv(file_name, index_col=&#39;Date&#39;, parse_dates=True)\\ndel file_name\\nimport matplotlib.pyplot as plt&quot;,&quot;^X&quot;,&quot;# Extract data from 2010-Aug-01 to 2010-Aug-15: unsmoothed\\nunsmoothed = df[&#39;Temperature&#39;][&#39;2010-Aug-01&#39;:&#39;2010-Aug-15&#39;]\\n\\n# Apply a rolling mean with a 24 hour window: smoothed\\nsmoothed = unsmoothed.rolling(window=24).mean()\\n\\n# Create a new DataFrame with columns smoothed and unsmoothed: august\\naugust = pd.DataFrame({&#39;smoothed&#39;:smoothed, &#39;unsmoothed&#39;:unsmoothed})\\n\\n# Plot both smoothed and unsmoothed data using august.plot().\\naugust.plot()\\nplt.show()&quot;,&quot;^Y&quot;,&quot;&lt;ul&gt;\\n&lt;li&gt;You can extract the appropriate temperature data by passing in &lt;code&gt;&#39;2010-Aug-01&#39;&lt;/code&gt; and &lt;code&gt;&#39;2010-Aug-15&#39;&lt;/code&gt; separated by the &lt;code&gt;:&lt;/code&gt;.&lt;/li&gt;\\n&lt;li&gt;Using method chaining, you can chain &lt;code&gt;.rolling()&lt;/code&gt; onto &lt;code&gt;unsmoothed&lt;/code&gt; using &lt;code&gt;unsmoothed.rolling()&lt;/code&gt;. Inside &lt;code&gt;.rolling()&lt;/code&gt;, you will have to specify &lt;code&gt;window=24&lt;/code&gt;, and then chain &lt;code&gt;.mean()&lt;/code&gt; onto &lt;code&gt;unsmoothed.rolling()&lt;/code&gt;.&lt;/li&gt;\\n&lt;li&gt;You can use the &lt;code&gt;pd.DataFrame()&lt;/code&gt; function and pass in a dictionary with keys &lt;code&gt;&#39;smoothed&#39;&lt;/code&gt; and &lt;code&gt;&#39;unsmoothed&#39;&lt;/code&gt; and values &lt;code&gt;smoothed&lt;/code&gt; and &lt;code&gt;unsmoothed&lt;/code&gt;.&lt;/li&gt;\\n&lt;li&gt;You can plot &lt;code&gt;august&lt;/code&gt; using &lt;code&gt;august.plot()&lt;/code&gt;.&lt;/li&gt;\\n&lt;/ul&gt;&quot;,&quot;^Z&quot;,null,&quot;xp&quot;,100,&quot;^[&quot;,[],&quot;^10&quot;,[],&quot;^11&quot;,&quot;&quot;,&quot;^16&quot;,&quot;python&quot;,&quot;^17&quot;,0.05604666634510802,&quot;^18&quot;,44357],[&quot;^ &quot;,&quot;id&quot;,46426,&quot;^&gt;&quot;,&quot;NormalExercise&quot;,&quot;^T&quot;,&quot;&lt;p&gt;As of pandas version 0.18.0, the interface for applying rolling transformations to time series has become more consistent and flexible, and feels somewhat like a &lt;code&gt;groupby&lt;/code&gt; (If you do not know what a &lt;code&gt;groupby&lt;/code&gt; is, don&#39;t worry, you will learn about it in the next course!). &lt;/p&gt;\\n&lt;p&gt;You can now flexibly chain together resampling and rolling operations. In this exercise, the same weather data from the previous exercises has been pre-loaded for you. Your job is to extract one month of data, resample to find the daily high temperatures, and then use a rolling and aggregation operation to smooth the data.&lt;/p&gt;&quot;,&quot;^1&quot;,&quot;Resample and roll with it&quot;,&quot;^U&quot;,&quot;# Extract the August 2010 data: august\\naugust = df[&#39;Temperature&#39;][____]\\n\\n# Resample to daily data, aggregating by max: daily_highs\\ndaily_highs = ____\\n\\n# Use a rolling 7-day window with method chaining to smooth the daily high temperatures in August\\ndaily_highs_smoothed = ____\\nprint(____)&quot;,&quot;^V&quot;,&quot;&lt;ul&gt;\\n&lt;li&gt;Use partial string indexing to extract August 2010 temperature data, and assign to &lt;code&gt;august&lt;/code&gt;.&lt;/li&gt;\\n&lt;li&gt;Resample to daily frequency, saving the maximum daily temperatures, and assign the result to &lt;code&gt;daily_highs&lt;/code&gt;.&lt;/li&gt;\\n&lt;li&gt;As part of one long method chain, repeat the above resampling (or you can re-use &lt;code&gt;daily_highs&lt;/code&gt;) and then combine it with &lt;code&gt;.rolling()&lt;/code&gt; to apply a 7 day &lt;code&gt;.mean()&lt;/code&gt; (with &lt;code&gt;window=7&lt;/code&gt; inside &lt;code&gt;.rolling()&lt;/code&gt;) so as to smooth the daily highs. Assign the result to &lt;code&gt;daily_highs_smoothed&lt;/code&gt; and print the result.&lt;/li&gt;\\n&lt;/ul&gt;&quot;,&quot;^N&quot;,10,&quot;sct&quot;,&quot;Ex().check_object(\\&quot;august\\&quot;).has_equal_value(&#39;Did you select the `Temperature` column for only `2010-August` from `df`?&#39;)\\n\\nEx().check_correct(\\n\\tcheck_object(&#39;daily_highs&#39;).has_equal_value(),\\n  \\thas_equal_ast(code = &#39;august.resample(\\\\&#39;D\\\\&#39;).max()&#39;, incorrect_msg = \\&quot;Did you resample `august` by day (`&#39;D&#39;`) and call `.max()` to create `daily_highs`?\\&quot;)\\n)\\n\\nEx().check_correct(\\n\\tcheck_object(&#39;daily_highs_smoothed&#39;).has_equal_value(),\\n  \\thas_equal_ast(code = &#39;august.resample(\\\\&#39;D\\\\&#39;).max().rolling(window=7).mean()&#39;, incorrect_msg = \\&quot;Did you resample `august` by day (`&#39;D&#39;`), call `.max()`, create a rolling window of 7 days, and call `.mean()` to create `daily_highs_smoothed`?\\&quot;)\\n)\\n\\nEx().check_function(\\&quot;print\\&quot;).check_args(0).has_equal_value()\\n\\nsuccess_msg(\\&quot;Fantastic!\\&quot;)&quot;,&quot;^W&quot;,&quot;import pandas as pd\\nfile_name = \\&quot;/usr/local/share/datasets/weather_data_austin_2010.csv\\&quot;\\ndf = pd.read_csv(file_name, index_col=&#39;Date&#39;, parse_dates=True)\\n\\ndel file_name\\n&quot;,&quot;^X&quot;,&quot;# Extract the August 2010 data: august\\naugust = df[&#39;Temperature&#39;][&#39;2010-Aug&#39;]\\n\\n# Resample to daily data, aggregating by max: daily_highs\\ndaily_highs = august.resample(&#39;D&#39;).max()\\n\\n# Use a rolling 7-day window with method chaining to smooth the daily high temperatures in August\\ndaily_highs_smoothed = august.resample(&#39;D&#39;).max().rolling(window=7).mean()\\nprint(daily_highs_smoothed)&quot;,&quot;^Y&quot;,&quot;&lt;ul&gt;\\n&lt;li&gt;You can extract the temperature for October 2010 using &lt;code&gt;df[&#39;Temperature&#39;][&#39;2010-Oct&#39;]&lt;/code&gt;. Follow this template to extract the August 2010 data.&lt;/li&gt;\\n&lt;li&gt;To downsample to daily frequency and take the maximum daily temperature, you will have to chain together &lt;code&gt;.resample(&#39;D&#39;)&lt;/code&gt; and &lt;code&gt;.max()&lt;/code&gt;.&lt;/li&gt;\\n&lt;li&gt;Build from the above downsampling code to chain onto it &lt;code&gt;.rolling()&lt;/code&gt; and &lt;code&gt;.mean()&lt;/code&gt;. Inside &lt;code&gt;.rolling()&lt;/code&gt;, specify &lt;code&gt;window=7&lt;/code&gt;.&lt;/li&gt;\\n&lt;li&gt;Print &lt;code&gt;daily_highs_smoothed&lt;/code&gt;.&lt;/li&gt;\\n&lt;/ul&gt;&quot;,&quot;^Z&quot;,null,&quot;xp&quot;,100,&quot;^[&quot;,[],&quot;^10&quot;,[],&quot;^11&quot;,&quot;&quot;,&quot;^16&quot;,&quot;python&quot;,&quot;^17&quot;,0.05369142281268635,&quot;^18&quot;,46426],[&quot;^ &quot;,&quot;id&quot;,44359,&quot;^&gt;&quot;,&quot;VideoExercise&quot;,&quot;^T&quot;,null,&quot;^1&quot;,&quot;Manipulating pandas time series&quot;,&quot;^U&quot;,&quot;&quot;,&quot;^V&quot;,null,&quot;^N&quot;,11,&quot;sct&quot;,&quot;&quot;,&quot;^W&quot;,&quot;&quot;,&quot;^X&quot;,&quot;&quot;,&quot;^Y&quot;,null,&quot;^Z&quot;,null,&quot;xp&quot;,50,&quot;^[&quot;,[],&quot;^10&quot;,[],&quot;^11&quot;,&quot;&quot;,&quot;^12&quot;,null,&quot;^13&quot;,&quot;//videos.datacamp.com/transcoded/1639_pandas-1/v2/hls-ch3_3.master.m3u8&quot;,&quot;^14&quot;,56.25,&quot;^15&quot;,&quot;course_1639_79c11eb139ae230bf613e743dcc60ed8&quot;,&quot;^16&quot;,&quot;python&quot;,&quot;^17&quot;,0.14588042868998619,&quot;^18&quot;,44359],[&quot;^ &quot;,&quot;id&quot;,44360,&quot;^&gt;&quot;,&quot;NormalExercise&quot;,&quot;^T&quot;,&quot;&lt;p&gt;We&#39;ve seen that pandas supports method chaining. This technique can be very powerful when cleaning and filtering data. &lt;/p&gt;\\n&lt;p&gt;In this exercise, a DataFrame containing flight departure data for a single airline and a single airport for the month of July 2015 has been pre-loaded. Your job is to use &lt;code&gt;.str()&lt;/code&gt; filtering and method chaining to generate summary statistics on flight delays each day to Dallas.&lt;/p&gt;&quot;,&quot;^1&quot;,&quot;Method chaining and filtering&quot;,&quot;^U&quot;,&quot;# Strip extra whitespace from the column names: df.columns\\ndf.columns = ____\\n\\n# Extract data for which the destination airport is Dallas: dallas\\ndallas = df[&#39;Destination Airport&#39;].____.____(____)\\n\\n# Compute the total number of Dallas departures each day: daily_departures\\ndaily_departures = ____\\n\\n# Generate the summary statistics for daily Dallas departures: stats\\nstats = ____&quot;,&quot;^V&quot;,&quot;&lt;ul&gt;\\n&lt;li&gt;Use &lt;code&gt;.str.strip()&lt;/code&gt; to strip extra whitespace from &lt;code&gt;df.columns&lt;/code&gt;. Assign the result back to &lt;code&gt;df.columns&lt;/code&gt;.&lt;/li&gt;\\n&lt;li&gt;In the &lt;code&gt;&#39;Destination Airport&#39;&lt;/code&gt; column, extract all entries where Dallas (&lt;code&gt;&#39;DAL&#39;&lt;/code&gt;) is the destination airport. Use &lt;code&gt;.str.contains(&#39;DAL&#39;)&lt;/code&gt; for this and store the result in &lt;code&gt;dallas&lt;/code&gt;.&lt;/li&gt;\\n&lt;li&gt;Resample &lt;code&gt;dallas&lt;/code&gt; such that you get the total number of departures each day. Store the result in &lt;code&gt;daily_departures&lt;/code&gt;. &lt;/li&gt;\\n&lt;li&gt;Generate summary statistics for daily Dallas departures using &lt;code&gt;.describe()&lt;/code&gt;. Store the result in &lt;code&gt;stats&lt;/code&gt;.&lt;/li&gt;\\n&lt;/ul&gt;&quot;,&quot;^N&quot;,12,&quot;sct&quot;,&quot;Ex().check_correct(\\n\\tcheck_object(\\&quot;df\\&quot;).has_equal_value(),\\n  \\tcheck_function(\\&quot;df.columns.str.strip\\&quot;)\\n)\\n\\nEx().check_correct(\\n\\tcheck_object(&#39;dallas&#39;).has_equal_value(),\\n\\thas_equal_ast(\\&quot;Did you correctly extract the `&#39;DAL&#39;` entries in the `&#39;Destination Airport&#39;` column of `df`?\\&quot;,\\n                   code=\\&quot;df[&#39;Destination Airport&#39;].str.contains(&#39;DAL&#39;)\\&quot;,\\n                   exact=False)  \\n)\\n         \\nEx().check_correct(\\n\\tcheck_object(\\&quot;daily_departures\\&quot;).has_equal_value(),\\n    has_equal_ast(code = &#39;dallas.resample(\\\\&#39;D\\\\&#39;).sum()&#39;, incorrect_msg = &#39;Did you resample `dallas` by days and call `.sum()`?&#39;)\\n)    \\n\\nEx().check_correct(\\n\\tcheck_object(\\&quot;stats\\&quot;).has_equal_value(),\\n  \\tcheck_function(\\&quot;daily_departures.describe\\&quot;)\\n)\\n\\nsuccess_msg(\\&quot;Great work! You&#39;ll return to this dataset later in this chapter.\\&quot;)&quot;,&quot;^W&quot;,&quot;import pandas as pd\\n# Data file obtained as CSV from http://apps.bts.gov/xml/ontimesummarystatistics/src/dstat/OntimeSummaryDepatures.xml\\nfile_name= \\&quot;/usr/local/share/datasets/austin_airport_departure_data_2015_july.csv\\&quot;\\ndf = pd.read_csv(file_name, \\n                 skiprows=range(0,15), \\n                 parse_dates=True, \\n                 index_col=&#39;Date (MM/DD/YYYY)&#39;)\\ndel file_name&quot;,&quot;^X&quot;,&quot;# Strip extra whitespace from the column names: df.columns\\ndf.columns = df.columns.str.strip()\\n\\n# Extract data for which the destination airport is Dallas: dallas\\ndallas = df[&#39;Destination Airport&#39;].str.contains(&#39;DAL&#39;)\\n\\n# Compute the total number of Dallas departures each day: daily_departures\\ndaily_departures = dallas.resample(&#39;D&#39;).sum()\\n\\n# Generate the summary statistics for daily Dallas departures: stats\\nstats = daily_departures.describe()&quot;,&quot;^Y&quot;,&quot;&lt;ul&gt;\\n&lt;li&gt;Use &lt;code&gt;df.columns.str.strip()&lt;/code&gt; to strip extra whitespace from the column names. &lt;/li&gt;\\n&lt;li&gt;You will have to use &lt;code&gt;.str.contains(&#39;DAL&#39;)&lt;/code&gt; on &lt;code&gt;df[&#39;Destination Airport&#39;]&lt;/code&gt; to extract all entries where the Dallas is the destination airport.&lt;/li&gt;\\n&lt;li&gt;To resample &lt;code&gt;dallas&lt;/code&gt; by day and get the total number of departures, you will have to first use &lt;code&gt;.resample()&lt;/code&gt; with &lt;code&gt;&#39;D&#39;&lt;/code&gt; and then chain &lt;code&gt;.sum()&lt;/code&gt; to it.&lt;/li&gt;\\n&lt;li&gt;Use &lt;code&gt;resample(&#39;D&#39;).sum()&lt;/code&gt; to get to total number of Dallas departures each day.&lt;/li&gt;\\n&lt;li&gt;Use the &lt;code&gt;.describe()&lt;/code&gt; method on &lt;code&gt;daily_departures&lt;/code&gt; to generate summary statistics.&lt;/li&gt;\\n&lt;/ul&gt;&quot;,&quot;^Z&quot;,null,&quot;xp&quot;,100,&quot;^[&quot;,[],&quot;^10&quot;,[],&quot;^11&quot;,&quot;&quot;,&quot;^16&quot;,&quot;python&quot;,&quot;^17&quot;,0.7368318329583405,&quot;^18&quot;,44360],[&quot;^ &quot;,&quot;id&quot;,44361,&quot;^&gt;&quot;,&quot;NormalExercise&quot;,&quot;^T&quot;,&quot;&lt;p&gt;One common application of interpolation in data analysis is to fill in missing data. &lt;/p&gt;\\n&lt;p&gt;In this exercise, noisy measured data that has some dropped or otherwise missing values has been loaded. The goal is to compare two time series, and then look at summary statistics of the differences. The problem is that one of the data sets is missing data at some of the times. The pre-loaded data &lt;code&gt;ts1&lt;/code&gt; has value for all times, yet the data set &lt;code&gt;ts2&lt;/code&gt; does not: it is missing data for the weekends. &lt;/p&gt;\\n&lt;p&gt;Your job is to first interpolate to fill in the data for all days. Then, compute the differences between the two data sets, now that they both have full support for all times. Finally, generate the summary statistics that describe the distribution of differences.&lt;/p&gt;&quot;,&quot;^1&quot;,&quot;Missing values and interpolation&quot;,&quot;^U&quot;,&quot;# Reset the index of ts2 to ts1, and then use linear interpolation to fill in the NaNs: ts2_interp\\nts2_interp = ____\\n\\n# Compute the absolute difference of ts1 and ts2_interp: differences \\ndifferences = ____\\n\\n# Generate and print summary statistics of the differences\\nprint(____)&quot;,&quot;^V&quot;,&quot;&lt;ul&gt;\\n&lt;li&gt;Replace the index of &lt;code&gt;ts2&lt;/code&gt; with that of &lt;code&gt;ts1&lt;/code&gt;, and then fill in the missing values of &lt;code&gt;ts2&lt;/code&gt; by using &lt;code&gt;.interpolate(how=&#39;linear&#39;)&lt;/code&gt;. Save the result as &lt;code&gt;ts2_interp&lt;/code&gt;.&lt;/li&gt;\\n&lt;li&gt;Compute the difference between &lt;code&gt;ts1&lt;/code&gt; and &lt;code&gt;ts2_interp&lt;/code&gt;. Take the absolute value of the difference with &lt;code&gt;np.abs()&lt;/code&gt;, and assign the result to &lt;code&gt;differences&lt;/code&gt;.&lt;/li&gt;\\n&lt;li&gt;Generate and print summary statistics of the &lt;code&gt;differences&lt;/code&gt; with &lt;code&gt;.describe()&lt;/code&gt; and &lt;code&gt;print()&lt;/code&gt;.&lt;/li&gt;\\n&lt;/ul&gt;&quot;,&quot;^N&quot;,13,&quot;sct&quot;,&quot;Ex().check_correct(\\n  \\tcheck_object(&#39;ts2_interp&#39;).has_equal_value(),\\n   \\thas_equal_ast(code = &#39;ts2.reindex(ts1.index).interpolate(how=\\\\&#39;linear\\\\&#39;)&#39;, incorrect_msg = &#39;Did you reindex `ts2` using the index from `ts1`, then interpolate linearly to create `ts2`?&#39;)\\n)\\n\\nEx().check_correct(\\n\\tcheck_object(\\&quot;differences\\&quot;).has_equal_value(),\\n  \\tcheck_function(\\&quot;numpy.abs\\&quot;, signature = sig_from_obj(&#39;numpy.abs&#39;)) # order of difference doesn&#39;t matter\\n)\\n\\nEx().check_function(\\&quot;print\\&quot;).check_args(0).has_equal_value()\\n\\nsuccess_msg(\\&quot;Well done!\\&quot;)&quot;,&quot;^W&quot;,&quot;import numpy as np\\nimport pandas as pd\\n\\n# Create Series that includes weekends\\ndates1 = pd.to_datetime([&#39;2016-07-01&#39;,\\n                         &#39;2016-07-02&#39;,&#39;2016-07-03&#39;,\\n                         &#39;2016-07-04&#39;,&#39;2016-07-05&#39;,&#39;2016-07-06&#39;,&#39;2016-07-07&#39;,&#39;2016-07-08&#39;,\\n                         &#39;2016-07-09&#39;,&#39;2016-07-10&#39;,\\n                         &#39;2016-07-11&#39;,&#39;2016-07-12&#39;,&#39;2016-07-13&#39;,&#39;2016-07-14&#39;,&#39;2016-07-15&#39;,\\n                         &#39;2016-07-16&#39;,&#39;2016-07-17&#39;])\\ndata1 = range(len(dates1))\\nts1 = pd.Series(data1, index=dates1)\\n\\n# Create Series that does NOT include weekends\\ndates2 = pd.to_datetime([&#39;2016-07-01&#39;,\\n                         &#39;2016-07-04&#39;,&#39;2016-07-05&#39;,&#39;2016-07-06&#39;,&#39;2016-07-07&#39;,&#39;2016-07-08&#39;,\\n                         &#39;2016-07-11&#39;,&#39;2016-07-12&#39;,&#39;2016-07-13&#39;,&#39;2016-07-14&#39;,&#39;2016-07-15&#39;])\\ndata2 = range(len(dates2))\\nts2 = pd.Series(data2, index=dates2)&quot;,&quot;^X&quot;,&quot;# Reset the index of ts2 to ts1, and then use linear interpolation to fill in the NaNs: ts2_interp\\nts2_interp = ts2.reindex(ts1.index).interpolate(how=&#39;linear&#39;)\\n\\n# Compute the absolute difference of ts1 and ts2_interp: differences \\ndifferences = np.abs(ts1 - ts2_interp)\\n\\n# Generate and print summary statistics of the differences\\nprint(differences.describe())&quot;,&quot;^Y&quot;,&quot;&lt;ul&gt;\\n&lt;li&gt;To reindex &lt;code&gt;ts2&lt;/code&gt; using the index of &lt;code&gt;ts1&lt;/code&gt;, use the &lt;code&gt;.reindex()&lt;/code&gt; method with &lt;code&gt;ts1.index&lt;/code&gt; as the argument. After this, you can chain the &lt;code&gt;.interpolate()&lt;/code&gt; method with the keyword argument &lt;code&gt;how=&#39;linear&#39;&lt;/code&gt;.&lt;/li&gt;\\n&lt;li&gt;Make sure you use &lt;code&gt;np.abs()&lt;/code&gt; to take the absolute value of the difference between &lt;code&gt;ts1&lt;/code&gt; and &lt;code&gt;ts2_interp&lt;/code&gt;.&lt;/li&gt;\\n&lt;li&gt;You can generate summary statistics of the differences using &lt;code&gt;.describe()&lt;/code&gt;, and print these statistics with &lt;code&gt;print()&lt;/code&gt;.&lt;/li&gt;\\n&lt;/ul&gt;&quot;,&quot;^Z&quot;,null,&quot;xp&quot;,100,&quot;^[&quot;,[],&quot;^10&quot;,[],&quot;^11&quot;,&quot;&quot;,&quot;^16&quot;,&quot;python&quot;,&quot;^17&quot;,0.6705666660342386,&quot;^18&quot;,44361],[&quot;^ &quot;,&quot;id&quot;,44362,&quot;^&gt;&quot;,&quot;NormalExercise&quot;,&quot;^T&quot;,&quot;&lt;p&gt;Time zone handling with pandas typically assumes that you are handling the Index of the Series. In this exercise, you will learn how to handle timezones that are associated with datetimes in the column data, and not just the Index.&lt;/p&gt;\\n&lt;p&gt;You will work with the flight departure dataset again, and this time you will select Los Angeles (&lt;code&gt;&#39;LAX&#39;&lt;/code&gt;) as the destination airport.&lt;/p&gt;\\n&lt;p&gt;Here we will use a &lt;em&gt;mask&lt;/em&gt; to ensure that we only compute on data we actually want. To learn more about Boolean masks, click &lt;a href=\\&quot;https://docs.scipy.org/doc/numpy/reference/maskedarray.generic.html\\&quot;&gt;here&lt;/a&gt;!&lt;/p&gt;&quot;,&quot;^1&quot;,&quot;Time zones and conversion&quot;,&quot;^U&quot;,&quot;# Build a Boolean mask to filter out all the &#39;LAX&#39; departure flights: mask\\nmask = df[&#39;Destination Airport&#39;] == ____\\n\\n# Use the mask to subset the data: la\\nla = df[____]\\n\\n# Combine two columns of data to create a datetime series: times_tz_none \\ntimes_tz_none = pd.____( ____ + &#39; &#39; + ____ )\\n\\n# Localize the time to US/Central: times_tz_central\\ntimes_tz_central = ____\\n\\n# Convert the datetimes from US/Central to US/Pacific\\ntimes_tz_pacific = ____&quot;,&quot;^V&quot;,&quot;&lt;ul&gt;\\n&lt;li&gt;Create a Boolean mask, &lt;code&gt;mask&lt;/code&gt;, such that if the &lt;code&gt;&#39;Destination Airport&#39;&lt;/code&gt; column of &lt;code&gt;df&lt;/code&gt; equals &lt;code&gt;&#39;LAX&#39;&lt;/code&gt;, the result is &lt;code&gt;True&lt;/code&gt;, and otherwise, it is &lt;code&gt;False&lt;/code&gt;.&lt;/li&gt;\\n&lt;li&gt;Use the mask to extract only the &lt;code&gt;LAX&lt;/code&gt; rows. Assign the result to &lt;code&gt;la&lt;/code&gt;.&lt;/li&gt;\\n&lt;li&gt;Concatenate the two columns &lt;code&gt;la[&#39;Date (MM/DD/YYYY)&#39;]&lt;/code&gt; and &lt;code&gt;la[&#39;Wheels-off Time&#39;]&lt;/code&gt; with a &lt;code&gt;&#39; &#39;&lt;/code&gt; space in between. Pass this to &lt;code&gt;pd.to_datetime()&lt;/code&gt; to create a datetime array of all the times the LAX-bound flights left the ground.&lt;/li&gt;\\n&lt;li&gt;Use &lt;code&gt;Series.dt.tz_localize()&lt;/code&gt; to localize the time to &lt;code&gt;&#39;US/Central&#39;&lt;/code&gt;.&lt;/li&gt;\\n&lt;li&gt;Use the &lt;code&gt;.dt.tz_convert()&lt;/code&gt; method to convert datetimes from &lt;code&gt;&#39;US/Central&#39;&lt;/code&gt; to &lt;code&gt;&#39;US/Pacific&#39;&lt;/code&gt;.&lt;/li&gt;\\n&lt;/ul&gt;&quot;,&quot;^N&quot;,14,&quot;sct&quot;,&quot;Ex().check_object(\\&quot;mask\\&quot;).has_equal_value()\\n\\nEx().check_object(\\&quot;la\\&quot;).has_equal_value()\\n\\n# Ex().check_correct()\\n# test_function(\\&quot;pandas.to_datetime\\&quot;)\\n# test_object(\\&quot;times_tz_none\\&quot;)\\n\\nEx().check_correct(\\n\\tcheck_object(&#39;times_tz_central&#39;).has_equal_value(),\\n  \\thas_equal_ast(code = &#39;times_tz_none.dt.tz_localize(\\\\&#39;US/Central\\\\&#39;)&#39;, incorrect_msg = &#39;Did you call `dt.tz_localize` to set `times_tz_central` to the `\\\\&#39;US/Central\\\\&#39;` time zone?&#39;)\\n)\\n\\nEx().check_correct(\\n\\tcheck_object(&#39;times_tz_pacific&#39;).has_equal_value(),\\n  \\thas_equal_ast(code = &#39;times_tz_central.dt.tz_convert(\\\\&#39;US/Pacific\\\\&#39;)&#39;, incorrect_msg = &#39;Did you create `times_tz_pacific` by calling `dt.tz_convert` to convert `times_tz_central` to the `\\\\&#39;US/Pacific\\\\&#39;` time zone?&#39;)\\n)\\n\\nsuccess_msg(\\&quot;Wonderful work!\\&quot;)&quot;,&quot;^W&quot;,&quot;import pandas as pd\\n# Data file obtained as CSV from http://apps.bts.gov/xml/ontimesummarystatistics/src/dstat/OntimeSummaryDepatures.xml\\nfile_name = \\&quot;/usr/local/share/datasets/austin_airport_departure_data_2015_july.csv\\&quot;\\ndf = pd.read_csv(file_name, \\n                 skiprows=range(0,15))\\ndf.columns = df.columns.str.strip()\\ndel file_name&quot;,&quot;^X&quot;,&quot;# Build a Boolean mask to filter out all the &#39;LAX&#39; departure flights: mask\\nmask = df[&#39;Destination Airport&#39;] == &#39;LAX&#39;\\n\\n# Use the mask to subset the data: la\\nla = df[mask]\\n\\n# Combine two columns of data to create a datetime series: times_tz_none \\ntimes_tz_none = pd.to_datetime( la[&#39;Date (MM/DD/YYYY)&#39;] + &#39; &#39; + la[&#39;Wheels-off Time&#39;] )\\n\\n# Localize the time to US/Central: times_tz_central\\ntimes_tz_central = times_tz_none.dt.tz_localize(&#39;US/Central&#39;)\\n\\n# Convert the datetimes from US/Central to US/Pacific\\ntimes_tz_pacific = times_tz_central.dt.tz_convert(&#39;US/Pacific&#39;)&quot;,&quot;^Y&quot;,&quot;&lt;ul&gt;\\n&lt;li&gt;Take advantage of element-wise operations to create the mask. You can do this with &lt;code&gt;df[&#39;Destination Airport&#39;] == &#39;LAX&#39;&lt;/code&gt;.&lt;/li&gt;\\n&lt;li&gt;By passing the mask as an index to &lt;code&gt;df&lt;/code&gt;, as with &lt;code&gt;df[mask]&lt;/code&gt;, you can subset the data such that it only contains entries with &lt;code&gt;&#39;LAX&#39;&lt;/code&gt; as the &lt;code&gt;&#39;Destination Airport&#39;&lt;/code&gt;.&lt;/li&gt;\\n&lt;li&gt;Inside &lt;code&gt;pd.to_datetime()&lt;/code&gt;, pass in the columns mentioned and be sure that there is a space between them.&lt;/li&gt;\\n&lt;li&gt;To localize the time of &lt;code&gt;times_tz_none&lt;/code&gt;, you can use &lt;code&gt;times_tz_none.dt.tz_localize()&lt;/code&gt;. Inside &lt;code&gt;.tz_localize()&lt;/code&gt;, specify &lt;code&gt;&#39;US/Central&#39;&lt;/code&gt;.&lt;/li&gt;\\n&lt;li&gt;Pass in &lt;code&gt;&#39;US/Pacific&#39;&lt;/code&gt; as an argument inside &lt;code&gt;times_tz_central.dt.tz_convert()&lt;/code&gt; to convert the time zone.&lt;/li&gt;\\n&lt;/ul&gt;&quot;,&quot;^Z&quot;,null,&quot;xp&quot;,100,&quot;^[&quot;,[],&quot;^10&quot;,[],&quot;^11&quot;,&quot;&quot;,&quot;^16&quot;,&quot;python&quot;,&quot;^17&quot;,0.6567513091913255,&quot;^18&quot;,44362],[&quot;^ &quot;,&quot;id&quot;,44363,&quot;^&gt;&quot;,&quot;VideoExercise&quot;,&quot;^T&quot;,null,&quot;^1&quot;,&quot;Visualizing pandas time series&quot;,&quot;^U&quot;,&quot;&quot;,&quot;^V&quot;,null,&quot;^N&quot;,15,&quot;sct&quot;,&quot;&quot;,&quot;^W&quot;,&quot;&quot;,&quot;^X&quot;,&quot;&quot;,&quot;^Y&quot;,null,&quot;^Z&quot;,null,&quot;xp&quot;,50,&quot;^[&quot;,[],&quot;^10&quot;,[],&quot;^11&quot;,&quot;&quot;,&quot;^12&quot;,null,&quot;^13&quot;,&quot;//videos.datacamp.com/transcoded/1639_pandas-1/v2/hls-ch3_4.master.m3u8&quot;,&quot;^14&quot;,56.25,&quot;^15&quot;,&quot;course_1639_6a75d6ac92b56f139ad06120b4d553b4&quot;,&quot;^16&quot;,&quot;python&quot;,&quot;^17&quot;,0.08806802352281395,&quot;^18&quot;,44363],[&quot;^ &quot;,&quot;id&quot;,44364,&quot;^&gt;&quot;,&quot;NormalExercise&quot;,&quot;^T&quot;,&quot;&lt;p&gt;Pandas handles datetimes not only in your data, but also in your plotting. &lt;/p&gt;\\n&lt;p&gt;In this exercise, some time series data has been pre-loaded. However, we have not parsed the date-like columns nor set the index, as we have done for you in the past! &lt;/p&gt;\\n&lt;p&gt;The plot displayed is how pandas renders data with the default integer/positional index. Your job is to convert the &lt;code&gt;&#39;Date&#39;&lt;/code&gt; column from a collection of strings into a collection of datetime objects. Then, you will use this converted &lt;code&gt;&#39;Date&#39;&lt;/code&gt; column as your new index, and re-plot the data, noting the improved datetime awareness. After you are done, you can cycle between the two plots you generated by clicking on the &#39;Previous Plot&#39; and &#39;Next Plot&#39; buttons. &lt;/p&gt;\\n&lt;p&gt;Before proceeding, look at the plot shown and observe how pandas handles data with the default integer index. Then, inspect the DataFrame &lt;code&gt;df&lt;/code&gt; using the &lt;code&gt;.head()&lt;/code&gt; method in the IPython Shell to get a feel for its structure.&lt;/p&gt;&quot;,&quot;^1&quot;,&quot;Plotting time series, datetime indexing&quot;,&quot;^U&quot;,&quot;# Plot the raw data before setting the datetime index\\ndf.plot()\\nplt.show()\\n\\n# Convert the &#39;Date&#39; column into a collection of datetime objects: df.Date\\ndf.Date = ____\\n\\n# Set the index to be the converted &#39;Date&#39; column\\n____\\n\\n# Re-plot the DataFrame to see that the axis is now datetime aware!\\ndf.plot()\\nplt.show()&quot;,&quot;^V&quot;,&quot;&lt;ul&gt;\\n&lt;li&gt;Use &lt;code&gt;pd.to_datetime()&lt;/code&gt; to convert the &lt;code&gt;&#39;Date&#39;&lt;/code&gt; column to a collection of datetime objects, and assign back to &lt;code&gt;df.Date&lt;/code&gt;.&lt;/li&gt;\\n&lt;li&gt;Set the index to this updated &lt;code&gt;&#39;Date&#39;&lt;/code&gt; column, using &lt;code&gt;df.set_index()&lt;/code&gt; with the optional keyword argument &lt;code&gt;inplace=True&lt;/code&gt;, so that you don&#39;t have to assign the result back to &lt;code&gt;df&lt;/code&gt;.&lt;/li&gt;\\n&lt;li&gt;Re-plot the DataFrame to see that the axis is now datetime aware. This code has been written for you.&lt;/li&gt;\\n&lt;/ul&gt;&quot;,&quot;^N&quot;,16,&quot;sct&quot;,&quot;Ex().check_function(\\&quot;df.plot\\&quot;, index=0)\\nEx().check_function(\\&quot;matplotlib.pyplot.show\\&quot;, index=0)\\n\\nEx().check_or(\\n  \\thas_equal_ast(\\&quot;Column `Date` of your `pandas` DataFrame, `df`, is not correct. Did you correctly convert it into a collection of `datetime` objects?\\&quot;,\\n                  code=\\&quot;pd.to_datetime(df.Date)\\&quot;,\\n                  exact=False),\\n\\thas_equal_ast(\\&quot;Column `Date` of your `pandas` DataFrame, `df`, is not correct. Did you correctly convert it into a collection of `datetime` objects?\\&quot;,\\n                  code=\\&quot;pd.to_datetime(df[&#39;Date&#39;])\\&quot;,\\n                  exact=False))\\n\\nEx().check_function(\\&quot;df.set_index\\&quot;).multi(\\n\\tcheck_args(0).has_equal_ast(),\\n  \\tcheck_args(&#39;inplace&#39;).has_equal_ast()\\n)\\n\\nEx().check_function(\\&quot;df.plot\\&quot;, index=1)\\nEx().check_function(\\&quot;matplotlib.pyplot.show\\&quot;, index=1)\\n\\nsuccess_msg(\\&quot;Great work! Click on &#39;Next Plot&#39; and &#39;Previous Plot&#39; to cycle between the two plots and note the difference.\\&quot;)&quot;,&quot;^W&quot;,&quot;import pandas as pd\\nimport matplotlib.pyplot as plt\\n# Read the raw data\\nfile_name = \\&quot;/usr/local/share/datasets/weather_data_austin_2010.csv\\&quot;\\ndf = pd.read_csv(file_name)\\n\\n# pull out just the hourly temperature data for January\\ndf = df[[&#39;Temperature&#39;,&#39;Date&#39;]]\\ndf = df.loc[0:31*24]\\n\\n# clean up namespace\\ndel file_name\\n&quot;,&quot;^X&quot;,&quot;# Plot the raw data before setting the datetime index\\ndf.plot()\\nplt.show()\\n\\n# Convert the &#39;Date&#39; column into a collection of datetime objects: df.Date\\ndf.Date = pd.to_datetime(df.Date)\\n\\n# Set the index to be the converted &#39;Date&#39; column\\ndf.set_index(&#39;Date&#39;, inplace=True)\\n\\n# Re-plot the DataFrame to see that the axis is now datetime aware!\\ndf.plot()\\nplt.show()&quot;,&quot;^Y&quot;,&quot;&lt;ul&gt;\\n&lt;li&gt;Pass in &lt;code&gt;df.Date&lt;/code&gt; as an argument to &lt;code&gt;pd.to_datetime()&lt;/code&gt; to convert the &lt;code&gt;&#39;Date&#39;&lt;/code&gt; column into a collection of datetime objects. &lt;/li&gt;\\n&lt;li&gt;Inside the &lt;code&gt;.set_index()&lt;/code&gt; method, you have to specify the column you want to use as the index - in this case, the &lt;code&gt;&#39;Date&#39;&lt;/code&gt; column. By also specifying the keyword argument &lt;code&gt;inplace=True&lt;/code&gt;, you don&#39;t have to assign the result back to &lt;code&gt;df&lt;/code&gt;.&lt;/li&gt;\\n&lt;li&gt;The code to re-plot the DataFrame has been written for you. Click &#39;Submit Answer&#39; to see the result!&lt;/li&gt;\\n&lt;/ul&gt;&quot;,&quot;^Z&quot;,null,&quot;xp&quot;,100,&quot;^[&quot;,[],&quot;^10&quot;,[],&quot;^11&quot;,&quot;&quot;,&quot;^16&quot;,&quot;python&quot;,&quot;^17&quot;,0.034190490298461995,&quot;^18&quot;,44364],[&quot;^ &quot;,&quot;id&quot;,44365,&quot;^&gt;&quot;,&quot;NormalExercise&quot;,&quot;^T&quot;,&quot;&lt;p&gt;Now that you have set the DatetimeIndex in your DataFrame, you have a much more powerful and flexible set of tools to use when plotting your time series data. Of these, one of the most convenient is partial string indexing and slicing. In this exercise, we&#39;ve pre-loaded a full year of Austin 2010 weather data, with the index set to be the datetime parsed &lt;code&gt;&#39;Date&#39;&lt;/code&gt; column as shown in the previous exercise. &lt;/p&gt;\\n&lt;p&gt;Your job is to use partial string indexing of the dates, in a variety of datetime string formats, to plot all the summer data and just one week of data together. After you are done, you can cycle between the two plots by clicking on the &#39;Previous Plot&#39; and &#39;Next Plot&#39; buttons.&lt;/p&gt;\\n&lt;p&gt;First, remind yourself how to extract one month of temperature data using &lt;code&gt;&#39;May 2010&#39;&lt;/code&gt; as a key into &lt;code&gt;df.Temperature[]&lt;/code&gt;, and call &lt;code&gt;head()&lt;/code&gt; to inspect the result: &lt;code&gt;df.Temperature[&#39;May 2010&#39;].head()&lt;/code&gt;.&lt;/p&gt;&quot;,&quot;^1&quot;,&quot;Plotting date ranges, partial indexing&quot;,&quot;^U&quot;,&quot;# Plot the summer data\\ndf.Temperature[____:____].____\\nplt.show()\\nplt.clf()\\n\\n# Plot the one week data\\ndf.Temperature[____:____].____\\nplt.show()\\nplt.clf()\\n&quot;,&quot;^V&quot;,&quot;&lt;ul&gt;\\n&lt;li&gt;Plot the summer temperatures using method chaining. The summer ranges from the months &lt;code&gt;&#39;2010-Jun&#39;&lt;/code&gt; to &lt;code&gt;&#39;2010-Aug&#39;&lt;/code&gt;. &lt;/li&gt;\\n&lt;li&gt;Plot the temperatures for one week in June using the same method chaining, but this time indexing with &lt;code&gt;&#39;2010-06-10&#39;:&#39;2010-06-17&#39;&lt;/code&gt; before you follow up with &lt;code&gt;.plot()&lt;/code&gt;.&lt;/li&gt;\\n&lt;/ul&gt;&quot;,&quot;^N&quot;,17,&quot;sct&quot;,&quot;Ex().has_equal_ast(\\&quot;Did you correctly slice `df.Temperature` using `&#39;2010-Jun&#39;:&#39;2010-Aug&#39;` to plot the summer temperatures of 2010?\\&quot;,\\n                   code=\\&quot;df.Temperature[&#39;2010-Jun&#39;:&#39;2010-Aug&#39;].plot()\\&quot;,\\n                   exact=False)\\n\\nEx().has_equal_ast(\\&quot;Did you correctly slice `df.Temperature` using `&#39;2010-06-10&#39;:&#39;2010-06-17&#39;` to plot the temperatures of one week of June 2010?\\&quot;,\\n                   code=\\&quot;df.Temperature[&#39;2010-06-10&#39;:&#39;2010-06-17&#39;].plot()\\&quot;,\\n                   exact=False)\\n\\nEx().check_function(\\&quot;matplotlib.pyplot.show\\&quot;, index=0)\\nEx().check_function(\\&quot;matplotlib.pyplot.clf\\&quot;, index=0)\\n  \\nEx().check_function(\\&quot;matplotlib.pyplot.show\\&quot;, index=1)\\nEx().check_function(\\&quot;matplotlib.pyplot.clf\\&quot;, index=1)\\n\\nsuccess_msg(\\&quot;Well done! Now that you&#39;ve built your pandas foundations, you&#39;re ready to dive into a case study!\\&quot;)&quot;,&quot;^W&quot;,&quot;import pandas as pd\\nimport matplotlib.pyplot as plt\\n# Read the raw data\\nfile_name = \\&quot;/usr/local/share/datasets/weather_data_austin_2010.csv\\&quot;\\ndf = pd.read_csv(file_name, parse_dates=True, index_col=\\&quot;Date\\&quot;)\\n\\n# clean up namespace\\ndel file_name\\n&quot;,&quot;^X&quot;,&quot;# Plot the summer data\\ndf.Temperature[&#39;2010-Jun&#39;:&#39;2010-Aug&#39;].plot()\\nplt.show()\\nplt.clf()\\n\\n# Plot the one week data\\ndf.Temperature[&#39;2010-06-10&#39;:&#39;2010-06-17&#39;].plot()\\nplt.show()\\nplt.clf()\\n&quot;,&quot;^Y&quot;,&quot;&lt;ul&gt;\\n&lt;li&gt;To plot the the summer temperatures, first select out the &lt;code&gt;Temperature&lt;/code&gt; column, then use bracket slicing from &lt;code&gt;&#39;2010-Jun&#39;:&#39;2010-Aug&#39;&lt;/code&gt;, and chain the &lt;code&gt;.plot()&lt;/code&gt; method to this.&lt;/li&gt;\\n&lt;li&gt;To plot the one week data, follow the same process as above, modifying the way you slice &lt;code&gt;df.Temperature&lt;/code&gt;.&lt;/li&gt;\\n&lt;/ul&gt;&quot;,&quot;^Z&quot;,null,&quot;xp&quot;,100,&quot;^[&quot;,[],&quot;^10&quot;,[],&quot;^11&quot;,&quot;&quot;,&quot;^16&quot;,&quot;python&quot;,&quot;^17&quot;,0.11375870971681423,&quot;^18&quot;,44365]]]],&quot;activeImage&quot;,[&quot;^0&quot;,[&quot;status&quot;,&quot;SUCCESS&quot;,&quot;data&quot;,&quot;course-1639-master:013883417c7ca80ce5f0186f4636f631-20190204201642849&quot;]],&quot;sharedImage&quot;,[&quot;^0&quot;,[&quot;status&quot;,&quot;SUCCESS&quot;,&quot;data&quot;,&quot;shared-python:a3c4bdd667d4bbe8788c137413874aaa-20190215130059186&quot;]]]],&quot;systemStatus&quot;,[&quot;^0&quot;,[&quot;indicator&quot;,&quot;none&quot;,&quot;description&quot;,&quot;No status has been fetched from the Status Page.&quot;]],&quot;backendSession&quot;,[&quot;^0&quot;,[&quot;status&quot;,[&quot;^0&quot;,[&quot;code&quot;,&quot;none&quot;,&quot;text&quot;,&quot;&quot;]],&quot;isInitSession&quot;,false,&quot;message&quot;,null]],&quot;settings&quot;,[&quot;^0&quot;,[&quot;uiTheme&quot;,&quot;LIGHT&quot;,&quot;isOnboarding&quot;,false]],&quot;autocomplete&quot;,[&quot;^0&quot;,[]],&quot;user&quot;,[&quot;^0&quot;,[&quot;status&quot;,null,&quot;settings&quot;,[&quot;^0&quot;,[]]]],&quot;fileBrowser&quot;,[&quot;^0&quot;,[&quot;isVisible&quot;,true,&quot;fileSelected&quot;,null]],&quot;chapter&quot;,[&quot;^0&quot;,[&quot;current&quot;,[&quot;^0&quot;,[&quot;badge_uncompleted_url&quot;,&quot;https://assets.datacamp.com/production/default/badges/missing_unc.png&quot;,&quot;number&quot;,3,&quot;slug&quot;,&quot;time-series-in-pandas&quot;,&quot;last_updated_on&quot;,&quot;08/01/2019&quot;,&quot;title_meta&quot;,null,&quot;nb_exercises&quot;,17,&quot;free_preview&quot;,null,&quot;slides_link&quot;,&quot;https://s3.amazonaws.com/assets.datacamp.com/production/course_2357/slides/ch3_slides.pdf&quot;,&quot;title&quot;,&quot;Time series in pandas&quot;,&quot;xp&quot;,1450,&quot;id&quot;,4261,&quot;description&quot;,&quot;In this chapter, you will learn how to manipulate and visualize time series data using Pandas. You will become familiar with concepts such as upsampling, downsampling, and interpolation. You will practice using Pandas&#39; method chaining to efficiently filter your data and perform time series analyses. From stock prices to flight timings, time series data are found in a wide variety of domains and being able to effectively work with such data can be an invaluable skill.&quot;,&quot;badge_completed_url&quot;,&quot;https://assets.datacamp.com/production/default/badges/missing.png&quot;]]]],&quot;boot&quot;,[&quot;^0&quot;,[&quot;bootState&quot;,&quot;PRE_BOOTED&quot;,&quot;error&quot;,null]],&quot;location&quot;,[&quot;^0&quot;,[&quot;current&quot;,[&quot;^0&quot;,[&quot;pathname&quot;,&quot;/courses/pandas-foundations/time-series-in-pandas&quot;,&quot;query&quot;,[&quot;^0&quot;,[&quot;ex&quot;,&quot;14&quot;]]]],&quot;canonical&quot;,null]],&quot;course&quot;,[&quot;^0&quot;,[&quot;difficulty_level&quot;,2,&quot;reduced_outline&quot;,null,&quot;shared_image&quot;,&quot;shared-python:a3c4bdd667d4bbe8788c137413874aaa-20190215130059186&quot;,&quot;active_image&quot;,&quot;course-1639-master:013883417c7ca80ce5f0186f4636f631-20190204201642849&quot;,&quot;author_field&quot;,null,&quot;chapters&quot;,[&quot;~#iL&quot;,[[&quot;^0&quot;,[&quot;badge_uncompleted_url&quot;,&quot;https://assets.datacamp.com/production/default/badges/missing_unc.png&quot;,&quot;number&quot;,1,&quot;slug&quot;,&quot;data-ingestion-inspection&quot;,&quot;last_updated_on&quot;,&quot;04/02/2019&quot;,&quot;title_meta&quot;,null,&quot;nb_exercises&quot;,14,&quot;free_preview&quot;,true,&quot;slides_link&quot;,&quot;https://s3.amazonaws.com/assets.datacamp.com/production/course_2357/slides/ch1_slides.pdf&quot;,&quot;title&quot;,&quot;Data ingestion &amp; inspection&quot;,&quot;xp&quot;,1100,&quot;id&quot;,4259,&quot;description&quot;,&quot;In this chapter, you will be introduced to Panda&#39;s DataFrames. You will use Pandas to import and inspect a variety of datasets, ranging from population data obtained from The World Bank to monthly stock data obtained via Yahoo! Finance. You will also practice building DataFrames from scratch, and become familiar with Pandas&#39; intrinsic data visualization capabilities.&quot;,&quot;badge_completed_url&quot;,&quot;https://assets.datacamp.com/production/default/badges/missing.png&quot;]],[&quot;^0&quot;,[&quot;badge_uncompleted_url&quot;,&quot;https://assets.datacamp.com/production/default/badges/missing_unc.png&quot;,&quot;number&quot;,2,&quot;slug&quot;,&quot;exploratory-data-analysis&quot;,&quot;last_updated_on&quot;,&quot;13/11/2018&quot;,&quot;title_meta&quot;,null,&quot;nb_exercises&quot;,15,&quot;free_preview&quot;,null,&quot;slides_link&quot;,&quot;https://s3.amazonaws.com/assets.datacamp.com/production/course_2357/slides/ch2_slides.pdf&quot;,&quot;title&quot;,&quot;Exploratory data analysis&quot;,&quot;xp&quot;,1250,&quot;id&quot;,4260,&quot;description&quot;,&quot;Having learned how to ingest and inspect your data, you will next explore it visually as well as quantitatively. This process, known as exploratory data analysis (EDA), is a crucial component of any data science project. Pandas has powerful methods that help with statistical and visual EDA. In this chapter, you will learn how and when to apply these techniques.&quot;,&quot;badge_completed_url&quot;,&quot;https://assets.datacamp.com/production/default/badges/missing.png&quot;]],[&quot;^0&quot;,[&quot;badge_uncompleted_url&quot;,&quot;https://assets.datacamp.com/production/default/badges/missing_unc.png&quot;,&quot;number&quot;,3,&quot;slug&quot;,&quot;time-series-in-pandas&quot;,&quot;last_updated_on&quot;,&quot;08/01/2019&quot;,&quot;title_meta&quot;,null,&quot;nb_exercises&quot;,17,&quot;free_preview&quot;,null,&quot;slides_link&quot;,&quot;https://s3.amazonaws.com/assets.datacamp.com/production/course_2357/slides/ch3_slides.pdf&quot;,&quot;title&quot;,&quot;Time series in pandas&quot;,&quot;xp&quot;,1450,&quot;id&quot;,4261,&quot;description&quot;,&quot;In this chapter, you will learn how to manipulate and visualize time series data using Pandas. You will become familiar with concepts such as upsampling, downsampling, and interpolation. You will practice using Pandas&#39; method chaining to efficiently filter your data and perform time series analyses. From stock prices to flight timings, time series data are found in a wide variety of domains and being able to effectively work with such data can be an invaluable skill.&quot;,&quot;badge_completed_url&quot;,&quot;https://assets.datacamp.com/production/default/badges/missing.png&quot;]],[&quot;^0&quot;,[&quot;badge_uncompleted_url&quot;,&quot;https://assets.datacamp.com/production/default/badges/missing_unc.png&quot;,&quot;number&quot;,4,&quot;slug&quot;,&quot;case-study-sunlight-in-austin&quot;,&quot;last_updated_on&quot;,&quot;04/02/2019&quot;,&quot;title_meta&quot;,null,&quot;nb_exercises&quot;,16,&quot;free_preview&quot;,null,&quot;slides_link&quot;,&quot;https://s3.amazonaws.com/assets.datacamp.com/production/course_2357/slides/ch4_slides.pdf&quot;,&quot;title&quot;,&quot;Case Study - Sunlight in Austin&quot;,&quot;xp&quot;,1350,&quot;id&quot;,4284,&quot;description&quot;,&quot;Working with real-world weather and climate data, in this chapter you will bring together and apply all of the skills you have acquired in this course. You will use Pandas to manipulate the data into a form usable for analysis, and then systematically explore it using the techniques you learned in the prior chapters. Enjoy!&quot;,&quot;badge_completed_url&quot;,&quot;https://assets.datacamp.com/production/default/badges/missing.png&quot;]]]],&quot;time_needed&quot;,&quot;4 hours&quot;,&quot;author_image&quot;,&quot;placeholder.png&quot;,&quot;runtime_config&quot;,&quot;heavy&quot;,&quot;lti_only&quot;,false,&quot;image_url&quot;,&quot;https://assets.datacamp.com/production/course_1639/shields/thumb/shield_image_course_1639_20190204-13-1xw9geb?1549311490&quot;,&quot;topic_id&quot;,3,&quot;slug&quot;,&quot;pandas-foundations&quot;,&quot;last_updated_on&quot;,&quot;04/02/2019&quot;,&quot;paid&quot;,true,&quot;university&quot;,null,&quot;state&quot;,&quot;live&quot;,&quot;author_bio&quot;,null,&quot;should_cache&quot;,true,&quot;sharing_links&quot;,[&quot;^0&quot;,[&quot;twitter&quot;,&quot;http://bit.ly/1eWTMJh&quot;,&quot;facebook&quot;,&quot;http://bit.ly/1iS42Do&quot;]],&quot;title&quot;,&quot;pandas Foundations&quot;,&quot;xp&quot;,5150,&quot;image_thumbnail_url&quot;,&quot;https://assets.datacamp.com/production/course_1639/shields/thumb_home/shield_image_course_1639_20190204-13-1xw9geb?1549311490&quot;,&quot;short_description&quot;,&quot;Learn how to use the industry-standard pandas library to import, build, and manipulate DataFrames. &quot;,&quot;nb_of_subscriptions&quot;,85379,&quot;type&quot;,&quot;datacamp&quot;,&quot;link&quot;,&quot;https://www.datacamp.com/courses/pandas-foundations&quot;,&quot;id&quot;,1639,&quot;description&quot;,&quot;Pandas DataFrames are the most widely used in-memory representation of complex data collections within Python.  Whether in finance, scientific fields, or data science, a familiarity with Pandas is essential.  This course teaches you to work with real-world data sets containing both string and numeric data, often structured around time series.  You will learn powerful analysis, selection, and visualization techniques in this course.&quot;,&quot;programming_language&quot;,&quot;python&quot;]],&quot;exercises&quot;,[&quot;^0&quot;,[&quot;current&quot;,13,&quot;all&quot;,[&quot;^19&quot;,[[&quot;^0&quot;,[&quot;sample_code&quot;,&quot;&quot;,&quot;sct&quot;,&quot;&quot;,&quot;aspect_ratio&quot;,56.25,&quot;instructions&quot;,null,&quot;externalId&quot;,44351,&quot;question&quot;,&quot;&quot;,&quot;hint&quot;,null,&quot;possible_answers&quot;,[&quot;^19&quot;,[]],&quot;number&quot;,1,&quot;video_hls&quot;,&quot;//videos.datacamp.com/transcoded/1639_pandas-1/v6/hls-ch3_1.master.m3u8&quot;,&quot;randomNumber&quot;,0.9909757797839178,&quot;assignment&quot;,null,&quot;feedbacks&quot;,[&quot;^19&quot;,[]],&quot;attachments&quot;,null,&quot;title&quot;,&quot;Indexing pandas time series&quot;,&quot;xp&quot;,50,&quot;language&quot;,&quot;python&quot;,&quot;pre_exercise_code&quot;,&quot;&quot;,&quot;solution&quot;,&quot;&quot;,&quot;type&quot;,&quot;VideoExercise&quot;,&quot;id&quot;,44351,&quot;projector_key&quot;,&quot;course_1639_4c739c46fd495fbaf4f0a50286d6f0a0&quot;,&quot;video_link&quot;,null]],[&quot;^0&quot;,[&quot;sample_code&quot;,&quot;&quot;,&quot;sct&quot;,&quot;msg1 = \\&quot;Incorrect. Try running `df1.loc[&#39;2010-Aug-01&#39;]`. What happens?\\&quot; # df1 \\nmsg2 = \\&quot;Try using `df1.loc[&#39;2010-Aug-01&#39;]` and `df2.loc[&#39;2010-Aug-01&#39;]` in the IPython Shell to inspect the data.\\&quot; # df1 and df2\\nmsg3 = \\&quot;Try running `df2.loc[&#39;2010-Aug-01&#39;]` in the IPython Shell.\\&quot; # df2\\nmsg4 = \\&quot;Try out `df2.loc[&#39;2010-Aug-01&#39;]` and `df3.loc[&#39;2010-Aug-01&#39;]` in the IPython Shell to inspect the data.\\&quot; # df2 and df3\\n\\nEx().has_chosen(correct = 5,\\n                msgs = [msg1, msg2, msg3, msg4, &#39;Correct! This is why it is important to read in your data properly, especially when working with time series data.&#39;])&quot;,&quot;instructions&quot;,null,&quot;externalId&quot;,46106,&quot;question&quot;,&quot;&quot;,&quot;hint&quot;,&quot;&lt;p&gt;Run the given &lt;code&gt;.loc[&#39;2010-Aug-01&#39;]&lt;/code&gt; method on all three DataFrames and inspect the results!&lt;/p&gt;&quot;,&quot;possible_answers&quot;,[&quot;^19&quot;,[&quot;&lt;code&gt;df1&lt;/code&gt;.&quot;,&quot;&lt;code&gt;df1&lt;/code&gt; and &lt;code&gt;df2&lt;/code&gt;.&quot;,&quot;&lt;code&gt;df2&lt;/code&gt;.&quot;,&quot;&lt;code&gt;df2&lt;/code&gt; and &lt;code&gt;df3&lt;/code&gt;.&quot;,&quot;[&lt;code&gt;df3&lt;/code&gt;.]&quot;]],&quot;number&quot;,2,&quot;randomNumber&quot;,0.9144603061430696,&quot;assignment&quot;,&quot;&lt;p&gt;For this exercise, we have read in the same data file using three different approaches:&lt;/p&gt;\\n&lt;ul&gt;\\n&lt;li&gt;&lt;p&gt;&lt;code&gt;df1 = pd.read_csv(filename)&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;\\n&lt;li&gt;&lt;p&gt;&lt;code&gt;df2 = pd.read_csv(filename, parse_dates=[&#39;Date&#39;])&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;\\n&lt;li&gt;&lt;p&gt;&lt;code&gt;df3 = pd.read_csv(filename, index_col=&#39;Date&#39;, parse_dates=True)&lt;/code&gt;&lt;/p&gt;\\n&lt;p&gt;Use the &lt;code&gt;.head()&lt;/code&gt; and &lt;code&gt;.info()&lt;/code&gt; methods in the IPython Shell to inspect the DataFrames. Then, try to index each DataFrame with a datetime string. Which of the resulting DataFrames allows you to easily index and slice data by dates using, for example, &lt;code&gt;df1.loc[&#39;2010-Aug-01&#39;]&lt;/code&gt;?&lt;/p&gt;&lt;/li&gt;\\n&lt;/ul&gt;&quot;,&quot;feedbacks&quot;,[&quot;^19&quot;,[]],&quot;attachments&quot;,null,&quot;title&quot;,&quot;Reading and slicing times&quot;,&quot;xp&quot;,50,&quot;language&quot;,&quot;python&quot;,&quot;pre_exercise_code&quot;,&quot;import pandas as pd\\n\\nfile_name = \\&quot;/usr/local/share/datasets/weather_data_austin_2010.csv\\&quot;\\n\\ndf1 = pd.read_csv(file_name)\\ndf2 = pd.read_csv(file_name, parse_dates=[&#39;Date&#39;])\\ndf3 = pd.read_csv(file_name, index_col=&#39;Date&#39;, parse_dates=True)\\n\\ndel file_name&quot;,&quot;solution&quot;,&quot;&quot;,&quot;type&quot;,&quot;MultipleChoiceExercise&quot;,&quot;id&quot;,46106]],[&quot;^0&quot;,[&quot;sample_code&quot;,&quot;# Prepare a format string: time_format\\ntime_format = ____\\n\\n# Convert date_list into a datetime object: my_datetimes\\nmy_datetimes = ____(____, ____=____)  \\n\\n# Construct a pandas Series using temperature_list and my_datetimes: time_series\\ntime_series = ____(temperature_list, ____=my_datetimes)&quot;,&quot;sct&quot;,&quot;Ex().check_correct(\\n\\tcheck_object(&#39;time_format&#39;).has_equal_value(),\\n  \\thas_equal_ast(code = \\&quot;&#39;%Y-%m-%d %H:%M&#39;\\&quot;, incorrect_msg = &#39;Did you use the correct time format as a character string to create `time_format`?&#39;)\\n)\\n\\nEx().check_correct(\\n\\tcheck_object(&#39;my_datetimes&#39;).has_equal_value(),\\n  \\tcheck_function(&#39;pandas.to_datetime&#39;, signature = sig_from_obj(&#39;pandas.to_datetime&#39;)).multi(\\n    \\tcheck_args(0).has_equal_value(),\\n      \\tcheck_args(&#39;format&#39;).has_equal_value()\\n    )\\n)\\n\\nEx().check_correct(\\n\\tcheck_object(&#39;time_series&#39;).has_equal_value(),\\n  \\tcheck_function(&#39;pandas.Series&#39;, signature = sig_from_obj(&#39;pandas.Series&#39;)).multi(\\n    \\tcheck_args(0).has_equal_value(),\\n      \\tcheck_args(&#39;index&#39;).has_equal_value()\\n    )\\n)\\n\\nsuccess_msg(\\&quot;Awesome job! Next to `DataFrames`, `Series` are another important object that `pandas` allows us to create, and they&#39;re very convenient for time series data.\\&quot;)&quot;,&quot;instructions&quot;,&quot;&lt;ul&gt;\\n&lt;li&gt;Prepare a format string, &lt;code&gt;time_format&lt;/code&gt;, using &lt;code&gt;&#39;%Y-%m-%d %H:%M&#39;&lt;/code&gt; as the desired format.&lt;/li&gt;\\n&lt;li&gt;Convert &lt;code&gt;date_list&lt;/code&gt; into a &lt;code&gt;datetime&lt;/code&gt; object by using the &lt;code&gt;pd.to_datetime()&lt;/code&gt; function. Specify the format string you defined above and assign the result to &lt;code&gt;my_datetimes&lt;/code&gt;.&lt;/li&gt;\\n&lt;li&gt;Construct a pandas Series called &lt;code&gt;time_series&lt;/code&gt; using &lt;code&gt;pd.Series()&lt;/code&gt; with &lt;code&gt;temperature_list&lt;/code&gt; and &lt;code&gt;my_datetimes&lt;/code&gt;. Set the &lt;code&gt;index&lt;/code&gt; of the Series to be &lt;code&gt;my_datetimes&lt;/code&gt;.&lt;/li&gt;\\n&lt;/ul&gt;&quot;,&quot;externalId&quot;,44352,&quot;question&quot;,&quot;&quot;,&quot;hint&quot;,&quot;&lt;ul&gt;\\n&lt;li&gt;The desired format string here is &lt;code&gt;&#39;%Y-%m-%d %H:%M&#39;&lt;/code&gt;.&lt;/li&gt;\\n&lt;li&gt;You can create the &lt;code&gt;datetime&lt;/code&gt; object &lt;code&gt;my_datetimes&lt;/code&gt; by passing in &lt;code&gt;date_list&lt;/code&gt; to &lt;code&gt;pd.to_datetime()&lt;/code&gt; and specifying the keyword argument &lt;code&gt;format=time_format&lt;/code&gt;.&lt;/li&gt;\\n&lt;li&gt;When creating the Series with &lt;code&gt;pd.Series()&lt;/code&gt;, be sure to pass in &lt;code&gt;temperature_list&lt;/code&gt; as an argument and to also specify the &lt;code&gt;index&lt;/code&gt; parameter. Here, it should be &lt;code&gt;my_datetimes&lt;/code&gt;.&lt;/li&gt;\\n&lt;/ul&gt;&quot;,&quot;possible_answers&quot;,[&quot;^19&quot;,[]],&quot;number&quot;,3,&quot;randomNumber&quot;,0.9899993007503594,&quot;assignment&quot;,&quot;&lt;p&gt;The pandas Index is a powerful way to handle time series data, so it is valuable to know how to build one yourself. Pandas provides the &lt;code&gt;pd.to_datetime()&lt;/code&gt; function for just this task. For example, if passed the list of strings &lt;code&gt;[&#39;2015-01-01 091234&#39;,&#39;2015-01-01 091234&#39;]&lt;/code&gt; and a &lt;code&gt;format&lt;/code&gt; specification variable, such as &lt;code&gt;format=&#39;%Y-%m-%d %H%M%S&lt;/code&gt;, pandas will parse the string into the proper datetime elements and build the datetime objects. &lt;/p&gt;\\n&lt;p&gt;In this exercise, a list of temperature data and a list of date strings has been pre-loaded for you as &lt;code&gt;temperature_list&lt;/code&gt; and &lt;code&gt;date_list&lt;/code&gt; respectively. \\nYour job is to use the &lt;code&gt;.to_datetime()&lt;/code&gt; method to build a DatetimeIndex out of the list of date strings, and to then use it along with the list of temperature data to build a pandas Series.&lt;/p&gt;&quot;,&quot;feedbacks&quot;,[&quot;^19&quot;,[]],&quot;attachments&quot;,null,&quot;title&quot;,&quot;Creating and using a DatetimeIndex&quot;,&quot;xp&quot;,100,&quot;language&quot;,&quot;python&quot;,&quot;pre_exercise_code&quot;,&quot;import pandas as pd\\n\\n# Read in the data\\nfile_name = \\&quot;/usr/local/share/datasets/weather_data_austin_2010.csv\\&quot;\\ndf = pd.read_csv(file_name)\\n\\n# extract out the temperature and date solumns as lists\\ntemperature_list = list(df.Temperature)\\ndate_list = list(df.Date)\\n\\n# Clean up namespace before student sees it\\ndel df\\ndel file_name&quot;,&quot;solution&quot;,&quot;# Prepare a format string: time_format\\ntime_format=&#39;%Y-%m-%d %H:%M&#39;\\n\\n# Convert date_list into a datetime object: my_datetimes\\nmy_datetimes = pd.to_datetime(date_list, format=time_format)  \\n\\n# Construct a pandas Series using temperature_list and my_datetimes: time_series\\ntime_series = pd.Series(temperature_list, index=my_datetimes)&quot;,&quot;type&quot;,&quot;NormalExercise&quot;,&quot;id&quot;,44352]],[&quot;^0&quot;,[&quot;sample_code&quot;,&quot;# Extract the hour from 9pm to 10pm on &#39;2010-10-11&#39;: ts1\\nts1 = ts0.loc[&#39;2010-10-11 21:00:00&#39;:&#39;____&#39;]\\n\\n# Extract &#39;2010-07-04&#39; from ts0: ts2\\nts2 = ____\\n\\n# Extract data from &#39;2010-12-15&#39; to &#39;2010-12-31&#39;: ts3\\nts3 = ____\\n&quot;,&quot;sct&quot;,&quot;Ex().check_correct(\\n\\tcheck_object(&#39;ts1&#39;).has_equal_value(),\\n  \\thas_equal_ast(code = \\&quot;ts0.loc[&#39;2010-10-11 21:00:00&#39;:&#39;2010-10-11 22:00:00&#39;]\\&quot;, incorrect_msg = &#39;Be sure you\\\\&#39;re extracting info only on the hour from 21:00 to 22:00 on 2010-10-11.&#39;)\\n)\\n\\nEx().check_correct(\\n\\tcheck_object(&#39;ts2&#39;).has_equal_value(),\\n  \\thas_equal_ast(code = \\&quot;ts0.loc[&#39;2010-07-04&#39;]\\&quot;, incorrect_msg = &#39;Be sure you\\\\&#39;re extracting info only for the day of 2010-07-04.&#39;)\\n)\\n\\nEx().check_correct(\\n\\tcheck_object(&#39;ts3&#39;).has_equal_value(),\\n  \\thas_equal_ast(code = \\&quot;ts0.loc[&#39;2010-12-15&#39;:&#39;2010-12-31&#39;]\\&quot;, incorrect_msg = &#39;Be sure you\\\\&#39;re extracting info for only the days between 2010-12-15 and 2010-12-31.&#39;)\\n)\\n\\nsuccess_msg(\\&quot;Well done!\\&quot;)&quot;,&quot;instructions&quot;,&quot;&lt;ul&gt;\\n&lt;li&gt;Extract data from &lt;code&gt;ts0&lt;/code&gt; for a single hour - the hour from 9pm to 10pm on &lt;code&gt;2010-10-11&lt;/code&gt;. Assign it to &lt;code&gt;ts1&lt;/code&gt;.&lt;/li&gt;\\n&lt;li&gt;Extract data from &lt;code&gt;ts0&lt;/code&gt; for a single day - &lt;code&gt;July 4th, 2010&lt;/code&gt; - and assign it to &lt;code&gt;ts2&lt;/code&gt;.&lt;/li&gt;\\n&lt;li&gt;Extract data from &lt;code&gt;ts0&lt;/code&gt; for the second half of December 2010 - &lt;code&gt;12/15/2010&lt;/code&gt; to &lt;code&gt;12/31/2010&lt;/code&gt;. Assign it to &lt;code&gt;ts3&lt;/code&gt;.&lt;/li&gt;\\n&lt;/ul&gt;&quot;,&quot;externalId&quot;,44353,&quot;question&quot;,&quot;&quot;,&quot;hint&quot;,&quot;&lt;ul&gt;\\n&lt;li&gt;You can use the &lt;code&gt;.loc[]&lt;/code&gt; method to extract the relevant values from &lt;code&gt;ts0&lt;/code&gt;. You will have to pass in the appropriate date string. &lt;/li&gt;\\n&lt;li&gt;To extract the hour from 5pm to 6pm on November 5th 2010, for instance, the string would be &lt;code&gt;&#39;2010-11-05 17:00:00&#39;&lt;/code&gt;. &lt;/li&gt;\\n&lt;li&gt;For just November 5th 2010 it would be &lt;code&gt;&#39;2010-11-05&#39;&lt;/code&gt;. &lt;/li&gt;\\n&lt;li&gt;For the time range from November 5th 2010 to November 12th 2010, the string would be &lt;code&gt;&#39;2010-11-05&#39;:&#39;2010-11-12&#39;&lt;/code&gt;.&lt;/li&gt;\\n&lt;/ul&gt;&quot;,&quot;possible_answers&quot;,[&quot;^19&quot;,[]],&quot;number&quot;,4,&quot;randomNumber&quot;,0.8569771315432377,&quot;assignment&quot;,&quot;&lt;p&gt;Pandas time series support \\&quot;partial string\\&quot; indexing. What this means is that even when passed only a portion of the datetime, such as the date but not the time, pandas is remarkably good at doing what one would expect. Pandas datetime indexing also supports a wide variety of commonly used datetime string formats, even when mixed. &lt;/p&gt;\\n&lt;p&gt;In this exercise, a time series that contains hourly weather data has been pre-loaded for you. This data was read using the &lt;code&gt;parse_dates=True&lt;/code&gt; option in &lt;code&gt;read_csv()&lt;/code&gt; with &lt;code&gt;index_col=\\&quot;Dates\\&quot;&lt;/code&gt; so that the Index is indeed a &lt;code&gt;DatetimeIndex&lt;/code&gt;. &lt;/p&gt;\\n&lt;p&gt;All data from the &lt;code&gt;&#39;Temperature&#39;&lt;/code&gt; column has been extracted into the variable &lt;code&gt;ts0&lt;/code&gt;. Your job is to use a variety of natural date strings to extract one or more values from &lt;code&gt;ts0&lt;/code&gt;.&lt;/p&gt;\\n&lt;p&gt;After you are done, you will have three new variables - &lt;code&gt;ts1&lt;/code&gt;, &lt;code&gt;ts2&lt;/code&gt;, and &lt;code&gt;ts3&lt;/code&gt;. You can slice these further to extract only the first and last entries of each. Try doing this after your submission for more practice.&lt;/p&gt;&quot;,&quot;feedbacks&quot;,[&quot;^19&quot;,[]],&quot;attachments&quot;,null,&quot;title&quot;,&quot;Partial string indexing and slicing&quot;,&quot;xp&quot;,100,&quot;language&quot;,&quot;python&quot;,&quot;pre_exercise_code&quot;,&quot;import pandas as pd\\nfile_name = \\&quot;/usr/local/share/datasets/weather_data_austin_2010.csv\\&quot;\\ndf = pd.read_csv(file_name, index_col=&#39;Date&#39;, parse_dates=True)\\n\\ndel file_name\\n# Extract the Temperature data from the DataFrame: ts0\\nts0 = df[&#39;Temperature&#39;]&quot;,&quot;solution&quot;,&quot;# Extract the hour from 9pm to 10pm on &#39;2010-10-11&#39;: ts1\\nts1 = ts0.loc[&#39;2010-10-11 21:00:00&#39;:&#39;2010-10-11 22:00:00&#39;]\\n\\n# Extract &#39;2010-07-04&#39; from ts0: ts2\\nts2 = ts0.loc[&#39;2010-07-04&#39;]\\n\\n# Extract data from &#39;2010-12-15&#39; to &#39;2010-12-31&#39;: ts3\\nts3 = ts0.loc[&#39;2010-12-15&#39;:&#39;2010-12-31&#39;]&quot;,&quot;type&quot;,&quot;NormalExercise&quot;,&quot;id&quot;,44353]],[&quot;^0&quot;,[&quot;sample_code&quot;,&quot;# Reindex without fill method: ts3\\nts3 = ____\\n\\n# Reindex with fill method, using forward fill: ts4\\nts4 = ____\\n\\n# Combine ts1 + ts2: sum12\\nsum12 = ____\\n\\n# Combine ts1 + ts3: sum13\\nsum13 = ____\\n\\n# Combine ts1 + ts4: sum14\\nsum14 = ____&quot;,&quot;sct&quot;,&quot;Ex().check_correct(\\n\\tcheck_object(\\&quot;ts3\\&quot;).has_equal_value(),\\n\\tcheck_function(\\&quot;ts2.reindex\\&quot;).check_args(0).has_equal_value()\\n)\\n\\nEx().check_correct(\\n\\tcheck_object(\\&quot;ts4\\&quot;).has_equal_value(),\\n\\tcheck_function(\\&quot;ts2.reindex\\&quot;).check_args(0).has_equal_value()\\n)\\n\\nEx().check_correct(\\n\\tcheck_object(\\&quot;sum12\\&quot;).has_equal_value(),\\n  \\tcheck_or(\\n    \\thas_equal_ast(code = &#39;ts1 + ts2&#39;, incorrect_msg = &#39;Did you add together `ts1` and `ts2` to create `sum12`?&#39;),\\n      \\thas_equal_ast(code = &#39;ts2 + ts1&#39;, incorrect_msg = &#39;Did you add together `ts1` and `ts2` to create `sum12`?&#39;)\\n    )\\n)\\n\\nEx().check_correct(\\n\\tcheck_object(\\&quot;sum13\\&quot;).has_equal_value(),\\n  \\tcheck_or(\\n    \\thas_equal_ast(code = &#39;ts1 + ts3&#39;, incorrect_msg = &#39;Did you add together `ts1` and `ts3` to create `sum13`?&#39;),\\n      \\thas_equal_ast(code = &#39;ts3 + ts1&#39;, incorrect_msg = &#39;Did you add together `ts1` and `ts3` to create `sum13`?&#39;)\\n    )\\n)\\n\\nEx().check_correct(\\n\\tcheck_object(\\&quot;sum14\\&quot;).has_equal_value(),\\n  \\tcheck_or(\\n    \\thas_equal_ast(code = &#39;ts1 + ts4&#39;, incorrect_msg = &#39;Did you add together `ts1` and `ts4` to create `sum14`?&#39;),\\n      \\thas_equal_ast(code = &#39;ts4 + ts1&#39;, incorrect_msg = &#39;Did you add together `ts1` and `ts4` to create `sum14`?&#39;)\\n    )\\n)\\n\\nsuccess_msg(\\&quot;Wonderful work! Understanding how indexing and reindexing works is a valuable skill.\\&quot;)&quot;,&quot;instructions&quot;,&quot;&lt;ul&gt;\\n&lt;li&gt;Create a new time series &lt;code&gt;ts3&lt;/code&gt; by reindexing &lt;code&gt;ts2&lt;/code&gt; with the index of &lt;code&gt;ts1&lt;/code&gt;. To do this, call &lt;code&gt;.reindex()&lt;/code&gt; on &lt;code&gt;ts2&lt;/code&gt; and pass in the index of &lt;code&gt;ts1&lt;/code&gt; (&lt;code&gt;ts1.index&lt;/code&gt;).&lt;/li&gt;\\n&lt;li&gt;Create another new time series, &lt;code&gt;ts4&lt;/code&gt;, by calling the same &lt;code&gt;.reindex()&lt;/code&gt; as above, but also specifiying a fill method, using the keyword argument &lt;code&gt;method=\\&quot;ffill\\&quot;&lt;/code&gt; to forward-fill values.&lt;/li&gt;\\n&lt;li&gt;Add &lt;code&gt;ts1 + ts2&lt;/code&gt;. Assign the result to &lt;code&gt;sum12&lt;/code&gt;.&lt;/li&gt;\\n&lt;li&gt;Add &lt;code&gt;ts1 + ts3&lt;/code&gt;. Assign the result to &lt;code&gt;sum13&lt;/code&gt;.&lt;/li&gt;\\n&lt;li&gt;Add &lt;code&gt;ts1 + ts4&lt;/code&gt;, Assign the result to &lt;code&gt;sum14&lt;/code&gt;.&lt;/li&gt;\\n&lt;/ul&gt;&quot;,&quot;externalId&quot;,44354,&quot;question&quot;,&quot;&quot;,&quot;hint&quot;,&quot;&lt;ul&gt;\\n&lt;li&gt;&lt;code&gt;ts4 = ts2.reindex(ts1.index, method=&#39;ffill&#39;)&lt;/code&gt;&lt;/li&gt;\\n&lt;/ul&gt;&quot;,&quot;possible_answers&quot;,[&quot;^19&quot;,[]],&quot;number&quot;,5,&quot;randomNumber&quot;,0.6686954137114809,&quot;assignment&quot;,&quot;&lt;p&gt;Reindexing is useful in preparation for adding or otherwise combining two time series data sets. To reindex the data, we provide a new index and ask pandas to try and match the old data to the new index. If data is unavailable for one of the new index dates or times, you must tell pandas how to fill it in. Otherwise, pandas will fill with &lt;code&gt;NaN&lt;/code&gt; by default. &lt;/p&gt;\\n&lt;p&gt;In this exercise, two time series data sets containing daily data have been pre-loaded for you, each indexed by dates. The first, &lt;code&gt;ts1&lt;/code&gt;, includes weekends, but the second, &lt;code&gt;ts2&lt;/code&gt;, does not. The goal is to combine the two data sets in a sensible way. Your job is to reindex the second data set so that it has weekends as well, and then add it to the first. When you are done, it would be informative to inspect your results.&lt;/p&gt;&quot;,&quot;feedbacks&quot;,[&quot;^19&quot;,[]],&quot;attachments&quot;,null,&quot;title&quot;,&quot;Reindexing the Index&quot;,&quot;xp&quot;,100,&quot;language&quot;,&quot;python&quot;,&quot;pre_exercise_code&quot;,&quot;import pandas as pd\\n\\n# Create Series that includes weekends\\ndates1 = pd.to_datetime([&#39;2016-07-01&#39;,\\n                         &#39;2016-07-02&#39;,&#39;2016-07-03&#39;,\\n                         &#39;2016-07-04&#39;,&#39;2016-07-05&#39;,&#39;2016-07-06&#39;,&#39;2016-07-07&#39;,&#39;2016-07-08&#39;,\\n                         &#39;2016-07-09&#39;,&#39;2016-07-10&#39;,\\n                         &#39;2016-07-11&#39;,&#39;2016-07-12&#39;,&#39;2016-07-13&#39;,&#39;2016-07-14&#39;,&#39;2016-07-15&#39;,\\n                         &#39;2016-07-16&#39;,&#39;2016-07-17&#39;])\\ndata1 = range(len(dates1))\\nts1 = pd.Series(data1, index=dates1)\\n\\n# Create Series that does NOT include weekends\\ndates2 = pd.to_datetime([&#39;2016-07-01&#39;,\\n                         &#39;2016-07-04&#39;,&#39;2016-07-05&#39;,&#39;2016-07-06&#39;,&#39;2016-07-07&#39;,&#39;2016-07-08&#39;,\\n                         &#39;2016-07-11&#39;,&#39;2016-07-12&#39;,&#39;2016-07-13&#39;,&#39;2016-07-14&#39;,&#39;2016-07-15&#39;])\\ndata2 = range(len(dates2))\\nts2 = pd.Series(data2, index=dates2)&quot;,&quot;solution&quot;,&quot;# Reindex without fill method: ts3\\nts3 = ts2.reindex(ts1.index)\\n\\n# Reindex with fill method, using forward fill: ts4\\nts4 = ts2.reindex(ts1.index, method=&#39;ffill&#39;)\\n\\n# Combine ts1 + ts2: sum12\\nsum12 = ts1 + ts2\\n\\n# Combine ts1 + ts3: sum13\\nsum13 = ts1 + ts3\\n\\n# Combine ts1 + ts4: sum14\\nsum14 = ts1 + ts4&quot;,&quot;type&quot;,&quot;NormalExercise&quot;,&quot;id&quot;,44354]],[&quot;^0&quot;,[&quot;sample_code&quot;,&quot;&quot;,&quot;sct&quot;,&quot;&quot;,&quot;aspect_ratio&quot;,56.25,&quot;instructions&quot;,null,&quot;externalId&quot;,44355,&quot;question&quot;,&quot;&quot;,&quot;hint&quot;,null,&quot;possible_answers&quot;,[&quot;^19&quot;,[]],&quot;number&quot;,6,&quot;video_hls&quot;,&quot;//videos.datacamp.com/transcoded/1639_pandas-1/v3/hls-ch3_2.master.m3u8&quot;,&quot;randomNumber&quot;,0.7907269019091243,&quot;assignment&quot;,null,&quot;feedbacks&quot;,[&quot;^19&quot;,[]],&quot;attachments&quot;,null,&quot;title&quot;,&quot;Resampling pandas time series&quot;,&quot;xp&quot;,50,&quot;language&quot;,&quot;python&quot;,&quot;pre_exercise_code&quot;,&quot;&quot;,&quot;solution&quot;,&quot;&quot;,&quot;type&quot;,&quot;VideoExercise&quot;,&quot;id&quot;,44355,&quot;projector_key&quot;,&quot;course_1639_2668ea6284be6832ac78db0504762bae&quot;,&quot;video_link&quot;,null]],[&quot;^0&quot;,[&quot;sample_code&quot;,&quot;# Downsample to 6 hour data and aggregate by mean: df1\\ndf1 = ____\\n\\n# Downsample to daily data and count the number of data points: df2\\ndf2 = ____&quot;,&quot;sct&quot;,&quot;Ex().check_correct(\\n\\tcheck_object(\\&quot;df1\\&quot;).has_equal_value(),\\n    has_equal_ast(\\&quot;Did you correctly downsample `&#39;Temperature&#39;` using `.resample(&#39;6h&#39;)` and `.mean()`?\\&quot;,\\n                           code=\\&quot;df[&#39;Temperature&#39;].resample(&#39;6h&#39;).mean()\\&quot;,\\n                           exact=False))\\n\\n\\nEx().check_correct(\\n  \\tcheck_object(\\&quot;df2\\&quot;).has_equal_value(),\\n    has_equal_ast(\\&quot;Did you correctly downsample `&#39;Temperature&#39;` using `.resample(&#39;D&#39;)` and `.count()`?\\&quot;,\\n                           code=\\&quot;df[&#39;Temperature&#39;].resample(&#39;D&#39;).count()\\&quot;,\\n                           exact=False))\\n\\nsuccess_msg(\\&quot;Excellent job! You&#39;ll get a lot more practice with resampling in the coming exercises!\\&quot;)&quot;,&quot;instructions&quot;,&quot;&lt;ul&gt;\\n&lt;li&gt;Downsample the &lt;code&gt;&#39;Temperature&#39;&lt;/code&gt; column of &lt;code&gt;df&lt;/code&gt; to 6 hour data using &lt;code&gt;.resample(&#39;6h&#39;)&lt;/code&gt; and &lt;code&gt;.mean()&lt;/code&gt;. Assign the result to &lt;code&gt;df1&lt;/code&gt;.&lt;/li&gt;\\n&lt;li&gt;Downsample the &lt;code&gt;&#39;Temperature&#39;&lt;/code&gt; column of &lt;code&gt;df&lt;/code&gt; to daily data using &lt;code&gt;.resample(&#39;D&#39;)&lt;/code&gt; and then count the number of data points in each day with &lt;code&gt;.count()&lt;/code&gt;. Assign the result &lt;code&gt;df2&lt;/code&gt;.&lt;/li&gt;\\n&lt;/ul&gt;&quot;,&quot;externalId&quot;,44356,&quot;question&quot;,&quot;&quot;,&quot;hint&quot;,&quot;&lt;ul&gt;\\n&lt;li&gt;You can downsample a column to 6 hour data and aggregate the mean by chaining onto it the methods &lt;code&gt;.resample(&#39;6h&#39;).mean()&lt;/code&gt;. &lt;/li&gt;\\n&lt;li&gt;To downsample a column to daily data and aggregate the count, you can chain onto it the methods &lt;code&gt;.resample(&#39;D&#39;).count()&lt;/code&gt;.&lt;/li&gt;\\n&lt;/ul&gt;&quot;,&quot;possible_answers&quot;,[&quot;^19&quot;,[]],&quot;number&quot;,7,&quot;randomNumber&quot;,0.13850964168246005,&quot;assignment&quot;,&quot;&lt;p&gt;Pandas provides methods for resampling time series data. When downsampling or upsampling, the syntax is similar, but the methods called are different. Both use the concept of &#39;method chaining&#39; - &lt;code&gt;df.method1().method2().method3()&lt;/code&gt; - to direct the output from one method call to the input of the next, and so on, as a sequence of operations, one feeding into the next. &lt;/p&gt;\\n&lt;p&gt;For example, if you have hourly data, and just need daily data, pandas will not guess how to throw out the 23 of 24 points. You must specify this in the method. One approach, for instance, could be to take the mean, as in &lt;code&gt;df.resample(&#39;D&#39;).mean()&lt;/code&gt;. &lt;/p&gt;\\n&lt;p&gt;In this exercise, a data set containing hourly temperature data has been pre-loaded for you. Your job is to resample the data using a variety of aggregation methods to answer a few questions.&lt;/p&gt;&quot;,&quot;feedbacks&quot;,[&quot;^19&quot;,[]],&quot;attachments&quot;,null,&quot;title&quot;,&quot;Resampling and frequency&quot;,&quot;xp&quot;,100,&quot;language&quot;,&quot;python&quot;,&quot;pre_exercise_code&quot;,&quot;import pandas as pd\\nfile_name = \\&quot;/usr/local/share/datasets/weather_data_austin_2010.csv\\&quot;\\ndf = pd.read_csv(file_name, index_col=&#39;Date&#39;, parse_dates=True)\\n\\ndel file_name&quot;,&quot;solution&quot;,&quot;# Downsample to 6 hour data and aggregate by mean: df1\\ndf1 = df[&#39;Temperature&#39;].resample(&#39;6h&#39;).mean()\\n\\n# Downsample to daily data and count the number of data points: df2\\ndf2 = df[&#39;Temperature&#39;].resample(&#39;D&#39;).count()&quot;,&quot;type&quot;,&quot;NormalExercise&quot;,&quot;id&quot;,44356]],[&quot;^0&quot;,[&quot;sample_code&quot;,&quot;# Extract temperature data for August: august\\naugust = ____\\n\\n# Downsample to obtain only the daily highest temperatures in August: august_highs\\naugust_highs = ____\\n\\n# Extract temperature data for February: february\\nfebruary = ____\\n\\n# Downsample to obtain the daily lowest temperatures in February: february_lows\\nfebruary_lows = ____&quot;,&quot;sct&quot;,&quot;Ex().check_object(\\&quot;august\\&quot;).has_equal_value(&#39;Did you select the `Temperature` column for only `2010-August` from `df`?&#39;)\\n\\nEx().check_correct(\\n\\tcheck_object(\\&quot;august_highs\\&quot;).has_equal_value(),\\n  \\thas_equal_ast(code = &#39;august.resample(\\\\&#39;D\\\\&#39;).max()&#39;, incorrect_msg = \\&quot;Did you resample `august` correctly using `.resample(&#39;D&#39;)` and `.max()`?\\&quot;)\\n)\\n\\nEx().check_object(\\&quot;february\\&quot;).has_equal_value(&#39;Did you select the `Temperature` column for only `2010-Feb` from `df`?&#39;)\\n\\nEx().check_correct(\\n\\tcheck_object(\\&quot;february_lows\\&quot;).has_equal_value(),\\n  \\thas_equal_ast(code = &#39;february.resample(\\\\&#39;D\\\\&#39;).min()&#39;, incorrect_msg = \\&quot;Did you resample `february` correctly using `.resample(&#39;D&#39;)` and `.min()`?\\&quot;)\\n)\\n\\nsuccess_msg(\\&quot;Great work!\\&quot;)&quot;,&quot;instructions&quot;,&quot;&lt;ul&gt;\\n&lt;li&gt;Use partial string indexing to extract temperature data for August 2010 into &lt;code&gt;august&lt;/code&gt;.&lt;/li&gt;\\n&lt;li&gt;Use the temperature data for August and downsample to find the daily maximum temperatures. Store the result in &lt;code&gt;august_highs&lt;/code&gt;.&lt;/li&gt;\\n&lt;li&gt;Use partial string indexing to extract temperature data for February 2010 into &lt;code&gt;february&lt;/code&gt;.&lt;/li&gt;\\n&lt;li&gt;Use the temperature data for February and downsample to find the daily minimum temperatures. Store the result in &lt;code&gt;february_lows&lt;/code&gt;.&lt;/li&gt;\\n&lt;/ul&gt;&quot;,&quot;externalId&quot;,46425,&quot;question&quot;,&quot;&quot;,&quot;hint&quot;,&quot;&lt;ul&gt;\\n&lt;li&gt;To extract September 2010 from &lt;code&gt;df&lt;/code&gt; using partial string indexing, you can use &lt;code&gt;df[&#39;Temperature&#39;][&#39;2010-September&#39;]&lt;/code&gt;. Do this for August 2010.&lt;/li&gt;\\n&lt;li&gt;You need to downsample to daily data, so the relevant method is &lt;code&gt;.resample(&#39;D&#39;)&lt;/code&gt;. Then, you want the maximum daily temperaturs, so you will also have to chain &lt;code&gt;.max()&lt;/code&gt; onto &lt;code&gt;.resample(&#39;D&#39;)&lt;/code&gt;.&lt;/li&gt;\\n&lt;li&gt;Follow the approach you used to extract the August 2010 data from &lt;code&gt;df[&#39;Temperature&#39;]&lt;/code&gt; to extract the data for February 2010.&lt;/li&gt;\\n&lt;li&gt;As before, you need to downsample to daily data, so you need to use &lt;code&gt;.resample(&#39;D&#39;)&lt;/code&gt; on the February data. Since you now want the minimum daily temperatures, you will have to chain &lt;code&gt;.min()&lt;/code&gt; to &lt;code&gt;.resample(&#39;D&#39;)&lt;/code&gt;.&lt;/li&gt;\\n&lt;/ul&gt;&quot;,&quot;possible_answers&quot;,[&quot;^19&quot;,[]],&quot;number&quot;,8,&quot;randomNumber&quot;,0.7088183603186637,&quot;assignment&quot;,&quot;&lt;p&gt;With pandas, you can resample in different ways on different subsets of your data. For example, resampling different months of data with different aggregations. In this exercise, the data set containing hourly temperature data from the last exercise has been pre-loaded. &lt;/p&gt;\\n&lt;p&gt;Your job is to resample the data using a variety of aggregation methods. The DataFrame is available in the workspace as &lt;code&gt;df&lt;/code&gt;. You will be working with the &lt;code&gt;&#39;Temperature&#39;&lt;/code&gt; column.&lt;/p&gt;&quot;,&quot;feedbacks&quot;,[&quot;^19&quot;,[]],&quot;attachments&quot;,null,&quot;title&quot;,&quot;Separating and resampling&quot;,&quot;xp&quot;,100,&quot;language&quot;,&quot;python&quot;,&quot;pre_exercise_code&quot;,&quot;import pandas as pd\\nfile_name = \\&quot;/usr/local/share/datasets/weather_data_austin_2010.csv\\&quot;\\ndf = pd.read_csv(file_name, index_col=&#39;Date&#39;, parse_dates=True)\\n\\ndel file_name&quot;,&quot;solution&quot;,&quot;# Extract temperature data for August: august\\naugust = df[&#39;Temperature&#39;][&#39;2010-August&#39;]\\n\\n# Downsample to obtain only the daily highest temperatures in August: august_highs\\naugust_highs = august.resample(&#39;D&#39;).max()\\n\\n# Extract temperature data for February: february\\nfebruary = df[&#39;Temperature&#39;][&#39;2010-Feb&#39;]\\n\\n# Downsample to obtain the daily lowest temperatures in February: february_lows\\nfebruary_lows = february.resample(&#39;D&#39;).min()&quot;,&quot;type&quot;,&quot;NormalExercise&quot;,&quot;id&quot;,46425]],[&quot;^0&quot;,[&quot;sample_code&quot;,&quot;# Extract data from 2010-Aug-01 to 2010-Aug-15: unsmoothed\\nunsmoothed = df[&#39;Temperature&#39;][____:____]\\n\\n# Apply a rolling mean with a 24 hour window: smoothed\\nsmoothed = ____\\n\\n# Create a new DataFrame with columns smoothed and unsmoothed: august\\naugust = pd.DataFrame({&#39;smoothed&#39;:____, &#39;unsmoothed&#39;:____})\\n\\n# Plot both smoothed and unsmoothed data using august.plot().\\n____\\nplt.show()&quot;,&quot;sct&quot;,&quot;Ex().check_object(\\&quot;unsmoothed\\&quot;).has_equal_value(\\&quot;The contents of `unsmoothed` are incorrect. Did you correctly extract `&#39;2010-Aug-01&#39;:&#39;2010-Aug-15&#39;` from `df[&#39;Temperature&#39;]`?\\&quot;)\\n\\nEx().check_correct(\\n\\tcheck_object(\\&quot;smoothed\\&quot;).has_equal_value(),\\n  \\thas_equal_ast(code = &#39;unsmoothed.rolling(window=24).mean()&#39;, incorrect_msg = \\&quot;Did you apply a rolling mean to `unsmoothed` using `.rolling(window=24)` and `.mean()`?\\&quot;)\\n)\\n\\nEx().check_correct(\\n\\tcheck_object(\\&quot;august\\&quot;).has_equal_value(),\\n    multi(\\n    \\tcheck_function(\\&quot;pandas.DataFrame\\&quot;),\\n        has_equal_ast(code = \\&quot;{&#39;smoothed&#39;:smoothed, &#39;unsmoothed&#39;:unsmoothed}\\&quot;, incorrect_msg = \\&quot;Did you create the columns `&#39;smoothed&#39;` and `&#39;unsmoothed&#39;` using `smoothed` and `unsmoothed` in a dictionary?\\&quot;)\\n    )\\n)\\n\\nEx().check_function(\\&quot;august.plot\\&quot;)\\nEx().check_function(\\&quot;matplotlib.pyplot.show\\&quot;)\\n\\nsuccess_msg(\\&quot;Well done!\\&quot;)&quot;,&quot;instructions&quot;,&quot;&lt;ul&gt;\\n&lt;li&gt;Use partial string indexing to extract temperature data from August 1 2010 to August 15 2010. Assign to &lt;code&gt;unsmoothed&lt;/code&gt;.&lt;/li&gt;\\n&lt;li&gt;Use &lt;code&gt;.rolling()&lt;/code&gt; with a 24 hour window to smooth the mean temperature data. Assign the result to &lt;code&gt;smoothed&lt;/code&gt;.&lt;/li&gt;\\n&lt;li&gt;Use a dictionary to create a new DataFrame &lt;code&gt;august&lt;/code&gt; with the time series &lt;code&gt;smoothed&lt;/code&gt; and &lt;code&gt;unsmoothed&lt;/code&gt; as columns.&lt;/li&gt;\\n&lt;li&gt;Plot both the columns of &lt;code&gt;august&lt;/code&gt; as line plots using the &lt;code&gt;.plot()&lt;/code&gt; method.&lt;/li&gt;\\n&lt;/ul&gt;&quot;,&quot;externalId&quot;,44357,&quot;question&quot;,&quot;&quot;,&quot;hint&quot;,&quot;&lt;ul&gt;\\n&lt;li&gt;You can extract the appropriate temperature data by passing in &lt;code&gt;&#39;2010-Aug-01&#39;&lt;/code&gt; and &lt;code&gt;&#39;2010-Aug-15&#39;&lt;/code&gt; separated by the &lt;code&gt;:&lt;/code&gt;.&lt;/li&gt;\\n&lt;li&gt;Using method chaining, you can chain &lt;code&gt;.rolling()&lt;/code&gt; onto &lt;code&gt;unsmoothed&lt;/code&gt; using &lt;code&gt;unsmoothed.rolling()&lt;/code&gt;. Inside &lt;code&gt;.rolling()&lt;/code&gt;, you will have to specify &lt;code&gt;window=24&lt;/code&gt;, and then chain &lt;code&gt;.mean()&lt;/code&gt; onto &lt;code&gt;unsmoothed.rolling()&lt;/code&gt;.&lt;/li&gt;\\n&lt;li&gt;You can use the &lt;code&gt;pd.DataFrame()&lt;/code&gt; function and pass in a dictionary with keys &lt;code&gt;&#39;smoothed&#39;&lt;/code&gt; and &lt;code&gt;&#39;unsmoothed&#39;&lt;/code&gt; and values &lt;code&gt;smoothed&lt;/code&gt; and &lt;code&gt;unsmoothed&lt;/code&gt;.&lt;/li&gt;\\n&lt;li&gt;You can plot &lt;code&gt;august&lt;/code&gt; using &lt;code&gt;august.plot()&lt;/code&gt;.&lt;/li&gt;\\n&lt;/ul&gt;&quot;,&quot;possible_answers&quot;,[&quot;^19&quot;,[]],&quot;number&quot;,9,&quot;randomNumber&quot;,0.05604666634510802,&quot;assignment&quot;,&quot;&lt;p&gt;In this exercise, some hourly weather data is pre-loaded for you. You will continue to practice resampling, this time using rolling means.&lt;/p&gt;\\n&lt;p&gt;Rolling means (or moving averages) are generally used to smooth out short-term fluctuations in time series data and highlight long-term trends. You can read more about them &lt;a href=\\&quot;https://en.wikipedia.org/wiki/Moving_average\\&quot;&gt;here&lt;/a&gt;.  &lt;/p&gt;\\n&lt;p&gt;To use the &lt;code&gt;.rolling()&lt;/code&gt; method, you must always use method chaining, first calling &lt;code&gt;.rolling()&lt;/code&gt; and then chaining an aggregation method after it. For example, with a Series &lt;code&gt;hourly_data&lt;/code&gt;, &lt;code&gt;hourly_data.rolling(window=24).mean()&lt;/code&gt; would compute new values for each hourly point, based on a 24-hour window stretching out &lt;strong&gt;behind&lt;/strong&gt; each point. The frequency of the output data is the same: it is still hourly. Such an operation is useful for smoothing time series data. &lt;/p&gt;\\n&lt;p&gt;Your job is to resample the data using the combination of &lt;code&gt;.rolling()&lt;/code&gt; and &lt;code&gt;.mean()&lt;/code&gt;. You will work with the same DataFrame &lt;code&gt;df&lt;/code&gt; from the previous exercise.&lt;/p&gt;&quot;,&quot;feedbacks&quot;,[&quot;^19&quot;,[]],&quot;attachments&quot;,null,&quot;title&quot;,&quot;Rolling mean and frequency&quot;,&quot;xp&quot;,100,&quot;language&quot;,&quot;python&quot;,&quot;pre_exercise_code&quot;,&quot;import pandas as pd\\nfile_name = \\&quot;/usr/local/share/datasets/weather_data_austin_2010.csv\\&quot;\\ndf = pd.read_csv(file_name, index_col=&#39;Date&#39;, parse_dates=True)\\ndel file_name\\nimport matplotlib.pyplot as plt&quot;,&quot;solution&quot;,&quot;# Extract data from 2010-Aug-01 to 2010-Aug-15: unsmoothed\\nunsmoothed = df[&#39;Temperature&#39;][&#39;2010-Aug-01&#39;:&#39;2010-Aug-15&#39;]\\n\\n# Apply a rolling mean with a 24 hour window: smoothed\\nsmoothed = unsmoothed.rolling(window=24).mean()\\n\\n# Create a new DataFrame with columns smoothed and unsmoothed: august\\naugust = pd.DataFrame({&#39;smoothed&#39;:smoothed, &#39;unsmoothed&#39;:unsmoothed})\\n\\n# Plot both smoothed and unsmoothed data using august.plot().\\naugust.plot()\\nplt.show()&quot;,&quot;type&quot;,&quot;NormalExercise&quot;,&quot;id&quot;,44357]],[&quot;^0&quot;,[&quot;sample_code&quot;,&quot;# Extract the August 2010 data: august\\naugust = df[&#39;Temperature&#39;][____]\\n\\n# Resample to daily data, aggregating by max: daily_highs\\ndaily_highs = ____\\n\\n# Use a rolling 7-day window with method chaining to smooth the daily high temperatures in August\\ndaily_highs_smoothed = ____\\nprint(____)&quot;,&quot;sct&quot;,&quot;Ex().check_object(\\&quot;august\\&quot;).has_equal_value(&#39;Did you select the `Temperature` column for only `2010-August` from `df`?&#39;)\\n\\nEx().check_correct(\\n\\tcheck_object(&#39;daily_highs&#39;).has_equal_value(),\\n  \\thas_equal_ast(code = &#39;august.resample(\\\\&#39;D\\\\&#39;).max()&#39;, incorrect_msg = \\&quot;Did you resample `august` by day (`&#39;D&#39;`) and call `.max()` to create `daily_highs`?\\&quot;)\\n)\\n\\nEx().check_correct(\\n\\tcheck_object(&#39;daily_highs_smoothed&#39;).has_equal_value(),\\n  \\thas_equal_ast(code = &#39;august.resample(\\\\&#39;D\\\\&#39;).max().rolling(window=7).mean()&#39;, incorrect_msg = \\&quot;Did you resample `august` by day (`&#39;D&#39;`), call `.max()`, create a rolling window of 7 days, and call `.mean()` to create `daily_highs_smoothed`?\\&quot;)\\n)\\n\\nEx().check_function(\\&quot;print\\&quot;).check_args(0).has_equal_value()\\n\\nsuccess_msg(\\&quot;Fantastic!\\&quot;)&quot;,&quot;instructions&quot;,&quot;&lt;ul&gt;\\n&lt;li&gt;Use partial string indexing to extract August 2010 temperature data, and assign to &lt;code&gt;august&lt;/code&gt;.&lt;/li&gt;\\n&lt;li&gt;Resample to daily frequency, saving the maximum daily temperatures, and assign the result to &lt;code&gt;daily_highs&lt;/code&gt;.&lt;/li&gt;\\n&lt;li&gt;As part of one long method chain, repeat the above resampling (or you can re-use &lt;code&gt;daily_highs&lt;/code&gt;) and then combine it with &lt;code&gt;.rolling()&lt;/code&gt; to apply a 7 day &lt;code&gt;.mean()&lt;/code&gt; (with &lt;code&gt;window=7&lt;/code&gt; inside &lt;code&gt;.rolling()&lt;/code&gt;) so as to smooth the daily highs. Assign the result to &lt;code&gt;daily_highs_smoothed&lt;/code&gt; and print the result.&lt;/li&gt;\\n&lt;/ul&gt;&quot;,&quot;externalId&quot;,46426,&quot;question&quot;,&quot;&quot;,&quot;hint&quot;,&quot;&lt;ul&gt;\\n&lt;li&gt;You can extract the temperature for October 2010 using &lt;code&gt;df[&#39;Temperature&#39;][&#39;2010-Oct&#39;]&lt;/code&gt;. Follow this template to extract the August 2010 data.&lt;/li&gt;\\n&lt;li&gt;To downsample to daily frequency and take the maximum daily temperature, you will have to chain together &lt;code&gt;.resample(&#39;D&#39;)&lt;/code&gt; and &lt;code&gt;.max()&lt;/code&gt;.&lt;/li&gt;\\n&lt;li&gt;Build from the above downsampling code to chain onto it &lt;code&gt;.rolling()&lt;/code&gt; and &lt;code&gt;.mean()&lt;/code&gt;. Inside &lt;code&gt;.rolling()&lt;/code&gt;, specify &lt;code&gt;window=7&lt;/code&gt;.&lt;/li&gt;\\n&lt;li&gt;Print &lt;code&gt;daily_highs_smoothed&lt;/code&gt;.&lt;/li&gt;\\n&lt;/ul&gt;&quot;,&quot;possible_answers&quot;,[&quot;^19&quot;,[]],&quot;number&quot;,10,&quot;randomNumber&quot;,0.05369142281268635,&quot;assignment&quot;,&quot;&lt;p&gt;As of pandas version 0.18.0, the interface for applying rolling transformations to time series has become more consistent and flexible, and feels somewhat like a &lt;code&gt;groupby&lt;/code&gt; (If you do not know what a &lt;code&gt;groupby&lt;/code&gt; is, don&#39;t worry, you will learn about it in the next course!). &lt;/p&gt;\\n&lt;p&gt;You can now flexibly chain together resampling and rolling operations. In this exercise, the same weather data from the previous exercises has been pre-loaded for you. Your job is to extract one month of data, resample to find the daily high temperatures, and then use a rolling and aggregation operation to smooth the data.&lt;/p&gt;&quot;,&quot;feedbacks&quot;,[&quot;^19&quot;,[]],&quot;attachments&quot;,null,&quot;title&quot;,&quot;Resample and roll with it&quot;,&quot;xp&quot;,100,&quot;language&quot;,&quot;python&quot;,&quot;pre_exercise_code&quot;,&quot;import pandas as pd\\nfile_name = \\&quot;/usr/local/share/datasets/weather_data_austin_2010.csv\\&quot;\\ndf = pd.read_csv(file_name, index_col=&#39;Date&#39;, parse_dates=True)\\n\\ndel file_name\\n&quot;,&quot;solution&quot;,&quot;# Extract the August 2010 data: august\\naugust = df[&#39;Temperature&#39;][&#39;2010-Aug&#39;]\\n\\n# Resample to daily data, aggregating by max: daily_highs\\ndaily_highs = august.resample(&#39;D&#39;).max()\\n\\n# Use a rolling 7-day window with method chaining to smooth the daily high temperatures in August\\ndaily_highs_smoothed = august.resample(&#39;D&#39;).max().rolling(window=7).mean()\\nprint(daily_highs_smoothed)&quot;,&quot;type&quot;,&quot;NormalExercise&quot;,&quot;id&quot;,46426]],[&quot;^0&quot;,[&quot;sample_code&quot;,&quot;&quot;,&quot;sct&quot;,&quot;&quot;,&quot;aspect_ratio&quot;,56.25,&quot;instructions&quot;,null,&quot;externalId&quot;,44359,&quot;question&quot;,&quot;&quot;,&quot;hint&quot;,null,&quot;possible_answers&quot;,[&quot;^19&quot;,[]],&quot;number&quot;,11,&quot;video_hls&quot;,&quot;//videos.datacamp.com/transcoded/1639_pandas-1/v2/hls-ch3_3.master.m3u8&quot;,&quot;randomNumber&quot;,0.14588042868998619,&quot;assignment&quot;,null,&quot;feedbacks&quot;,[&quot;^19&quot;,[]],&quot;attachments&quot;,null,&quot;title&quot;,&quot;Manipulating pandas time series&quot;,&quot;xp&quot;,50,&quot;language&quot;,&quot;python&quot;,&quot;pre_exercise_code&quot;,&quot;&quot;,&quot;solution&quot;,&quot;&quot;,&quot;type&quot;,&quot;VideoExercise&quot;,&quot;id&quot;,44359,&quot;projector_key&quot;,&quot;course_1639_79c11eb139ae230bf613e743dcc60ed8&quot;,&quot;video_link&quot;,null]],[&quot;^0&quot;,[&quot;sample_code&quot;,&quot;# Strip extra whitespace from the column names: df.columns\\ndf.columns = ____\\n\\n# Extract data for which the destination airport is Dallas: dallas\\ndallas = df[&#39;Destination Airport&#39;].____.____(____)\\n\\n# Compute the total number of Dallas departures each day: daily_departures\\ndaily_departures = ____\\n\\n# Generate the summary statistics for daily Dallas departures: stats\\nstats = ____&quot;,&quot;sct&quot;,&quot;Ex().check_correct(\\n\\tcheck_object(\\&quot;df\\&quot;).has_equal_value(),\\n  \\tcheck_function(\\&quot;df.columns.str.strip\\&quot;)\\n)\\n\\nEx().check_correct(\\n\\tcheck_object(&#39;dallas&#39;).has_equal_value(),\\n\\thas_equal_ast(\\&quot;Did you correctly extract the `&#39;DAL&#39;` entries in the `&#39;Destination Airport&#39;` column of `df`?\\&quot;,\\n                   code=\\&quot;df[&#39;Destination Airport&#39;].str.contains(&#39;DAL&#39;)\\&quot;,\\n                   exact=False)  \\n)\\n         \\nEx().check_correct(\\n\\tcheck_object(\\&quot;daily_departures\\&quot;).has_equal_value(),\\n    has_equal_ast(code = &#39;dallas.resample(\\\\&#39;D\\\\&#39;).sum()&#39;, incorrect_msg = &#39;Did you resample `dallas` by days and call `.sum()`?&#39;)\\n)    \\n\\nEx().check_correct(\\n\\tcheck_object(\\&quot;stats\\&quot;).has_equal_value(),\\n  \\tcheck_function(\\&quot;daily_departures.describe\\&quot;)\\n)\\n\\nsuccess_msg(\\&quot;Great work! You&#39;ll return to this dataset later in this chapter.\\&quot;)&quot;,&quot;instructions&quot;,&quot;&lt;ul&gt;\\n&lt;li&gt;Use &lt;code&gt;.str.strip()&lt;/code&gt; to strip extra whitespace from &lt;code&gt;df.columns&lt;/code&gt;. Assign the result back to &lt;code&gt;df.columns&lt;/code&gt;.&lt;/li&gt;\\n&lt;li&gt;In the &lt;code&gt;&#39;Destination Airport&#39;&lt;/code&gt; column, extract all entries where Dallas (&lt;code&gt;&#39;DAL&#39;&lt;/code&gt;) is the destination airport. Use &lt;code&gt;.str.contains(&#39;DAL&#39;)&lt;/code&gt; for this and store the result in &lt;code&gt;dallas&lt;/code&gt;.&lt;/li&gt;\\n&lt;li&gt;Resample &lt;code&gt;dallas&lt;/code&gt; such that you get the total number of departures each day. Store the result in &lt;code&gt;daily_departures&lt;/code&gt;. &lt;/li&gt;\\n&lt;li&gt;Generate summary statistics for daily Dallas departures using &lt;code&gt;.describe()&lt;/code&gt;. Store the result in &lt;code&gt;stats&lt;/code&gt;.&lt;/li&gt;\\n&lt;/ul&gt;&quot;,&quot;externalId&quot;,44360,&quot;question&quot;,&quot;&quot;,&quot;hint&quot;,&quot;&lt;ul&gt;\\n&lt;li&gt;Use &lt;code&gt;df.columns.str.strip()&lt;/code&gt; to strip extra whitespace from the column names. &lt;/li&gt;\\n&lt;li&gt;You will have to use &lt;code&gt;.str.contains(&#39;DAL&#39;)&lt;/code&gt; on &lt;code&gt;df[&#39;Destination Airport&#39;]&lt;/code&gt; to extract all entries where the Dallas is the destination airport.&lt;/li&gt;\\n&lt;li&gt;To resample &lt;code&gt;dallas&lt;/code&gt; by day and get the total number of departures, you will have to first use &lt;code&gt;.resample()&lt;/code&gt; with &lt;code&gt;&#39;D&#39;&lt;/code&gt; and then chain &lt;code&gt;.sum()&lt;/code&gt; to it.&lt;/li&gt;\\n&lt;li&gt;Use &lt;code&gt;resample(&#39;D&#39;).sum()&lt;/code&gt; to get to total number of Dallas departures each day.&lt;/li&gt;\\n&lt;li&gt;Use the &lt;code&gt;.describe()&lt;/code&gt; method on &lt;code&gt;daily_departures&lt;/code&gt; to generate summary statistics.&lt;/li&gt;\\n&lt;/ul&gt;&quot;,&quot;possible_answers&quot;,[&quot;^19&quot;,[]],&quot;number&quot;,12,&quot;randomNumber&quot;,0.7368318329583405,&quot;assignment&quot;,&quot;&lt;p&gt;We&#39;ve seen that pandas supports method chaining. This technique can be very powerful when cleaning and filtering data. &lt;/p&gt;\\n&lt;p&gt;In this exercise, a DataFrame containing flight departure data for a single airline and a single airport for the month of July 2015 has been pre-loaded. Your job is to use &lt;code&gt;.str()&lt;/code&gt; filtering and method chaining to generate summary statistics on flight delays each day to Dallas.&lt;/p&gt;&quot;,&quot;feedbacks&quot;,[&quot;^19&quot;,[]],&quot;attachments&quot;,null,&quot;title&quot;,&quot;Method chaining and filtering&quot;,&quot;xp&quot;,100,&quot;language&quot;,&quot;python&quot;,&quot;pre_exercise_code&quot;,&quot;import pandas as pd\\n# Data file obtained as CSV from http://apps.bts.gov/xml/ontimesummarystatistics/src/dstat/OntimeSummaryDepatures.xml\\nfile_name= \\&quot;/usr/local/share/datasets/austin_airport_departure_data_2015_july.csv\\&quot;\\ndf = pd.read_csv(file_name, \\n                 skiprows=range(0,15), \\n                 parse_dates=True, \\n                 index_col=&#39;Date (MM/DD/YYYY)&#39;)\\ndel file_name&quot;,&quot;solution&quot;,&quot;# Strip extra whitespace from the column names: df.columns\\ndf.columns = df.columns.str.strip()\\n\\n# Extract data for which the destination airport is Dallas: dallas\\ndallas = df[&#39;Destination Airport&#39;].str.contains(&#39;DAL&#39;)\\n\\n# Compute the total number of Dallas departures each day: daily_departures\\ndaily_departures = dallas.resample(&#39;D&#39;).sum()\\n\\n# Generate the summary statistics for daily Dallas departures: stats\\nstats = daily_departures.describe()&quot;,&quot;type&quot;,&quot;NormalExercise&quot;,&quot;id&quot;,44360]],[&quot;^0&quot;,[&quot;sample_code&quot;,&quot;# Reset the index of ts2 to ts1, and then use linear interpolation to fill in the NaNs: ts2_interp\\nts2_interp = ____\\n\\n# Compute the absolute difference of ts1 and ts2_interp: differences \\ndifferences = ____\\n\\n# Generate and print summary statistics of the differences\\nprint(____)&quot;,&quot;sct&quot;,&quot;Ex().check_correct(\\n  \\tcheck_object(&#39;ts2_interp&#39;).has_equal_value(),\\n   \\thas_equal_ast(code = &#39;ts2.reindex(ts1.index).interpolate(how=\\\\&#39;linear\\\\&#39;)&#39;, incorrect_msg = &#39;Did you reindex `ts2` using the index from `ts1`, then interpolate linearly to create `ts2`?&#39;)\\n)\\n\\nEx().check_correct(\\n\\tcheck_object(\\&quot;differences\\&quot;).has_equal_value(),\\n  \\tcheck_function(\\&quot;numpy.abs\\&quot;, signature = sig_from_obj(&#39;numpy.abs&#39;)) # order of difference doesn&#39;t matter\\n)\\n\\nEx().check_function(\\&quot;print\\&quot;).check_args(0).has_equal_value()\\n\\nsuccess_msg(\\&quot;Well done!\\&quot;)&quot;,&quot;instructions&quot;,&quot;&lt;ul&gt;\\n&lt;li&gt;Replace the index of &lt;code&gt;ts2&lt;/code&gt; with that of &lt;code&gt;ts1&lt;/code&gt;, and then fill in the missing values of &lt;code&gt;ts2&lt;/code&gt; by using &lt;code&gt;.interpolate(how=&#39;linear&#39;)&lt;/code&gt;. Save the result as &lt;code&gt;ts2_interp&lt;/code&gt;.&lt;/li&gt;\\n&lt;li&gt;Compute the difference between &lt;code&gt;ts1&lt;/code&gt; and &lt;code&gt;ts2_interp&lt;/code&gt;. Take the absolute value of the difference with &lt;code&gt;np.abs()&lt;/code&gt;, and assign the result to &lt;code&gt;differences&lt;/code&gt;.&lt;/li&gt;\\n&lt;li&gt;Generate and print summary statistics of the &lt;code&gt;differences&lt;/code&gt; with &lt;code&gt;.describe()&lt;/code&gt; and &lt;code&gt;print()&lt;/code&gt;.&lt;/li&gt;\\n&lt;/ul&gt;&quot;,&quot;externalId&quot;,44361,&quot;question&quot;,&quot;&quot;,&quot;hint&quot;,&quot;&lt;ul&gt;\\n&lt;li&gt;To reindex &lt;code&gt;ts2&lt;/code&gt; using the index of &lt;code&gt;ts1&lt;/code&gt;, use the &lt;code&gt;.reindex()&lt;/code&gt; method with &lt;code&gt;ts1.index&lt;/code&gt; as the argument. After this, you can chain the &lt;code&gt;.interpolate()&lt;/code&gt; method with the keyword argument &lt;code&gt;how=&#39;linear&#39;&lt;/code&gt;.&lt;/li&gt;\\n&lt;li&gt;Make sure you use &lt;code&gt;np.abs()&lt;/code&gt; to take the absolute value of the difference between &lt;code&gt;ts1&lt;/code&gt; and &lt;code&gt;ts2_interp&lt;/code&gt;.&lt;/li&gt;\\n&lt;li&gt;You can generate summary statistics of the differences using &lt;code&gt;.describe()&lt;/code&gt;, and print these statistics with &lt;code&gt;print()&lt;/code&gt;.&lt;/li&gt;\\n&lt;/ul&gt;&quot;,&quot;possible_answers&quot;,[&quot;^19&quot;,[]],&quot;number&quot;,13,&quot;randomNumber&quot;,0.6705666660342386,&quot;assignment&quot;,&quot;&lt;p&gt;One common application of interpolation in data analysis is to fill in missing data. &lt;/p&gt;\\n&lt;p&gt;In this exercise, noisy measured data that has some dropped or otherwise missing values has been loaded. The goal is to compare two time series, and then look at summary statistics of the differences. The problem is that one of the data sets is missing data at some of the times. The pre-loaded data &lt;code&gt;ts1&lt;/code&gt; has value for all times, yet the data set &lt;code&gt;ts2&lt;/code&gt; does not: it is missing data for the weekends. &lt;/p&gt;\\n&lt;p&gt;Your job is to first interpolate to fill in the data for all days. Then, compute the differences between the two data sets, now that they both have full support for all times. Finally, generate the summary statistics that describe the distribution of differences.&lt;/p&gt;&quot;,&quot;feedbacks&quot;,[&quot;^19&quot;,[]],&quot;attachments&quot;,null,&quot;title&quot;,&quot;Missing values and interpolation&quot;,&quot;xp&quot;,100,&quot;language&quot;,&quot;python&quot;,&quot;pre_exercise_code&quot;,&quot;import numpy as np\\nimport pandas as pd\\n\\n# Create Series that includes weekends\\ndates1 = pd.to_datetime([&#39;2016-07-01&#39;,\\n                         &#39;2016-07-02&#39;,&#39;2016-07-03&#39;,\\n                         &#39;2016-07-04&#39;,&#39;2016-07-05&#39;,&#39;2016-07-06&#39;,&#39;2016-07-07&#39;,&#39;2016-07-08&#39;,\\n                         &#39;2016-07-09&#39;,&#39;2016-07-10&#39;,\\n                         &#39;2016-07-11&#39;,&#39;2016-07-12&#39;,&#39;2016-07-13&#39;,&#39;2016-07-14&#39;,&#39;2016-07-15&#39;,\\n                         &#39;2016-07-16&#39;,&#39;2016-07-17&#39;])\\ndata1 = range(len(dates1))\\nts1 = pd.Series(data1, index=dates1)\\n\\n# Create Series that does NOT include weekends\\ndates2 = pd.to_datetime([&#39;2016-07-01&#39;,\\n                         &#39;2016-07-04&#39;,&#39;2016-07-05&#39;,&#39;2016-07-06&#39;,&#39;2016-07-07&#39;,&#39;2016-07-08&#39;,\\n                         &#39;2016-07-11&#39;,&#39;2016-07-12&#39;,&#39;2016-07-13&#39;,&#39;2016-07-14&#39;,&#39;2016-07-15&#39;])\\ndata2 = range(len(dates2))\\nts2 = pd.Series(data2, index=dates2)&quot;,&quot;solution&quot;,&quot;# Reset the index of ts2 to ts1, and then use linear interpolation to fill in the NaNs: ts2_interp\\nts2_interp = ts2.reindex(ts1.index).interpolate(how=&#39;linear&#39;)\\n\\n# Compute the absolute difference of ts1 and ts2_interp: differences \\ndifferences = np.abs(ts1 - ts2_interp)\\n\\n# Generate and print summary statistics of the differences\\nprint(differences.describe())&quot;,&quot;type&quot;,&quot;NormalExercise&quot;,&quot;id&quot;,44361]],[&quot;^0&quot;,[&quot;sample_code&quot;,&quot;# Build a Boolean mask to filter out all the &#39;LAX&#39; departure flights: mask\\nmask = df[&#39;Destination Airport&#39;] == ____\\n\\n# Use the mask to subset the data: la\\nla = df[____]\\n\\n# Combine two columns of data to create a datetime series: times_tz_none \\ntimes_tz_none = pd.____( ____ + &#39; &#39; + ____ )\\n\\n# Localize the time to US/Central: times_tz_central\\ntimes_tz_central = ____\\n\\n# Convert the datetimes from US/Central to US/Pacific\\ntimes_tz_pacific = ____&quot;,&quot;sct&quot;,&quot;Ex().check_object(\\&quot;mask\\&quot;).has_equal_value()\\n\\nEx().check_object(\\&quot;la\\&quot;).has_equal_value()\\n\\n# Ex().check_correct()\\n# test_function(\\&quot;pandas.to_datetime\\&quot;)\\n# test_object(\\&quot;times_tz_none\\&quot;)\\n\\nEx().check_correct(\\n\\tcheck_object(&#39;times_tz_central&#39;).has_equal_value(),\\n  \\thas_equal_ast(code = &#39;times_tz_none.dt.tz_localize(\\\\&#39;US/Central\\\\&#39;)&#39;, incorrect_msg = &#39;Did you call `dt.tz_localize` to set `times_tz_central` to the `\\\\&#39;US/Central\\\\&#39;` time zone?&#39;)\\n)\\n\\nEx().check_correct(\\n\\tcheck_object(&#39;times_tz_pacific&#39;).has_equal_value(),\\n  \\thas_equal_ast(code = &#39;times_tz_central.dt.tz_convert(\\\\&#39;US/Pacific\\\\&#39;)&#39;, incorrect_msg = &#39;Did you create `times_tz_pacific` by calling `dt.tz_convert` to convert `times_tz_central` to the `\\\\&#39;US/Pacific\\\\&#39;` time zone?&#39;)\\n)\\n\\nsuccess_msg(\\&quot;Wonderful work!\\&quot;)&quot;,&quot;instructions&quot;,&quot;&lt;ul&gt;\\n&lt;li&gt;Create a Boolean mask, &lt;code&gt;mask&lt;/code&gt;, such that if the &lt;code&gt;&#39;Destination Airport&#39;&lt;/code&gt; column of &lt;code&gt;df&lt;/code&gt; equals &lt;code&gt;&#39;LAX&#39;&lt;/code&gt;, the result is &lt;code&gt;True&lt;/code&gt;, and otherwise, it is &lt;code&gt;False&lt;/code&gt;.&lt;/li&gt;\\n&lt;li&gt;Use the mask to extract only the &lt;code&gt;LAX&lt;/code&gt; rows. Assign the result to &lt;code&gt;la&lt;/code&gt;.&lt;/li&gt;\\n&lt;li&gt;Concatenate the two columns &lt;code&gt;la[&#39;Date (MM/DD/YYYY)&#39;]&lt;/code&gt; and &lt;code&gt;la[&#39;Wheels-off Time&#39;]&lt;/code&gt; with a &lt;code&gt;&#39; &#39;&lt;/code&gt; space in between. Pass this to &lt;code&gt;pd.to_datetime()&lt;/code&gt; to create a datetime array of all the times the LAX-bound flights left the ground.&lt;/li&gt;\\n&lt;li&gt;Use &lt;code&gt;Series.dt.tz_localize()&lt;/code&gt; to localize the time to &lt;code&gt;&#39;US/Central&#39;&lt;/code&gt;.&lt;/li&gt;\\n&lt;li&gt;Use the &lt;code&gt;.dt.tz_convert()&lt;/code&gt; method to convert datetimes from &lt;code&gt;&#39;US/Central&#39;&lt;/code&gt; to &lt;code&gt;&#39;US/Pacific&#39;&lt;/code&gt;.&lt;/li&gt;\\n&lt;/ul&gt;&quot;,&quot;externalId&quot;,44362,&quot;question&quot;,&quot;&quot;,&quot;hint&quot;,&quot;&lt;ul&gt;\\n&lt;li&gt;Take advantage of element-wise operations to create the mask. You can do this with &lt;code&gt;df[&#39;Destination Airport&#39;] == &#39;LAX&#39;&lt;/code&gt;.&lt;/li&gt;\\n&lt;li&gt;By passing the mask as an index to &lt;code&gt;df&lt;/code&gt;, as with &lt;code&gt;df[mask]&lt;/code&gt;, you can subset the data such that it only contains entries with &lt;code&gt;&#39;LAX&#39;&lt;/code&gt; as the &lt;code&gt;&#39;Destination Airport&#39;&lt;/code&gt;.&lt;/li&gt;\\n&lt;li&gt;Inside &lt;code&gt;pd.to_datetime()&lt;/code&gt;, pass in the columns mentioned and be sure that there is a space between them.&lt;/li&gt;\\n&lt;li&gt;To localize the time of &lt;code&gt;times_tz_none&lt;/code&gt;, you can use &lt;code&gt;times_tz_none.dt.tz_localize()&lt;/code&gt;. Inside &lt;code&gt;.tz_localize()&lt;/code&gt;, specify &lt;code&gt;&#39;US/Central&#39;&lt;/code&gt;.&lt;/li&gt;\\n&lt;li&gt;Pass in &lt;code&gt;&#39;US/Pacific&#39;&lt;/code&gt; as an argument inside &lt;code&gt;times_tz_central.dt.tz_convert()&lt;/code&gt; to convert the time zone.&lt;/li&gt;\\n&lt;/ul&gt;&quot;,&quot;possible_answers&quot;,[&quot;^19&quot;,[]],&quot;number&quot;,14,&quot;user&quot;,[&quot;^0&quot;,[&quot;isHintShown&quot;,false,&quot;rstudio&quot;,[&quot;^0&quot;,[&quot;isReady&quot;,false,&quot;settings&quot;,[&quot;^0&quot;,[]],&quot;showHistory&quot;,false,&quot;cards&quot;,[&quot;^0&quot;,[&quot;messages&quot;,[&quot;^19&quot;,[]],&quot;currentRow&quot;,0]]]],&quot;editorTabs&quot;,[&quot;^0&quot;,[&quot;files/script.py&quot;,[&quot;^0&quot;,[&quot;title&quot;,&quot;script.py&quot;,&quot;props&quot;,[&quot;^0&quot;,[&quot;active&quot;,true,&quot;isClosable&quot;,false,&quot;code&quot;,&quot;# Build a Boolean mask to filter out all the &#39;LAX&#39; departure flights: mask\\nmask = df[&#39;Destination Airport&#39;] == ____\\n\\n# Use the mask to subset the data: la\\nla = df[____]\\n\\n# Combine two columns of data to create a datetime series: times_tz_none \\ntimes_tz_none = pd.____( ____ + &#39; &#39; + ____ )\\n\\n# Localize the time to US/Central: times_tz_central\\ntimes_tz_central = ____\\n\\n# Convert the datetimes from US/Central to US/Pacific\\ntimes_tz_pacific = ____&quot;,&quot;extra&quot;,[&quot;^0&quot;,[]],&quot;resetCode&quot;,&quot;# Build a Boolean mask to filter out all the &#39;LAX&#39; departure flights: mask\\nmask = df[&#39;Destination Airport&#39;] == ____\\n\\n# Use the mask to subset the data: la\\nla = df[____]\\n\\n# Combine two columns of data to create a datetime series: times_tz_none \\ntimes_tz_none = pd.____( ____ + &#39; &#39; + ____ )\\n\\n# Localize the time to US/Central: times_tz_central\\ntimes_tz_central = ____\\n\\n# Convert the datetimes from US/Central to US/Pacific\\ntimes_tz_pacific = ____&quot;]]]]]],&quot;fileBrowser&quot;,[&quot;^0&quot;,[&quot;sampleCode&quot;,[&quot;^0&quot;,[&quot;fileSelected&quot;,null,&quot;files&quot;,[&quot;^0&quot;,[&quot;name&quot;,&quot;files&quot;,&quot;isOpen&quot;,true,&quot;children&quot;,[&quot;^19&quot;,[[&quot;^0&quot;,[&quot;name&quot;,&quot;script.py&quot;,&quot;initialContent&quot;,&quot;# Build a Boolean mask to filter out all the &#39;LAX&#39; departure flights: mask\\nmask = df[&#39;Destination Airport&#39;] == ____\\n\\n# Use the mask to subset the data: la\\nla = df[____]\\n\\n# Combine two columns of data to create a datetime series: times_tz_none \\ntimes_tz_none = pd.____( ____ + &#39; &#39; + ____ )\\n\\n# Localize the time to US/Central: times_tz_central\\ntimes_tz_central = ____\\n\\n# Convert the datetimes from US/Central to US/Pacific\\ntimes_tz_pacific = ____&quot;,&quot;content&quot;,&quot;# Build a Boolean mask to filter out all the &#39;LAX&#39; departure flights: mask\\nmask = df[&#39;Destination Airport&#39;] == ____\\n\\n# Use the mask to subset the data: la\\nla = df[____]\\n\\n# Combine two columns of data to create a datetime series: times_tz_none \\ntimes_tz_none = pd.____( ____ + &#39; &#39; + ____ )\\n\\n# Localize the time to US/Central: times_tz_central\\ntimes_tz_central = ____\\n\\n# Convert the datetimes from US/Central to US/Pacific\\ntimes_tz_pacific = ____&quot;,&quot;isClosable&quot;,false]]]]]]]],&quot;solution&quot;,[&quot;^0&quot;,[&quot;fileSelected&quot;,null,&quot;files&quot;,[&quot;^0&quot;,[&quot;name&quot;,&quot;solution&quot;,&quot;isOpen&quot;,true,&quot;children&quot;,[&quot;^19&quot;,[[&quot;^0&quot;,[&quot;name&quot;,&quot;solution.py&quot;,&quot;initialContent&quot;,&quot;# Build a Boolean mask to filter out all the &#39;LAX&#39; departure flights: mask\\nmask = df[&#39;Destination Airport&#39;] == &#39;LAX&#39;\\n\\n# Use the mask to subset the data: la\\nla = df[mask]\\n\\n# Combine two columns of data to create a datetime series: times_tz_none \\ntimes_tz_none = pd.to_datetime( la[&#39;Date (MM/DD/YYYY)&#39;] + &#39; &#39; + la[&#39;Wheels-off Time&#39;] )\\n\\n# Localize the time to US/Central: times_tz_central\\ntimes_tz_central = times_tz_none.dt.tz_localize(&#39;US/Central&#39;)\\n\\n# Convert the datetimes from US/Central to US/Pacific\\ntimes_tz_pacific = times_tz_central.dt.tz_convert(&#39;US/Pacific&#39;)&quot;,&quot;content&quot;,&quot;# Build a Boolean mask to filter out all the &#39;LAX&#39; departure flights: mask\\nmask = df[&#39;Destination Airport&#39;] == &#39;LAX&#39;\\n\\n# Use the mask to subset the data: la\\nla = df[mask]\\n\\n# Combine two columns of data to create a datetime series: times_tz_none \\ntimes_tz_none = pd.to_datetime( la[&#39;Date (MM/DD/YYYY)&#39;] + &#39; &#39; + la[&#39;Wheels-off Time&#39;] )\\n\\n# Localize the time to US/Central: times_tz_central\\ntimes_tz_central = times_tz_none.dt.tz_localize(&#39;US/Central&#39;)\\n\\n# Convert the datetimes from US/Central to US/Pacific\\ntimes_tz_pacific = times_tz_central.dt.tz_convert(&#39;US/Pacific&#39;)&quot;,&quot;isClosable&quot;,false]]]]]]]]]],&quot;outputMarkdownTabs&quot;,[&quot;^0&quot;,[]],&quot;markdown&quot;,[&quot;^0&quot;,[&quot;titles&quot;,[&quot;^19&quot;,[&quot;Knit PDF&quot;,&quot;Knit HTML&quot;]],&quot;activeTitle&quot;,&quot;Knit HTML&quot;]],&quot;currentXp&quot;,100,&quot;graphicalTabs&quot;,[&quot;^0&quot;,[&quot;plot&quot;,[&quot;^0&quot;,[&quot;extraClass&quot;,&quot;animation--flash&quot;,&quot;title&quot;,&quot;Plots&quot;,&quot;props&quot;,[&quot;^0&quot;,[&quot;sources&quot;,[&quot;^19&quot;,[]],&quot;currentIndex&quot;,0]],&quot;dimension&quot;,[&quot;^0&quot;,[&quot;isRealSize&quot;,false,&quot;width&quot;,1,&quot;height&quot;,1]]]],&quot;html&quot;,[&quot;^0&quot;,[&quot;extraClass&quot;,&quot;animation--flash&quot;,&quot;title&quot;,&quot;HTML Viewer&quot;,&quot;props&quot;,[&quot;^0&quot;,[&quot;sources&quot;,[&quot;^19&quot;,[]],&quot;currentIndex&quot;,0]]]]]],&quot;feedbackMessages&quot;,[&quot;^19&quot;,[]],&quot;lastSubmittedCode&quot;,null,&quot;ltiStatus&quot;,[&quot;^0&quot;,[]],&quot;lastSubmitActiveEditorTab&quot;,null,&quot;consoleSqlTabs&quot;,[&quot;^0&quot;,[&quot;query_result&quot;,[&quot;^0&quot;,[&quot;extraClass&quot;,&quot;&quot;,&quot;title&quot;,&quot;query result&quot;,&quot;props&quot;,[&quot;^0&quot;,[&quot;active&quot;,true,&quot;isNotView&quot;,true,&quot;message&quot;,&quot;No query executed yet...&quot;]]]]]],&quot;consoleTabs&quot;,[&quot;^0&quot;,[&quot;console&quot;,[&quot;^0&quot;,[&quot;title&quot;,&quot;IPython Shell&quot;,&quot;props&quot;,[&quot;^0&quot;,[&quot;active&quot;,true]]]],&quot;slides&quot;,[&quot;^0&quot;,[&quot;title&quot;,&quot;Slides&quot;,&quot;props&quot;,[&quot;^0&quot;,[&quot;active&quot;,false]]]]]],&quot;inputMarkdownTabs&quot;,[&quot;^0&quot;,[]]]],&quot;randomNumber&quot;,0.6567513091913255,&quot;assignment&quot;,&quot;&lt;p&gt;Time zone handling with pandas typically assumes that you are handling the Index of the Series. In this exercise, you will learn how to handle timezones that are associated with datetimes in the column data, and not just the Index.&lt;/p&gt;\\n&lt;p&gt;You will work with the flight departure dataset again, and this time you will select Los Angeles (&lt;code&gt;&#39;LAX&#39;&lt;/code&gt;) as the destination airport.&lt;/p&gt;\\n&lt;p&gt;Here we will use a &lt;em&gt;mask&lt;/em&gt; to ensure that we only compute on data we actually want. To learn more about Boolean masks, click &lt;a href=\\&quot;https://docs.scipy.org/doc/numpy/reference/maskedarray.generic.html\\&quot;&gt;here&lt;/a&gt;!&lt;/p&gt;&quot;,&quot;feedbacks&quot;,[&quot;^19&quot;,[]],&quot;attachments&quot;,null,&quot;title&quot;,&quot;Time zones and conversion&quot;,&quot;xp&quot;,100,&quot;language&quot;,&quot;python&quot;,&quot;pre_exercise_code&quot;,&quot;import pandas as pd\\n# Data file obtained as CSV from http://apps.bts.gov/xml/ontimesummarystatistics/src/dstat/OntimeSummaryDepatures.xml\\nfile_name = \\&quot;/usr/local/share/datasets/austin_airport_departure_data_2015_july.csv\\&quot;\\ndf = pd.read_csv(file_name, \\n                 skiprows=range(0,15))\\ndf.columns = df.columns.str.strip()\\ndel file_name&quot;,&quot;solution&quot;,&quot;# Build a Boolean mask to filter out all the &#39;LAX&#39; departure flights: mask\\nmask = df[&#39;Destination Airport&#39;] == &#39;LAX&#39;\\n\\n# Use the mask to subset the data: la\\nla = df[mask]\\n\\n# Combine two columns of data to create a datetime series: times_tz_none \\ntimes_tz_none = pd.to_datetime( la[&#39;Date (MM/DD/YYYY)&#39;] + &#39; &#39; + la[&#39;Wheels-off Time&#39;] )\\n\\n# Localize the time to US/Central: times_tz_central\\ntimes_tz_central = times_tz_none.dt.tz_localize(&#39;US/Central&#39;)\\n\\n# Convert the datetimes from US/Central to US/Pacific\\ntimes_tz_pacific = times_tz_central.dt.tz_convert(&#39;US/Pacific&#39;)&quot;,&quot;type&quot;,&quot;NormalExercise&quot;,&quot;id&quot;,44362]],[&quot;^0&quot;,[&quot;sample_code&quot;,&quot;&quot;,&quot;sct&quot;,&quot;&quot;,&quot;aspect_ratio&quot;,56.25,&quot;instructions&quot;,null,&quot;externalId&quot;,44363,&quot;question&quot;,&quot;&quot;,&quot;hint&quot;,null,&quot;possible_answers&quot;,[&quot;^19&quot;,[]],&quot;number&quot;,15,&quot;video_hls&quot;,&quot;//videos.datacamp.com/transcoded/1639_pandas-1/v2/hls-ch3_4.master.m3u8&quot;,&quot;randomNumber&quot;,0.08806802352281395,&quot;assignment&quot;,null,&quot;feedbacks&quot;,[&quot;^19&quot;,[]],&quot;attachments&quot;,null,&quot;title&quot;,&quot;Visualizing pandas time series&quot;,&quot;xp&quot;,50,&quot;language&quot;,&quot;python&quot;,&quot;pre_exercise_code&quot;,&quot;&quot;,&quot;solution&quot;,&quot;&quot;,&quot;type&quot;,&quot;VideoExercise&quot;,&quot;id&quot;,44363,&quot;projector_key&quot;,&quot;course_1639_6a75d6ac92b56f139ad06120b4d553b4&quot;,&quot;video_link&quot;,null]],[&quot;^0&quot;,[&quot;sample_code&quot;,&quot;# Plot the raw data before setting the datetime index\\ndf.plot()\\nplt.show()\\n\\n# Convert the &#39;Date&#39; column into a collection of datetime objects: df.Date\\ndf.Date = ____\\n\\n# Set the index to be the converted &#39;Date&#39; column\\n____\\n\\n# Re-plot the DataFrame to see that the axis is now datetime aware!\\ndf.plot()\\nplt.show()&quot;,&quot;sct&quot;,&quot;Ex().check_function(\\&quot;df.plot\\&quot;, index=0)\\nEx().check_function(\\&quot;matplotlib.pyplot.show\\&quot;, index=0)\\n\\nEx().check_or(\\n  \\thas_equal_ast(\\&quot;Column `Date` of your `pandas` DataFrame, `df`, is not correct. Did you correctly convert it into a collection of `datetime` objects?\\&quot;,\\n                  code=\\&quot;pd.to_datetime(df.Date)\\&quot;,\\n                  exact=False),\\n\\thas_equal_ast(\\&quot;Column `Date` of your `pandas` DataFrame, `df`, is not correct. Did you correctly convert it into a collection of `datetime` objects?\\&quot;,\\n                  code=\\&quot;pd.to_datetime(df[&#39;Date&#39;])\\&quot;,\\n                  exact=False))\\n\\nEx().check_function(\\&quot;df.set_index\\&quot;).multi(\\n\\tcheck_args(0).has_equal_ast(),\\n  \\tcheck_args(&#39;inplace&#39;).has_equal_ast()\\n)\\n\\nEx().check_function(\\&quot;df.plot\\&quot;, index=1)\\nEx().check_function(\\&quot;matplotlib.pyplot.show\\&quot;, index=1)\\n\\nsuccess_msg(\\&quot;Great work! Click on &#39;Next Plot&#39; and &#39;Previous Plot&#39; to cycle between the two plots and note the difference.\\&quot;)&quot;,&quot;instructions&quot;,&quot;&lt;ul&gt;\\n&lt;li&gt;Use &lt;code&gt;pd.to_datetime()&lt;/code&gt; to convert the &lt;code&gt;&#39;Date&#39;&lt;/code&gt; column to a collection of datetime objects, and assign back to &lt;code&gt;df.Date&lt;/code&gt;.&lt;/li&gt;\\n&lt;li&gt;Set the index to this updated &lt;code&gt;&#39;Date&#39;&lt;/code&gt; column, using &lt;code&gt;df.set_index()&lt;/code&gt; with the optional keyword argument &lt;code&gt;inplace=True&lt;/code&gt;, so that you don&#39;t have to assign the result back to &lt;code&gt;df&lt;/code&gt;.&lt;/li&gt;\\n&lt;li&gt;Re-plot the DataFrame to see that the axis is now datetime aware. This code has been written for you.&lt;/li&gt;\\n&lt;/ul&gt;&quot;,&quot;externalId&quot;,44364,&quot;question&quot;,&quot;&quot;,&quot;hint&quot;,&quot;&lt;ul&gt;\\n&lt;li&gt;Pass in &lt;code&gt;df.Date&lt;/code&gt; as an argument to &lt;code&gt;pd.to_datetime()&lt;/code&gt; to convert the &lt;code&gt;&#39;Date&#39;&lt;/code&gt; column into a collection of datetime objects. &lt;/li&gt;\\n&lt;li&gt;Inside the &lt;code&gt;.set_index()&lt;/code&gt; method, you have to specify the column you want to use as the index - in this case, the &lt;code&gt;&#39;Date&#39;&lt;/code&gt; column. By also specifying the keyword argument &lt;code&gt;inplace=True&lt;/code&gt;, you don&#39;t have to assign the result back to &lt;code&gt;df&lt;/code&gt;.&lt;/li&gt;\\n&lt;li&gt;The code to re-plot the DataFrame has been written for you. Click &#39;Submit Answer&#39; to see the result!&lt;/li&gt;\\n&lt;/ul&gt;&quot;,&quot;possible_answers&quot;,[&quot;^19&quot;,[]],&quot;number&quot;,16,&quot;randomNumber&quot;,0.034190490298461995,&quot;assignment&quot;,&quot;&lt;p&gt;Pandas handles datetimes not only in your data, but also in your plotting. &lt;/p&gt;\\n&lt;p&gt;In this exercise, some time series data has been pre-loaded. However, we have not parsed the date-like columns nor set the index, as we have done for you in the past! &lt;/p&gt;\\n&lt;p&gt;The plot displayed is how pandas renders data with the default integer/positional index. Your job is to convert the &lt;code&gt;&#39;Date&#39;&lt;/code&gt; column from a collection of strings into a collection of datetime objects. Then, you will use this converted &lt;code&gt;&#39;Date&#39;&lt;/code&gt; column as your new index, and re-plot the data, noting the improved datetime awareness. After you are done, you can cycle between the two plots you generated by clicking on the &#39;Previous Plot&#39; and &#39;Next Plot&#39; buttons. &lt;/p&gt;\\n&lt;p&gt;Before proceeding, look at the plot shown and observe how pandas handles data with the default integer index. Then, inspect the DataFrame &lt;code&gt;df&lt;/code&gt; using the &lt;code&gt;.head()&lt;/code&gt; method in the IPython Shell to get a feel for its structure.&lt;/p&gt;&quot;,&quot;feedbacks&quot;,[&quot;^19&quot;,[]],&quot;attachments&quot;,null,&quot;title&quot;,&quot;Plotting time series, datetime indexing&quot;,&quot;xp&quot;,100,&quot;language&quot;,&quot;python&quot;,&quot;pre_exercise_code&quot;,&quot;import pandas as pd\\nimport matplotlib.pyplot as plt\\n# Read the raw data\\nfile_name = \\&quot;/usr/local/share/datasets/weather_data_austin_2010.csv\\&quot;\\ndf = pd.read_csv(file_name)\\n\\n# pull out just the hourly temperature data for January\\ndf = df[[&#39;Temperature&#39;,&#39;Date&#39;]]\\ndf = df.loc[0:31*24]\\n\\n# clean up namespace\\ndel file_name\\n&quot;,&quot;solution&quot;,&quot;# Plot the raw data before setting the datetime index\\ndf.plot()\\nplt.show()\\n\\n# Convert the &#39;Date&#39; column into a collection of datetime objects: df.Date\\ndf.Date = pd.to_datetime(df.Date)\\n\\n# Set the index to be the converted &#39;Date&#39; column\\ndf.set_index(&#39;Date&#39;, inplace=True)\\n\\n# Re-plot the DataFrame to see that the axis is now datetime aware!\\ndf.plot()\\nplt.show()&quot;,&quot;type&quot;,&quot;NormalExercise&quot;,&quot;id&quot;,44364]],[&quot;^0&quot;,[&quot;sample_code&quot;,&quot;# Plot the summer data\\ndf.Temperature[____:____].____\\nplt.show()\\nplt.clf()\\n\\n# Plot the one week data\\ndf.Temperature[____:____].____\\nplt.show()\\nplt.clf()\\n&quot;,&quot;sct&quot;,&quot;Ex().has_equal_ast(\\&quot;Did you correctly slice `df.Temperature` using `&#39;2010-Jun&#39;:&#39;2010-Aug&#39;` to plot the summer temperatures of 2010?\\&quot;,\\n                   code=\\&quot;df.Temperature[&#39;2010-Jun&#39;:&#39;2010-Aug&#39;].plot()\\&quot;,\\n                   exact=False)\\n\\nEx().has_equal_ast(\\&quot;Did you correctly slice `df.Temperature` using `&#39;2010-06-10&#39;:&#39;2010-06-17&#39;` to plot the temperatures of one week of June 2010?\\&quot;,\\n                   code=\\&quot;df.Temperature[&#39;2010-06-10&#39;:&#39;2010-06-17&#39;].plot()\\&quot;,\\n                   exact=False)\\n\\nEx().check_function(\\&quot;matplotlib.pyplot.show\\&quot;, index=0)\\nEx().check_function(\\&quot;matplotlib.pyplot.clf\\&quot;, index=0)\\n  \\nEx().check_function(\\&quot;matplotlib.pyplot.show\\&quot;, index=1)\\nEx().check_function(\\&quot;matplotlib.pyplot.clf\\&quot;, index=1)\\n\\nsuccess_msg(\\&quot;Well done! Now that you&#39;ve built your pandas foundations, you&#39;re ready to dive into a case study!\\&quot;)&quot;,&quot;instructions&quot;,&quot;&lt;ul&gt;\\n&lt;li&gt;Plot the summer temperatures using method chaining. The summer ranges from the months &lt;code&gt;&#39;2010-Jun&#39;&lt;/code&gt; to &lt;code&gt;&#39;2010-Aug&#39;&lt;/code&gt;. &lt;/li&gt;\\n&lt;li&gt;Plot the temperatures for one week in June using the same method chaining, but this time indexing with &lt;code&gt;&#39;2010-06-10&#39;:&#39;2010-06-17&#39;&lt;/code&gt; before you follow up with &lt;code&gt;.plot()&lt;/code&gt;.&lt;/li&gt;\\n&lt;/ul&gt;&quot;,&quot;externalId&quot;,44365,&quot;question&quot;,&quot;&quot;,&quot;hint&quot;,&quot;&lt;ul&gt;\\n&lt;li&gt;To plot the the summer temperatures, first select out the &lt;code&gt;Temperature&lt;/code&gt; column, then use bracket slicing from &lt;code&gt;&#39;2010-Jun&#39;:&#39;2010-Aug&#39;&lt;/code&gt;, and chain the &lt;code&gt;.plot()&lt;/code&gt; method to this.&lt;/li&gt;\\n&lt;li&gt;To plot the one week data, follow the same process as above, modifying the way you slice &lt;code&gt;df.Temperature&lt;/code&gt;.&lt;/li&gt;\\n&lt;/ul&gt;&quot;,&quot;possible_answers&quot;,[&quot;^19&quot;,[]],&quot;number&quot;,17,&quot;randomNumber&quot;,0.11375870971681423,&quot;assignment&quot;,&quot;&lt;p&gt;Now that you have set the DatetimeIndex in your DataFrame, you have a much more powerful and flexible set of tools to use when plotting your time series data. Of these, one of the most convenient is partial string indexing and slicing. In this exercise, we&#39;ve pre-loaded a full year of Austin 2010 weather data, with the index set to be the datetime parsed &lt;code&gt;&#39;Date&#39;&lt;/code&gt; column as shown in the previous exercise. &lt;/p&gt;\\n&lt;p&gt;Your job is to use partial string indexing of the dates, in a variety of datetime string formats, to plot all the summer data and just one week of data together. After you are done, you can cycle between the two plots by clicking on the &#39;Previous Plot&#39; and &#39;Next Plot&#39; buttons.&lt;/p&gt;\\n&lt;p&gt;First, remind yourself how to extract one month of temperature data using &lt;code&gt;&#39;May 2010&#39;&lt;/code&gt; as a key into &lt;code&gt;df.Temperature[]&lt;/code&gt;, and call &lt;code&gt;head()&lt;/code&gt; to inspect the result: &lt;code&gt;df.Temperature[&#39;May 2010&#39;].head()&lt;/code&gt;.&lt;/p&gt;&quot;,&quot;feedbacks&quot;,[&quot;^19&quot;,[]],&quot;attachments&quot;,null,&quot;title&quot;,&quot;Plotting date ranges, partial indexing&quot;,&quot;xp&quot;,100,&quot;language&quot;,&quot;python&quot;,&quot;pre_exercise_code&quot;,&quot;import pandas as pd\\nimport matplotlib.pyplot as plt\\n# Read the raw data\\nfile_name = \\&quot;/usr/local/share/datasets/weather_data_austin_2010.csv\\&quot;\\ndf = pd.read_csv(file_name, parse_dates=True, index_col=\\&quot;Date\\&quot;)\\n\\n# clean up namespace\\ndel file_name\\n&quot;,&quot;solution&quot;,&quot;# Plot the summer data\\ndf.Temperature[&#39;2010-Jun&#39;:&#39;2010-Aug&#39;].plot()\\nplt.show()\\nplt.clf()\\n\\n# Plot the one week data\\ndf.Temperature[&#39;2010-06-10&#39;:&#39;2010-06-17&#39;].plot()\\nplt.show()\\nplt.clf()\\n&quot;,&quot;type&quot;,&quot;NormalExercise&quot;,&quot;id&quot;,44365]]]]]]]]";</script><div id="root"><div class="theme progress-indicator--visible theme--light" data-reactroot=""><header data-cy="header-container" class="dc-header-campus"><a href="https://www.datacamp.com/" data-cy="header-logo" class="dc-header-campus__home"><img alt="datacamp-logo" src="https://campus.datacamp.com/static/media/logo-full-color.018b48cc.svg" style="max-height:29px"></a><div class="dc-nav-course__container"><div class="__react_component_tooltip place-top type-dark " data-id="tooltip"></div><div class="__react_component_tooltip place-top type-dark " data-id="tooltip"></div><div class="__react_component_tooltip place-top type-dark " data-id="tooltip"></div><nav class="dc-nav-course" data-onboarding="course-navigation"><a data-cy="header-previous" class="dc-nav-course__backward" data-tip="true" data-for="nav-tp-prev" href="time-series-in-pandas6abb.html?ex=13"><svg width="12" height="12" aria-label="arrow_2_left icon" class="dc-icon-arrow_2_left dc-nav-course__icon" role="Img" fill="currentColor"><use xlink:href="https://campus.datacamp.com/static/media/symbols.cace91b1.svg#arrow_2_left"/></svg></a><a data-cy="header-outline" class="dc-nav-course__outline" data-tip="true" data-for="nav-tp-outline" href="javascript:void(0)"><svg width="12" height="12" aria-label="bars icon" class="dc-icon-bars dc-nav-course__icon" role="Img" fill="currentColor"><use xlink:href="https://campus.datacamp.com/static/media/symbols.cace91b1.svg#bars"/></svg>Course Outline</a><a data-cy="header-next" class="dc-nav-course__forward" data-tip="true" data-for="nav-tp-next" href="time-series-in-pandas9499.html?ex=15"><svg width="12" height="12" aria-label="arrow_2_right icon" class="dc-icon-arrow_2_right dc-nav-course__icon" role="Img" fill="currentColor"><use xlink:href="https://campus.datacamp.com/static/media/symbols.cace91b1.svg#arrow_2_right"/></svg></a></nav></div><nav class="dc-u-fx dc-u-fx-ais dc-u-fx-jcfe dc-u-w-96"><div data-cy="header-session" class="app-status dc-u-fx dc-u-mr-8"><div class="hcSlide-wrapper"></div><svg width="18" height="18" aria-label="circle icon" class="dc-icon-circle dc-u-color-green" role="Img" fill="currentColor"><use xlink:href="https://campus.datacamp.com/static/media/symbols.cace91b1.svg#circle"/></svg></div><div data-tip="true" data-for="tp-notifications"><div class="__react_component_tooltip place-top type-dark " data-id="tooltip"></div><a data-cy="header-notifications" class="ds-icon-action dc-u-fx" href="javascript:void(0)"><svg width="18" height="18" aria-label="notification icon" class="dc-icon-notification" role="Img" fill="currentColor"><use xlink:href="https://campus.datacamp.com/static/media/symbols.cace91b1.svg#notification"/></svg></a></div><a data-cy="header-slides" class="ds-icon-action dc-u-fx dc-u-ml-8" href="javascript:void(0)"><div data-tip="true" data-for="tp-slides"><div class="__react_component_tooltip place-top type-dark " data-id="tooltip"></div><svg width="18" height="18" aria-label="pdf icon" class="dc-icon-pdf dc-u-fx" role="Img" fill="currentColor"><use xlink:href="https://campus.datacamp.com/static/media/symbols.cace91b1.svg#pdf"/></svg></div></a><a data-cy="header-issue" class="ds-icon-action dc-u-fx dc-u-ml-8" data-test-id="header-report-issue-button" href="javascript:void(0)"><div data-tip="true" data-for="tp-issue"><div class="__react_component_tooltip place-top type-dark " data-id="tooltip"></div><svg width="18" height="18" aria-label="attention icon" class="dc-icon-attention dc-u-fx" role="Img" fill="currentColor"><use xlink:href="https://campus.datacamp.com/static/media/symbols.cace91b1.svg#attention"/></svg></div></a></nav></header><div class="exercise-area "><div data-cy="server-side-loader-placeholder"><aside class="exercise--sidebar" style="width:40%"><div class="exercise--sidebar-content"><div class="listview__outer"><div class="listview__inner"><div class="listview__section" data-onboarding="assignment"><div><div role="button" class="listview__header"><div class="exercise--sidebar-header"><h5 class="dc-panel__title"><svg width="12" height="12" aria-label="exercise icon" class="dc-icon-exercise dc-u-color-grey-dark dc-u-mr-8" role="Img" fill="currentColor"><use xlink:href="https://campus.datacamp.com/static/media/symbols.cace91b1.svg#exercise"/></svg>Exercise</h5></div></div></div><div class="listview__content"><div class="exercise--assignment exercise--typography"><h1 class="exercise--title">Time zones and conversion</h1><div class=""><p>Time zone handling with pandas typically assumes that you are handling the Index of the Series. In this exercise, you will learn how to handle timezones that are associated with datetimes in the column data, and not just the Index.</p>
<p>You will work with the flight departure dataset again, and this time you will select Los Angeles (<code>&apos;LAX&apos;</code>) as the destination airport.</p>
<p>Here we will use a <em>mask</em> to ensure that we only compute on data we actually want. To learn more about Boolean masks, click <a href="https://docs.scipy.org/doc/numpy/reference/maskedarray.generic.html">here</a>!</p></div></div></div></div><div class="listview__section" style="min-height:calc(100% - 33px)" data-onboarding="instructions"><div><div role="button" class="listview__header"><div class="exercise--sidebar-header"><h5 class="dc-panel__title"><svg width="12" height="12" aria-label="checkmark_circle icon" class="dc-icon-checkmark_circle dc-u-color-grey-dark dc-u-mr-8" role="Img" fill="currentColor"><use xlink:href="https://campus.datacamp.com/static/media/symbols.cace91b1.svg#checkmark_circle"/></svg>Instructions</h5><span class="tag tag--xp">100<!-- --> XP</span></div></div></div><div class="listview__content"><div><div class=""><div data-onboarding="instructions" class="exercise--instructions exercise--typography"><div class="exercise--instructions__content"><ul>
<li>Create a Boolean mask, <code>mask</code>, such that if the <code>&apos;Destination Airport&apos;</code> column of <code>df</code> equals <code>&apos;LAX&apos;</code>, the result is <code>True</code>, and otherwise, it is <code>False</code>.</li>
<li>Use the mask to extract only the <code>LAX</code> rows. Assign the result to <code>la</code>.</li>
<li>Concatenate the two columns <code>la[&apos;Date (MM/DD/YYYY)&apos;]</code> and <code>la[&apos;Wheels-off Time&apos;]</code> with a <code>&apos; &apos;</code> space in between. Pass this to <code>pd.to_datetime()</code> to create a datetime array of all the times the LAX-bound flights left the ground.</li>
<li>Use <code>Series.dt.tz_localize()</code> to localize the time to <code>&apos;US/Central&apos;</code>.</li>
<li>Use the <code>.dt.tz_convert()</code> method to convert datetimes from <code>&apos;US/Central&apos;</code> to <code>&apos;US/Pacific&apos;</code>.</li>
</ul></div><div class="campus-dc-sct-feedback" tabindex="-1"><div style="position:absolute;width:0;height:0;visibility:hidden;display:none"></div><ul class="campus-dc-sct-feedback__tab-list"><div style="display:inline-block" data-tip="true" data-for="tp-hint"><div class="__react_component_tooltip place-top type-dark " data-id="tooltip"></div><a class="exercise--show-hint" data-cy="exercise-show-hint" href="javascript:void(0)"><svg width="18" height="18" aria-label="lightbulb icon" class="dc-icon-lightbulb dc-u-mr-4" role="Img" fill="currentColor"><use xlink:href="https://campus.datacamp.com/static/media/symbols.cace91b1.svg#lightbulb"/></svg><span>Take Hint<!-- --> (-<!-- -->30<!-- --> XP)</span></a></div></ul></div></div></div></div></div></div></div></div></div></aside><section class="exercise--content" style="width:60%"><div class="exercise-waiting"><div class="global-spinner"><object type="image/svg+xml" data="https://campus.datacamp.com/static/media/spinner.dd0612cb.svg" aria-label="Loading"></object></div><noscript></noscript></div></section></div><div class="Toastify"></div></div><div class="exercise-footer"><ul data-cy="progress-container" class="dc-progress-indicator"><li class="dc-progress-indicator__item"><a class="dc-progress-indicator__bar" href="javascript:void(0)"><div class="dc-progress-indicator__fill" style="width:0%"></div></a></li><li class="dc-progress-indicator__item"><a class="dc-progress-indicator__bar" href="javascript:void(0)"><div class="dc-progress-indicator__fill" style="width:0%"></div></a></li><li class="dc-progress-indicator__item"><a class="dc-progress-indicator__bar" href="javascript:void(0)"><div class="dc-progress-indicator__fill" style="width:0%"></div></a></li><li class="dc-progress-indicator__item"><a class="dc-progress-indicator__bar" href="javascript:void(0)"><div class="dc-progress-indicator__fill" style="width:0%"></div></a></li></ul></div></div></div><script type="text/x-mathjax-config">MathJax && MathJax.Hub && MathJax.Hub.Config && MathJax.Hub.Config({
        messageStyle: "none"
      });</script><script type="text/javascript" src="../../../cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJaxdda6.js?config=TeX-AMS-MML_HTMLorMML"></script></body>
<!-- Mirrored from campus.datacamp.com/courses/pandas-foundations/time-series-in-pandas?ex=14 by HTTrack Website Copier/3.x [XR&CO'2014], Mon, 25 Feb 2019 20:43:28 GMT -->
</html>